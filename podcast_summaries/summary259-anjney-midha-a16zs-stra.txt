--- Podcast Metadata ---
Show: Eye On A.I.
Episode: #259 Anjney Midha: a16z’s Stra…
Host: Unknown
GUESTS: Anjney Midha
Guests: Anjney Midha
Source URL: https://podcasts.apple.com/us/podcast/259-anjney-midha-a16zs-strategy-to-turn-ai-startups/id1438378439?i=1000710873617
------------------------

Here is a comprehensive, structured summary of the podcast episode "Eye On A.I. #259 Anjney Midha: a16z’s Stra…".

---

**1. Podcast Overview & Key Segments:**

*   **Overall Summary:** This episode features Anjney Midha, a General Partner at Andreessen Horowitz (a16z), discussing the evolving landscape of AI, particularly from an early-stage venture capital perspective. The conversation delves into the shift from general models to specialized "last miles," the emergence of agentic AI systems, and the critical challenge of AI reliability through robust evaluation. Midha emphasizes a return to a more hands-on, science-driven investment approach reminiscent of early biotech VC, focusing on commercializing cutting-edge research into productized solutions rather than just models.

*   **Key Topics:**

    *   **The Rise of Agentic AI Systems:** The discussion highlights the transition of AI models from mere "next word prediction machines" to "next action prediction machines." Midha defines agents broadly as models capable of taking action, calling tools, and self-learning. He expresses particular excitement for agents in code workflows due to the ease of verification via unit tests, contrasting this with the brittleness of general-purpose browsing agents.
        *   "We're entering a regime where the model is taking action versus just producing words. We're starting to get into an agentic system."
    *   **Evolution of AI Architectures and the "Bitter Lesson":** Midha discusses the dominance of transformer models and the "bitter lesson" – the counterintuitive truth that general models, especially transformers, have often outperformed specialized architectures due to scaling laws and Moore's Law. However, he anticipates a future of "hybrid architectures" where transformers are combined with other approaches (like diffusion models for multimodal generation) for specific "last miles" to achieve optimal performance and efficiency.
        *   "I do think that the last few years have been the unabashed growth of transformer pre-training scaling. And that meant for a long time, people thought that meant that general models would win. And I think actually now we're transitioning to an era where general models with specific last miles are winning."
    *   **The Challenge of AI Reliability and Evaluation:** A significant focus is placed on the critical need for robust evaluation methods to ensure AI reliability, especially as models move from research to deployment in mission-critical industries like healthcare and defense. Midha argues that traditional academic benchmarks are no longer sufficient and advocates for real-world, crowdsourced evaluation (like LMSys) to combat "Goodhart's law" (when a measure becomes a target, it ceases to be a good measure).
        *   "The number one thing that keeps me up at night right now is evaluation. How do you actually tell how good these models are?"
    *   **The Shifting Landscape of AI Investment:** Midha describes his investment philosophy as a return to the early days of venture capital, akin to biotech investing, where VCs work closely with scientists to commercialize research. He emphasizes the importance of understanding the underlying science, procuring compute, and helping founders translate foundational models (which he views as components, not products) into end-to-end solutions for specific customer problems.
        *   "The discipline of investing, weirdly, has changed so dramatically in the last few years that it actually looks, at least in the world that I spend my time in, which is AI infrastructure, you know, at the earliest stages of taking AI technology out of the lab, it looks much more like the early days of the venture capital industry."

*   **Conclusion:** The podcast concludes with Midha reiterating his hands-on, early-stage investment approach, often being the "first call" for scientists looking to commercialize their research. He highlights the unique challenges and opportunities in AI infrastructure, where the investment process often involves deep technical engagement, compute procurement, and a focus on turning scientific breakthroughs into viable, productized businesses that solve real-world problems, rather than just betting on models as standalone products.

**2. Key Themes, Technological Insights & Core Discussion Points:**

*   **Agentic Systems as the Next Frontier:** AI models are evolving from passive text generators to active decision-makers capable of interacting with tools and environments.
    *   "We're entering a regime where the model is taking action versus just producing words. We're starting to get into an agentic system."
*   **Hybrid Architectures for "Last Mile" Specialization:** While transformers have dominated, the future of AI will likely involve combining general transformer models with specialized, non-transformer architectures for specific applications to achieve optimal performance and efficiency.
    *   "I think actually now we're transitioning to an era where general models with specific last miles are winning. That last mile can often be a combination of an LSTM, an SSM, a completely different non-transformer-based approach."
*   **The Critical Need for Real-World AI Evaluation:** Traditional academic benchmarks are insufficient for assessing AI reliability in deployment; real-world, user-driven evaluation is paramount to ensure models are useful and trustworthy in critical applications.
    *   "Now we're in the era where if you want to know if a new model actually solves a physician's problem in the field or a scientist's problem in the field, well, you need these models to be trained in that real-world evaluation loop."
*   **AI Reliability as the Core Problem:** The biggest barrier to AI adoption in mission-critical industries (defense, healthcare, finance) is the lack of reliability, which can be addressed through interpretability, robust real-world evaluation, or open-source/open-weight models.
    *   "The biggest problem holding back AI models from being useful, I would say, in the most mission-critical industries of life, defense, healthcare, financial services, is reliability."
*   **Models are Components, Not Products:** Foundational models, while powerful, are akin to chips or transistors; true value is created by building end-to-end product solutions on top of these models that address specific customer problems.
    *   "I don't think models have ever really been products. Models are phenomenal components... but ultimately, customers don't buy components, they buy solutions."
*   **The "Bitter Lesson" and Moore's Law:** The unexpected success of general-purpose transformer models, despite the theoretical efficiency of specialized architectures, is largely attributed to the relentless progress of Moore's Law and the efficiency of transformers in extracting latent knowledge from vast datasets.
    *   "The bitter lesson is just turning out to be true because Moore's Law continues being one of the biggest drivers of efficiency."
*   **Interpretability as a Path to Control:** Making black-box transformer models more transparent through mechanistic interpretability research (like Anthropic's work) is crucial for understanding and ultimately controlling their behavior, offering an alternative to relying solely on open weights for control.
    *   "There's only two solutions, I think. Either you have an architectural change that makes these black boxes transparent... or the second approach is you start measuring the output of the models to be sufficiently predictable that they're reliable."

**3. Actionable Investment Theses (Early-Stage VC Focus):**

*   **Investment Thesis 1: Agentic AI for Verifiable Workflows (e.g., Code Generation, Front-End Development)**
    *   **Problem:** While general-purpose agents are brittle, specific domains lack automated, reliable AI assistance for complex, multi-step tasks where outcomes can be formally verified.
        *   "The reality is for things like browsing, general-purpose agents are very brittle. But in workflows like coding, where the outcomes actually quite easy to verify and score, we have unit tests, right, in software."
    *   **Proposed Solution/Market Opportunity:** Develop specialized AI agents and platforms that excel in domains with clear, automated verification mechanisms (e.g., unit tests, formal specifications). This includes tools for front-end web development, automated testing, and potentially other codified engineering workflows.
        *   "I'm a huge believer that within a year, you will be able to ask an AI-assisted agent to, or an AI agent to create a website for you end-to-end. And we're almost already there, to be honest."
    *   **Why Compelling Now:** The underlying LLM capabilities for tool calling are maturing, and the ability to automate verification provides a clear path to reliability and demonstrable ROI, making these solutions immediately valuable for enterprises.
    *   **Mentioned Companies:** agency (open source collective for multi-agent software), Rabbit AI, MANUS.
*   **Investment Thesis 2: Next-Generation AI Evaluation & Reliability Platforms**
    *   **Problem:** The current methods for evaluating AI models (academic benchmarks) are prone to overfitting and do not accurately reflect real-world performance or reliability, hindering adoption in critical sectors.
        *   "Now we're in the era where if you want to know if a new model actually solves a physician's problem in the field or a scientist's problem in the field, well, you need these models to be trained in that real-world evaluation loop."
    *   **Proposed Solution/Market Opportunity:** Build platforms and methodologies for robust, real-world, and ideally crowdsourced AI evaluation. This could involve tools for A/B testing LLM outputs with human feedback, simulation environments for agent performance, or systems for continuous monitoring of AI reliability in production.
        *   "I've become much more partial to crowdsource the wisdom of the crowd, things like LMSIS, right? Where you have real-world users show up and rank two side-by-side responses from LLMs."
    *   **Why Compelling Now:** As AI moves from research to widespread deployment, especially in regulated industries, reliability becomes paramount. Companies that can provide verifiable, trustworthy evaluation will be critical enablers for enterprise AI adoption.
    *   **Mentioned Companies:** LMSys, Chat Arena.
*   **Investment Thesis 3: Specialized Foundational Models for Niche Modalities & Conversational AI**
    *   **Problem:** While general models exist, specific "sub-modalities" within AI (e.g., real-time conversational speech vs. asynchronous text-to-speech) require fundamentally different architectural and training approaches to achieve human-like performance and speed.
        *   "Within the field of audio, text-to-speech is completely different from the modality of conversational speech."
    *   **Proposed Solution/Market Opportunity:** Invest in teams building highly specialized foundational models and productized solutions for distinct sub-modalities where general models fall short. This includes real-time conversational AI, specific multimodal generation (e.g., transfusion models for image/video), or other niche areas requiring unique data processing and architectural considerations.
        *   "Sesame approaches their problem as a different modality, which is what they call conversational speech. When you need to train a model to be a two-way companion that can talk to you in real time... the kinds of decisions you end up making to build a product off of that are completely different."
    *   **Why Compelling Now:** As the AI market matures, differentiation will come from superior performance in specific, high-value use cases. Teams with deep scientific expertise in these niche modalities can build defensible product experiences.
    *   **Mentioned Companies:** Sesame, 11 Labs, Mistral, Black Forest Labs.

**4. Noteworthy Observations & Unique Perspectives:**

*   **VC's Role Reverting to Early Biotech Model:** Midha observes that early-stage AI infrastructure investing today mirrors the hands-on, science-driven approach of early venture capital in the 1970s and 80s, particularly in biotech, where VCs actively help scientists commercialize lab research.
    *   "The discipline of investing, weirdly, has changed so dramatically in the last few years that it actually looks, at least in the world that I spend my time in, which is AI infrastructure, you know, at the earliest stages of taking AI technology out of the lab, it looks much more like the early days of the venture capital industry."
*   **The "Bitter Lesson" of General Models:** Despite traditional machine learning wisdom favoring specialized architectures for efficiency, the transformer's general applicability and the relentless march of Moore's Law have made general models surprisingly efficient and dominant.
    *   "That task-specific architectures historically have been more efficient when it comes to production. And that's just turned out to be unintuitively, frustratingly untrue, right? Like the transformer has just marched ahead."
*   **The Discomfort of Frontier Science as an Investment Signal:** Midha finds that when leading scientists challenge a fundamental assumption and make him feel uncomfortable (e.g., Anthropic's initial $500M compute need), it's often a strong signal to dig deeper and indicates a potentially transformative opportunity.
    *   "Usually I find that when some of the most leading scientists kind of challenge a base assumption you have, it's usually a good and you feel uncomfortable. It's a good, I find it's a good practice to dig into that discomfort and kind of dig, ask the five whys on from a first principles basis, why are they so convicted in that, right?"
*   **The "Inevitable to Imminent" Transition:** The most exciting moment for investment is when a scientific breakthrough transitions from being theoretically "inevitable" to practically "imminent," as this is when a VC can be most useful in helping commercialize the research.
    *   "I find the most exciting moment is when science is going from being, or some kind of, or some strain of technology is going from being inevitable to being imminent."

**5. Companies & Entities Mentioned:**

*   **agency (AGENCY)**: An open-source collective building the "Internet of Agents," a collaboration layer for AI agents.
    *   URL: agntcy.org
    *   Context: Mentioned in a sponsored segment as a solution for building multi-agent software and inter-agent communication.
*   **Kleiner Perkins (KPCB)**: Venture capital firm where Anjney Midha previously worked.
    *   URL: www.kleinerperkins.com
    *   Context: Midha's first exposure to VC, where he helped portfolio companies with ML pipelines and later became an investor.
*   **Ubiquiti 6**: Anjney Midha's former company, focused on high-precision 3D mapping using computer vision.
    *   Context: Built technology for augmented reality applications and massively multiplayer networking, later sold to Discord.
*   **Pokemon Go**: Location-based augmented reality game.
    *   URL: pokemongo.nianticlabs.com
    *   Context: A primary source of customer demand for Ubiquiti 6's mapping technology.
*   **Niantic**: Developer of Pokemon Go.
    *   URL: nianticlabs.com
    *   Context: Credited by Midha for opening his eyes to location-based gaming.
*   **Discord**: Communication platform.
    *   URL: discord.com
    *   Context: Acquired Ubiquiti 6; Midha led their developer platform business.
*   **OpenAI**: AI research and deployment company.
    *   URL: openai.com
    *   Context: Friends from OpenAI (Tom Brown) called Midha to help fundraise for Anthropic. GPT-3 and GPT-2 are mentioned.
*   **Anthropic**: AI safety and research company.
    *   URL: www.anthropic.com
    *   Context: Midha was an angel investor and helped with fundraising and compute acquisition; their work on scaling laws and interpretability is discussed.
*   **MidJourney**: Text-to-image AI model.
    *   URL: www.midjourney.com
    *   Context: Midha helped launch it on Discord's app store, seeing it as an early "killer app" for a new platform shift.
*   **Andreessen Horowitz (a16z)**: Venture capital firm where Anjney Midha is currently a General Partner.
    *   URL: a16z.com
    *   Context: Midha joined to invest full-time in foundation model infrastructure businesses.
*   **Mistral AI**: Open-source language model company.
    *   URL: mistral.ai
    *   Context: Midha has worked with their founders; their "Law Platform" is cited as an example of a productized solution.
*   **Stable Diffusion**: Open-source image generation model.
    *   URL: stability.ai (original creator, though Black Forest Labs is a new venture by creators)
    *   Context: Robin Rombach and team (creators) are now involved with Black Forest Labs.
*   **Black Forest Labs**: Open-source image and video model lab.
    *   Context: Midha is a founding investor and board member, helping them build a commercially viable business around open-source image models.
*   **Sesame**: Conversational voice companion company.
    *   Context: A company Midha invested in, highlighted as an example of a specialized "sub-modality" in audio (conversational speech vs. text-to-speech).
*   **11 Labs**: Text-to-speech and voice AI company.
    *   URL: 11labs.io
    *   Context: Midha is an angel investor; used as a contrast to Sesame to illustrate different audio modalities.
*   **LMSys**: Open-source organization for LLM evaluation.
    *   URL: lmsys.org
    *   Context: Cited as a good example of crowdsourced, real-world AI evaluation.
*   **Chat Arena**: A platform for side-by-side LLM comparisons, part of LMSys.
    *   URL: chat.lmsys.org
    *   Context: Mentioned as a positive move in AI evaluation.
*   **DeepSeek**: A family of open-source language models.
    *   URL: deepseek.com
    *   Context: Mentioned by the host as an example of cheaper-to-train models.
*   **Rabbit AI**: Company that launched Rabbit OS Intern / Large Action Model Playground.
    *   URL: www.rabbit.tech
    *   Context: Mentioned by the host as an example of multi-agent systems.
*   **MANUS**: Multi-agent systems (general term, not a specific company mentioned).
    *   Context: Mentioned by the host in the context of multi-agent systems like Rabbit AI.
*   **Speechify / Speech Matix**: (Host's examples of other voice AI companies, not directly endorsed by Midha).
    *   URL: speechify.com / speechmatics.com
    *   Context: Host's examples of other voice AI companies.

**6. VC Follow-Up Research & Due Diligence:**

*   **Market Sizing & Segmentation for Agentic AI:**
    *   Deep dive into specific industry verticals (e.g., software development, customer service, specialized enterprise workflows) where AI agents with verifiable outcomes can deliver significant ROI.
    *   Quantify the potential market size for "agent-assisted" vs. "fully autonomous" agent solutions in these verticals.
*   **Competitive Landscape for AI Evaluation & Reliability:**
    *   Map out existing players in AI observability, monitoring, and evaluation.
    *   Analyze their methodologies (e.g., synthetic benchmarks, human-in-the-loop, crowdsourcing, mechanistic interpretability tools) and assess their scalability and robustness for enterprise adoption.
    *   Investigate the regulatory and compliance implications of AI reliability in critical sectors.
*   **Technical Deep Dive into Hybrid Architectures & Sub-Modalities:**
    *   Research emerging non-transformer architectures (e.g., Mamba, LSTMs) and their potential for specific "last mile" applications.
    *   Identify research labs and academic groups pushing the boundaries in niche AI modalities (e.g., real-time conversational audio, specific video generation, specialized code generation).
    *   Evaluate the technical defensibility of specialized models against the continued scaling of general models.
*   **Compute Infrastructure & Supply Chain Analysis:**
    *   Assess the current and future availability and cost of high-end GPUs (e.g., H100s) and other specialized AI hardware.
    *   Understand the landscape of cloud providers and specialized compute providers for AI training and inference.
    *   Analyze the implications of "sovereign AI stacks" on compute demand and supply.
*   **Talent Mapping for Frontier AI Research:**
    *   Identify leading researchers and scientists in AI interpretability, agentic systems, and novel architectures.
    *   Understand the incentives and challenges for these researchers to transition from academia/labs to commercial ventures.
*   **Productization Strategy for Foundational Models:**
    *   Study successful examples of companies that have effectively productized foundational models (e.g., Mistral's Law Platform, Anthropic's early vision for an AI pair programmer).
    *   Develop frameworks for evaluating a team's ability to translate core model capabilities into compelling, end-to-end customer solutions.

**7. TomTunguz.com Style Blog Post Ideas:**

*   **Title: The "Bitter Lesson" of AI: Why General Models Keep Winning (and What It Means for Your Startup)**
    *   **Core Argument:** This post would explore the counterintuitive phenomenon of general-purpose AI models (like transformers) consistently outperforming specialized architectures, largely driven by Moore's Law and scaling. It would then discuss the implications for startups: focusing on "last mile" productization and data quality rather than chasing novel, task-specific architectures, while also acknowledging the emerging role of hybrid models.
    *   **Quotes:**
        *   "That task-specific architectures historically have been more efficient when it comes to production. And that's just turned out to be unintuitively, frustratingly untrue, right? Like the transformer has just marched ahead."
        *   "The bitter lesson is just turning out to be true because Moore's Law continues being one of the biggest drivers of efficiency."

*   **Title: Beyond Benchmarks: The VC's Guide to Investing in Reliable AI**
    *   **Core Argument:** As AI moves into mission-critical applications, traditional academic benchmarks are failing to ensure reliability. This post would argue for a shift towards real-world, crowdsourced evaluation methods and explore the investment opportunities in companies building the tools and platforms for robust AI reliability, interpretability, and verifiable performance.
    *   **Quotes:**
        *   "The number one thing that keeps me up at night right now is evaluation. How do you actually tell how good these models are?"
        *   "The biggest problem holding back AI models from being useful, I would say, in the most mission-critical industries of life, defense, healthcare, financial services, is reliability."

*   **Title: The Return of the Scientist-Founder: Why Early-Stage AI Investing Looks Like 1970s Biotech**
    *   **Core Argument:** This post would highlight the evolving nature of early-stage venture capital in AI, drawing parallels to the origins of biotech investing. It would emphasize the increasing importance of VCs partnering directly with deep scientific talent, assisting with fundamental infrastructure (like compute procurement), and guiding the commercialization of lab-born research into productized solutions, rather than just funding software features.
    *   **Quotes:**
        *   "The discipline of investing, weirdly, has changed so dramatically in the last few years that it actually looks, at least in the world that I spend my time in, which is AI infrastructure, you know, at the earliest stages of taking AI technology out of the lab, it looks much more like the early days of the venture capital industry."
        *   "I often find it most rewarding to be the first call for a scientist or a researcher about commercializing their research before there even is a company."

---
HOST: Unknown
GUESTS: Anjney Midha