
Welcome to Latent Space Live, our first mini conference held at NURIPS 2024 in Vancouver.
This is Charlie, your AI co-host.
As a special treat this week, we're recapping the best of 2024 going domain by domain.
We sent out a survey to the over 900 of you who told us what you wanted, and then invited
the best speakers in the latent space network to cover each field.
200 of you joined us in person throughout the day with over 2,200 watching live online.
Our next keynote covers the state of open models in 2024 with Lucas Oldani and Nathan
Lambert of the Allen Institute for AI, with a special appearance from Dr. Sophia Yang of
Mistral.
Our first hit episode of 2024 was with Nathan Lambert on RLHF 201 back in January, where
he discussed both reinforcement learning for language models and the growing post-training
and mid-training stack with hot takes on everything from constitutional AI to DPO to rejection
sampling and also previewed the sea change coming to the Allen Institute and to interconnects
his incredible sub-stack on the technical aspects of state-of-the-art AI training.
We highly recommend subscribing to get access to his Discord as well.
It is hard to overstate how much open models have exploded this past year.
In 2023, only five names were playing in the top LLM ranks, Mistral, Mosaic's MPT, TI-I
UAE's Falcon, Yi from Kifu Lee's 01.AI, and of course, Metas Llama 1 and 2.
This year, a whole cast of new open models have burst on the scene, from Google's Gemma
and Cohere's Commander, to Alibaba's Quen and DeepSick models, to LLM 360 and DCLM,
and of course to the Allen Institute's OLMO, OLMO-E, PIXMO, MOMO and OLMO 2 models.
Pursuing open model research comes with a lot of challenges beyond just funding and
access to GPUs and datasets, particularly the regulatory debates this year across Europe,
California and the White House.
We also were honored to hear from Mistral, who also presented a great session at the
AI Engineer World's Fair Open Models track.
As always, don't forget to check the show notes for the YouTube link to their talk,
as well as their slides.
Watch out and take care.
Cool.
Yeah, thanks for having me over, I'm Luca, I'm a research scientist at the Allen Institute
for AI.
I threw together a few slides on sort of like a recap of like interesting themes in open
models for 2024, have about maybe 20, 25 minutes of slides and then we can chat if
there are any questions, if I can advance to the next slides.
Okay, cool.
So I did the quick check of like, to sort of get a sense of like how much 2024 was different
from 2023.
So when I'm hugging face, instead of trying to get a picture of what kind of models were
released in 2023, and like, what do we get in 2024?
2023, we got things like both Llama 1 and 2, we got Mistral, got MPT, Falcon models,
the ye model came at the tail end of the year, it was a pretty good year.
But then I did the same for 2024, and it's actually quite stark difference.
We have models that are, you know, reveling frontier level performance of what you can
get from close models, from like when, from deep seek, we got Llama 3, we got all sorts
of different models.
I added our own, Olmo at the bottom, there's this green group of like fully open models
that I'm going to touch on a little bit later.
But, you know, just looking at this slide, it feels like 2024 was just smooth sailing,
happy knees, much better in previous year.
And, you know, you can plot, you can pick your favorite benchmark, or least favorite,
I don't know, depending on what point you're trying to make, and plot, you know, your
close model, your open model, and sort of spin it in ways that show that, oh, you know,
open models are much closer to where close models are today, versus to, versus last year
where the gap was fairly significant.
So one thing that I think, I don't know if I have to convince people in this room, but
usually when I give this talks about like open models, there is always like this background
question in people's mind of like, why should we use open models?
Because they just use model API's argument, you know, it's just an HTTP request to get
output from one of the best model out there.
Why do I have to set up infrared use local models?
And they really like to answer, there is the more researchy answer for this, which is where
my background lays, which is just research, if you want to do research or language models,
research thrives on open models.
There is like large worth of research on modeling and how these models behave on evaluation
and inference on mechanistic interpretability that could not happen at all, if you didn't
have open models.
They're also for AI builder, so they're also like good use cases for using local models.
You know, you have some, this is like a very not comprehensive slides, but you have things
like there are some application where local models just blow close models out of the water,
so like retrieval is a very clear example.
You might have like constraints like edge AI applications where it makes sense, but even
just like in terms of like stability, being able to say this model is not changing under
hood, it's, there's plenty of good cases for open models.
And the community's just models is I stole this slide from one of the quintu announcement
blog posts, but it's super cool to see like how much tech exists around open models, I'm
serving them, I'm making them efficient and hosting them, it's pretty cool.
And it's, if you think about like where the term opens confirm comes from like the open
source, really open models meet the core tenants of open source, specifically when it comes
around collaboration, there is really a spirit like through these open models, you can build
on top of others people innovation.
We see a lot of these even in our own work of like, you know, as we iterate in the various
version of almost, it's not just like every time we collect from scratch all the data.
No, the first step is like, okay, what other cool data sources and data sets people have
put together for language model for training, or when it comes to like our post training
pipeline, we, one of the steps is you want to do some DPO, and you use a lot of output
provided models to improve your preference model.
So it's really having like an open sort of ecosystem benefits and accelerates the development
of open models.
One thing that we got in 2024, which is not a specific model, but I thought it was really
significant is we first got our first open source AI definition.
So this is from the open source initiative, they've been generally the steward of a lot
of the open source licenses when it comes to software, and so they imparting this journey
and trying to figure out, okay, how does a license, an open source license for a model
look like?
Georgia, the work is very dry because licenses are dry, so I'm not going to walk through
the license step by step, but I'm just going to pick out one aspect that is very good,
and then one aspect that person feels like needs improvement.
On the good side, this open source AI license actually, this is very intuitive.
If you have a built open source software and you have some expectation around like what
open source looks like for software, for AI, sort of matches your intuition.
So the weights need to be freely available, the code must be released with an open source
license, and there shouldn't be like license clauses that block specific use cases.
So under this definition, for example, llama or some of the quen models are not open source,
because the license says you can't use this model for this, or it says if you use this
model, you have to name the output this way, or derivative needs to be named that way.
Those clauses don't meet open source definition, and so they will not be covered, the llama
license will not be covered under the open source definition.
It's not perfect.
One of the things internally, in discussion with OSI, we were sort of disappointed, is
around the language for data.
So you might imagine that an open source AI model means a model where the data is freely
available, we're discussion around that, but at the end of the day, they decide to go with
a soften stance, where they say a model is open source if you provide sufficient detail
information on how to sort of replicate the data pipeline, so you have an equivalent system.
Sufficiently detailed, it's very fuzzy, don't like that.
An equivalent system is also very fuzzy.
And this doesn't take into account the accessibility of the process, right?
It might be that you provide enough information, but this process costs, I don't know, ten
million dollars to do.
Now the open source definition, like any open source license, has never been about accessibility,
so that's never factor in open source software, how accessible software is.
I can make a piece of open source, put it on my hard drive, and never access it.
A software is still open source, the fact that it's now widely distributed doesn't change
the license, but practically there are expectations of what we want good open sources to be,
so it's kind of sad to see that the data component in this license is not as open as
some of us would like it to be, and a link to blog post underneath and wrote on the topic
that it's less friendly and easier to follow through.
One thing that in general, I think it's fair to say about the state of open models in
2024 is that we know a lot more than what we knew in 2023, like both on the training
data, like in the pre-training data, you curate on how to do all the post-training, especially
like on the RL side, 2023 was a lot of like throwing random darts at the board, in 2024
we have clear recipes that okay, don't get the same results as a closed lab because there
is a cost in actually matching what they do, but at least we have a good sense of like
okay, this is the path to get state of ER language model.
I think that one thing that it's a downside of 2024 is that I think we are more resource
constrained than 2023.
It feels like the barrier for compute that you need to move innovation along as just
being rising and rising, so like if you go back to this slide, there is now this cluster
of models that are sort of released by the compute rich club.
Membership is hotly debated, you know, can people don't want to be called rich because
it comes to expectations and people want to be called rich, but I don't know, there's
debate.
But like these are players that have 10,000, 50,000 GPUs at minimum, and so they can do
a lot of work and a lot of exploration and improving models that it's not very accessible.
To give you a sense of like how I personally think about research budget for each part
of the language model pipeline is like on the pre-training side, you can maybe do something
with 1,000 GPUs, really you want 10,000, and like if you want real estate of the arch,
you know, your deep seek at minimum is like 50,000, and you can scale to infinity, the
more you have the better it gets, everyone on that side still complains that they don't
have enough GPUs.
Post-training is like super wide sort of spectrum.
You can do this little with like eight GPUs, as long as you're able to run, you know, a
good version of say a llama model, you can do a lot of work there.
You can scale, a lot of the methodology just like scales with compute, right?
If you're interested in, you know, your open replication of what OpenAI's O1 is, you're
going to be on the 10K spectrum of our GPUs.
Inference, you can do a lot with very few resources, evaluation, you can do a lot with,
well, I should say at least one GPUs if you want to evaluate open models, but in general,
like if you care a lot about intervention to do on this model, which is my preferred
area of research, then, you know, the resources that you need are quite significant.
Another trend that has emerged in 2024 is this cluster of fully open models, so OMO, the
model that we build, AI2 being one of them.
And you know, it's nice that it's not just us, there's like a cluster of other mostly
research efforts who are working on this.
And so it's good to give you a primer of what like fully open means.
So fully open, the easy way to think about it is instead of just releasing a model checkpoint
that you run, you release a full recipe.
So the other people working on it, working on that space, can pick and choose whatever
they want from your recipe and create their own model or improve on top of your model.
You're giving out the full pipeline and all the details there, instead of just like the
end output.
So I pull up this screenshot from our recent MOE model, and like for this model, for example,
we released the model itself, the data that was trained on, the code, both for training
and inference, all the logs that we got through the training run, as well as every intermediate
checkpoint.
And like the fact that you release different part of a pipeline allows others to do really
cool things.
So for example, this tweet from early this year from Fox and News Research, they use our
pre-training data to do a replication of the bitmap paper in the open.
So they took just really the initial part of a pipeline and then did the thing on top of
it.
It goes both ways.
So for example, for the OMOTU model, a lot of our pre-training data for the first stage
of pre-training was from this DCLM initiative that was slide by folks, a variety of institutions,
a really nice group effort, but for when it was nice to be able to say, okay, the state
of the art in terms of like what is done in the open as improved, we don't have to like
do all this work from scratch to catch up to state of the art, we can just take it directly
and integrate it and do our own improvements on top of that.
I'm going to spend a few minutes doing a shameless plug for some of our fully open recipes.
So indulge me in this.
So a few things that we released this year was, as I was mentioning, this OMOTU model,
which I think still is state of the art OMOTU in its size class and it's also fully open.
So I have a component of this model available.
We released a multimodal model called MoMo.
MoMo is not just a model, but it's a full recipe of how you go from a tax-only model
to a multimodal model and we apply this recipe on top of quenchack points on top of OMOT
checkpoints, as well as on top of OMOTU.
And I think they've been replication doing that on top of Mistroll as well.
On the post-training side, we recently released TULU3.
Same story, this is a recipe on how you go from a base model to a state-of-the-art post-training
model.
We use the TULU recipe on top of OMOT, on top of llama, and then it's been open a replication
effort to do that on top of quench as well.
It's really nice to see when your recipe, it's kind of turnkey, you can apply it to
different models and it kind of just works.
And finally, the last thing we released this year was OMOTU, which so far is the best state
of the art, fully open language model.
It sort of combines aspect from all three of these previous models, what we learn on
the data side from OMOTU and what we learn on making models that are easy to adapt from
the mobile project and the TULU project.
I will close with a little bit of reflection, like, ways this ecosystem of open models is
not all roses, it's not all happy, it feels like day to day, it's always imperial.
And I talked a little bit about the compute issues that come with it, but it's really
not just compute.
One thing that is on top of my mind is due to the environment and how growing feelings
about our AI is treated, it's actually harder to get access to a lot of the data that was
used to train a lot of the models up to last year.
So this is a screenshot from really fabulous work from Shane Longpre, who I think is a
new rep about just access, like diminishing access to data for language model pre-training.
So what they did is they went through every snapshot of common crawl.
Common crawl is this publicly available scrape of a subset of the internet.
And they looked at how, for any given website, where the website that was accessible in 2017,
whether it was accessible or not in 2024.
And what they found is as a reaction to like the close, like the existence of close models,
like OpenAI or Cloud, GPT or Cloud, a lot of content owners have blanket blocked any
type of crawling to their website.
And this is something that we see also internally at AI2, like one project that we started this
here is we want to understand like if you're a good citizen or the internet and you crawl
following sort of norms and policy that have been established in the last 25 years, what
can you crawl?
And we found that there's a lot of website where the norms of how you express preference
of whether to crawl or that are not are broken.
A lot of people would block a lot of crawling, but do not advertise that in Robost.txt.
You can only tell that they're crawling, that they're blocking you and crawling when you
try doing it.
Sometimes you can't even crawl the Robost.txt to check whether you're allowed or not.
And then a lot of websites, there's like all these technologies that historically have
been existed to make websites serving easier, such as Cloudflow around DNS.
They're now being repurposed for blocking AI or any type of crawling in a way that is
very opaque to the content owners themselves.
So you go to this website, you try to access them and they're not available and you get
a feeling it's like oh something changed on the DNS side that it's blocking this and
likely the content owner has no idea, they're just using Cloudflare for better load balancing
and this is something that was sort of sprung on them with very little notice.
And I think the problem is this blocking or it really impacts people in different ways.
This proportionally helps companies that have a Head Start, which are usually the close
labs and it hurts incoming newcomer players, where you either have now to do things in a
sketchy way or you're never going to get that content that the close lab might have.
So there's a lot of coverage, I'm going to plug Nathan's blog post again, I think the
title of this one is very succinct, which is like we're actually not, you know, before
thinking about running out of training data, we're actually running out of open training
data and so if one better open models, they should be on top of our mind.
The other thing that has emerged is that there's strong lobbying efforts on trying to define
any kind of open source AI as like a new, extremely risky danger.
And I want to be precise here, the problem is not not considering the risk of this technology,
every technology has risk that should always be considered.
The thing that it's like to me is sort of ingenious is like just putting this AI on
a pedestal and calling it like an unknown alien technology that has like new and undiscovered
potentials to destroy humanity.
When in reality, all the dangers, I think, are rooted in dangers that we know from existing
software industry or existing issues that come with one using software on a lot of sensitive
domains like medical areas and it also knows a lot of efforts that have actually been going
on and trying to make this open model safe.
I pasted one here from AI2 but there's actually like a lot of work that has been going on
and I'm like, okay, how do you make, if you're distributing this model openly, how do you
make it safe, what's the right balance between accessibility of open models and safety.
And then also there's annoying brushing of concerns that are then proved to be unfounded
under the rug.
You know, if you remember at the beginning of this year, it was all about by your risk
of these open models.
The whole thing fizzled out because it's been finally there's been like rigorous research,
not just this paper from cohere folks, just being rigorous research showing that this
is really not a concern that we should be worried about.
Again, there is a lot of dangerous use of AI application but this one was just like a
lobbying ploy to just make things sound scarier than they actually are.
So I got a preface, this part says this is my personal opinion, it's not my employer,
but I look at things like the SBE 1047 from California and I think we kind of dodge a
bullet on this legislation.
The open source community, a lot of the academic community came together at the last sort of
the last minute and did a very good effort trying to explain all the negative impact
of this bill.
But there's like, I feel like there's a lot of excitement on building these open models
or like researching on these open models and lobbying is not sexy.
It's kind of boring, but it's sort of necessary to make sure that this ecosystem can really
thrive.
This end of presentation, I have some links, emails, sort of standard thing in case, and
you even want to reach out and the folks have questions or anything they wanted to discuss
sort of open floor.
I'm very curious how we should build incentives to build open models.
Is your opinion on how we should better align incentives in the community so that open models
stay open?
The incentive bit is really hard.
It's something that actually even we think a lot about it internally, because building open
models is risky, it's very expensive, and so people don't want to take risky bets.
I think definitely the challenges, like our challenge, I think those are like very valid
approaches for it.
And then, I think in general promoting building still, any kind of effort to participating
in this challenge, if we can provide doing that on top of open models and sort of really
lean into this multiplier effect, I think that is a good way to go.
If there were more money for efforts, like research efforts around open models, there's
a lot of, I think there's a lot of investments in companies that at the moment are releasing
their model in the open, which is really cool, but it's usually more because of commercial
interest and not wanting to support this open models in the long term.
It's a really hard problem, because I think everyone is operating in what, everyone is
at their local maximum rate, in ways that really optimize their position on the market.
The global maximum is harder to achieve.
Can I ask one question?
So I think one of the gaps between the closed and open source models is the multilinguality.
So the closed source models like JHPT works pretty good on the low resource languages,
which is not the same on the open source models, right?
So visiting your plan to improve on that space?
I think in general, yes is, I think it's, I think we'll see a lot of improvements there
like kind of on the side, like there's groups like focusing on the smaller side, there already
what is going on, like better calls for multilingual support, I think where I'm trying this very
able to really want to be experts who are actually meeting those countries, those people
explain which is, you know, participate in that country.
I think it's like a very easy example, I'm originally from Italy, I think I'm terribly
equipped to build a model that works for Italian.
Because what I think you need to be able to do is having a knowledge of like, okay, how
do I access, you know, libraries or content that it is, from the street to their colors
because I mean, in the US long enough, they're no longer gone.
So I think that the experts at the folks at the frontier, for example, are doing, around
like, okay, let's not include regional communities, we just get access, you know, to bring into
collaboration, from the lowest area, meeting some of the people, like, very crucial or
get modest.
Hello everyone.
Yeah, I'm super excited to be here to talk to you guys about Mistral.
I'm really short and quick recap of what we have done, what kind of models and products
we have released in the past a year and a half.
So most of you have already known that we are a small startup, funded about a year and
a half ago in Paris, in May, 2033, it was funded by three of our co-founders.
And in September 2033, we released our first open source model, Mistral 7B.
Yeah, how many of you have used or heard about Mistral 7B?
Hey, pretty much everyone.
Thank you.
Yeah, it's our pretty popular and community, our community really loved this model.
And in December 2033, we released another popular model with the MLE architecture, Mistral 8X7B.
And oh, going into this year, you can see we have released a lot of things this year.
First of all, in February, 2004, we released Mistral Small, Mistral Large, LaShat, which
is our chat interface.
I'll show you in a little bit, we released an embedding model for converting your text
into embedding vectors.
And all of our models are available, the cloud resources.
So you can use our model on Google Cloud, AWS, Azure, Snowflake, IBM.
So very useful for enterprise who wants to use our model through cloud.
In April and May this year, we released another powerful open source MLE model, AX20UB.
And we also released our first code model, Coastal, which is amazing at 80 plus languages.
And then we provided another fine-tuning service for customization.
So because we know the community love to fine-tune our models.
So we provide you a very nice and easy option for you to fine-tune our model on our platform
and also we released our fine-tuning code base called Mistral Fine 2, it's open source.
So feel free to take a look.
And more models on July to November this year, we released many, many other models.
First of all, it's the two new best small models.
We have Mistral 3B, great for deploying on edge devices.
We have Mistral 8B, if you used to use Mistral 7B, Mistral 8B is a great replacement with
much stronger performance than Mistral 7B.
We also collaborated with NVIDIA and open-sourced another model, Nemo 12B, another great model.
And just a few weeks ago, we updated Mistral Large with the version 2 with the updated state
of our features and really great at function-calling capabilities, it's supporting function-calling
and they tip me.
And we released two multi-modal models, pixstral 12B, it's open source and pixstral large.
Just amazing models for not understanding images but also great at text on our standings.
So yeah, a lot of the image models are not so good at text on our standings but pixstral
large and pixstral.
12B are good at both image on our standings and text on our standings.
And of course, we have models for research.
Coastal Mamba is built on Mamba architecture in Mathral, working with math problems.
So yeah, that's another model.
Here's another view of our model offerings.
We have several premier models, which means these models are mostly available through
our API.
I mean, all of the models are available throughout our API, except for Minister 3B.
But for the premier model, they have a Spatial License Mistral Research License.
You can use it for free, for exploration, but if you want to use it for enterprise,
for production use, you will need to purchase a license from us.
So on the top row here, we have Minister 3B and AB as our premier model.
Mr. Small, for best low latency use cases, Mr. Large is great for your most sophisticated
use cases.
Pixel Large is the frontier class multimodal model and we have Coastal for great for coding
and then again, Mr. embedding model.
And the bottom of the slides here, we have several Apache 2.0 licensed open-weight models
free for the community to use.
And also, if you want to fine-tune it, use it for customization, production, feel free
to do so.
The latest we have PIXTRO 12B.
We also have Mr. Nemo, Mom, Coastal Mamba, and Mastro as I mentioned.
And we have three Lexi models that we don't update anymore, so we recommend you to move
to our newer models if you are still using them.
And then just a few weeks ago, we did a lot of improvements to our code interface, LaShette.
How many of you have used LaShette?
Oh no, only a few.
Okay, I highly recommend LaShette is chat.mystrol.ai.
It's free to use.
It has all the amazing capabilities I'm going to show you right now.
But before that, LaShette in French means cat.
So this is actually a cat logo.
Yeah, if you can tell, this is a cat eyes.
Yeah, so first of all, I want to show you something, maybe let's take a look at image
understanding.
So here I have receipts and I want to ask that I'm just going to get the prompts.
Cool.
So basically, I have a receipt and I said I ordered a coffee and a sausage.
How much do I add 18% tip?
So hopefully it was able to get the cost of the coffee and the sausage and ignore the
other things.
And yeah, I don't really understand this, but I think this is coffee.
It's yeah, dying, yeah.
And then cost of the sausage, we have 22 here, yep.
And then it was able to add the cost, calculate the tip and all that.
Great.
So it's great that image understanding is great at OCR tasks.
So if you have OCR tasks, please use it as free on the chat.
It's also available throughout API and also I'm going to show you a canvas example.
A lot of you may have used cameras with other tools before, but with the shot is completely
free again.
Here I'm asking it to create a canvas that's used by script to execute Python in my browser.
Let's see if it works, import this, oh, yep.
Okay.
So yeah, so basically it's executing Python here, exactly what do we want it.
And the other day I was trying to ask the last chat to create a game for me.
Let's see if we can make it work.
Yeah, the Tetris game.
Yeah, let's just get one row, maybe, ah, oh no, okay, all right.
You get the idea.
I failed my mission.
Okay, here we go.
Yay, cool, yeah, so as you can see, like, I can write like a code by code.
It's about a simple game pretty easily, and you can't ask for a shot to explain the code,
make updates, however you like.
Another example, there's a bar here, I want to move, okay, right, okay.
And let's go back to another one.
Yeah, we also have web search capabilities, like you can ask what's the latest.
I use image generation, it's pretty cool, generate an image about researchers in Vancouver.
Yeah, it's Blackboard Slaps, FlexPro, again, this is free, so, oh, cool.
I guess researchers here are mostly from University of British Columbia, that's smart.
Yeah, so this is a lot, yeah, I, please feel free to use it, and let me know if you have
any feedback, we're always looking for improvement, and we're going to release a lot more powerful
features in the coming years, thank you.
Okay, maybe, maybe, maybe you guys in New York now.
Yeah, hi everyone, thank you so much for coming today.
Huge shout out to SWIX and the Layton Space Team, I think it's been a great, yeah, let's
just give it up for SWIX, just real quick.
I did a little bit in terms of helping with the planning, but I work at Notable Capital,
some of you may have heard of GGV, which was our former name, on the cloud infrastructure
team.
Basically, anything, data, DevTools, AI infrastructure, as well as AI applications, and so we like
to stay close to those that are smarter than us, which is all of you in this room.
So if anyone ever wants to, you know, brainstorm, or thinking about starting a company, we're
happy to collaborate, we've had the opportunity to partner with like amazing companies such
as HashiCorp, Vercel, Neon, and many others over the years, and we're based in San Francisco
and New York, so yeah, feel free to find me, Laura Hamilton, X, LinkedIn, you know, if
we become friends, Instagram, yeah, thank you all for coming, and then we'll kick off
some of the chats with AWS after everyone gets lunch, all right.
[MUSIC]

