
If 2025 is the year of agents, then the 2020s are the decade of deep, while LLM powered search
is as old as perplexity and search GPT, and open source projects like GPT researcher and
clones like Open Deep Research exist, the difference with commercial deep research products
is they are both agentic and bundling custom-tuned frontier models like OpenAI's 03, or as today's
guests discuss, a fine-tuned version of Gemini. Since the launch of OpenAI's deep research
on February 2, the reactions have been nothing short of breathless. "Deep research is the
best public-facing AI product Google has ever released. It's like having a college-educated
researcher in your pocket," end quote from Jason Calacanis. Quote, "I have had deep research
write a number of 10-page papers for me, each of them outstanding. I think of the quality
as comparable to having a good PhD level research assistant and sending that person away with
a task for a week or two or maybe more. Except deep research does the work in five or six
minutes." End quote from Tyler Calan. Quote, "Deep research is one of the best bargains
in technology." End quote from Ben Thompson. Quote, "My very approximate vibe is that it
can do a single digit percentage of all economically valuable tasks in the world, which is a wild
milestone." End quote from Sam Altman. Since then, a dozen open and closed source clones
have emerged from the woodwork trying to replicate this success, from perplexity to x.ai with
their Grock 3 launch late yesterday. In today's episode, we welcome Arish Selvan
and Mukhan Sridhar, the lead PM and tech lead for Gemini Deep Research, the originators
of the entire category of deep research agents which have overnight become the newest killer
use case for AI. We asked detailed questions from inspiration to implementation, why they
had to fine tune a special model for it instead of using the standard Gemini model, how to
run evils for them and how to think about the distribution of use cases. Arish and Mukhan
will also be joining us as keynote speakers for the Agents Engineering track at the AI
Engineer Summit in New York City on February 21. This is our last in our recent series
of upcoming AI Engineer Summit speakers and we hope you are as excited for their talks
and workshops as we are. You can sign up for the online live stream linked in the show
notes. See you at the summit. Watch out and take care.
Hey everyone, welcome to the Lead in Space podcast. This is Arishio, partner and CTO
that's about partners and I'm joined by my cohost Swix, founder of Smollei AI.
Hey and today we are very honored to have in our studio Arishio Mukhan from the Deep Research
team, the OG Deep Research team. Welcome. Thanks for having us.
Thanks for making a trip up. I was fortunate enough to be one of the early beta testers
of Deep Research where he came out and I was very keen on even at the end of last year
people already saying it was one of the most exciting agents that was coming out of Google,
you know that previously we had on Ryza and Usama from the Novokalem team and I think
like this is like an increasing trend that like Gemini and Google are shipping interesting
user facing products that use AI. So congrats on your success so far.
Yeah, it's been great. Thanks so much for having us here. Yeah, excited.
Yeah, thanks for making a trip up and I'm also excited for your talk that is not happening
next week. Obviously we have to talk about what exactly it is. I'll ask you towards
the end. But so basically, okay, you know, we have to screen up. Maybe we would just start
at a high level for people who don't yet know, like what is Deep Research?
Sure. So Deep Research is a feature where Gemini can act as your personal research assistant
to help you learn about any topic that you want more deeply. It's really helpful for
those queries where you want to go from zero to 50 really fast on a new thing. And the
way it works is it takes your query, browsers the web for about five minutes, and then outputs
a research report for you to review and ask follow up questions.
This is one of the first times, you know, something takes about five, six minutes trying
to perform your research. So there's a few challenges that brings like you want to make
sure you're spending that time in the computer doing what the user wants. So there's some
ways of the UX design that we can talk about as we go through an example. And then there's
also challenges in the browsers, the web is super fragmented and being able to plan iteratively
and as you pass through this noisy information as a challenge by itself.
Yeah, this is like the first time sort of Google automating yourself as searching. Like
you're supposed to be the experts at search, but now you're like meta searching and like
determining the search strategy.
Yeah, I think at least we see it as two different use cases. There are things that, you know,
exactly what you're looking for. And there's such a still probably, you know, a very, you
know, probably one of the best places to go. I think where deeply such really shines is
there like multiple facets to your question and you spend like a weekend, you know, just
opening like 50, 60 tabs and many times I just give up and we wanted to solve that problem
and give a great starting point.
Do you want to start a query so that it runs in the meantime and then we can chat over it?
Okay, here's one query that we like, we love to test like super niche random things like
things where there's like no Wikipedia page already about this topic or something like
that, right? Because that's where you'll see the most lift from from a feature like this.
So for this one, I've come I've come come up with this query. This is actually Morgan
Square that he's he loves to test is help me understand how milk and meat regulations differ
between the US and Europe.
What's nice is the first step is actually where it puts together a research plan that
you can review. And so this is sort of its guide for how it's going to go about and
carry out the research, right? And so this was like a pretty decently well specified
query, but like let's say you came to Gemini and were like, tell me about batteries, right?
That query, you could mean so many different things. You might want to know about the like
latest innovations in battery tech, you might want to know about like a specific type of
battery chemistry. And if we're going to spend like five to even 10 minutes researching
something, we want to one, understand what exactly are you trying to accomplish here.
And to give you an opportunity like to steer where the research goes, right? Because like
if you had an intern and you asked them this question, the first thing they do is ask you
like a bunch of follow up questions and be like, okay, so like, help me figure out exactly
what you want me to do. And so the way we approached it is we thought like, why don't
we just have the model produce its first stab at the at the research query at how it would
break this down and then invite the user to come and kind of engage with how they would
want to steer this. Yeah. And many times when you try to use a product like this, you often
don't know what questions to look for are the things to look for. So we kind of made
this decision very deliberately that in stuff asking the users just follow up questions
directly, we kind of lay out, hey, this is what I would do. Like these are the different
facets. For example, here it could be like, what additives are allowed and how that differs
or labeling restrictions and so on in products. The aim of this is to kind of tell the user
about the topic a little bit more and also get steered at the same time be elicit for
like, you know, follow up questions and so on. So we did that and I'm trying to edit
a ball chain of thought. Exactly. Exactly. Yeah, I think that, you know, we were talking
to you about like your top tips for using deep research. Yeah, your number one tip is to
edit it. Just edit it. Right. So like we actually, you can actually edit conversationally. We
put in a button here just to like draw users attention to the fact that you can edit this.
Oh, actually, you don't need to click. Yeah, actually, like in early rounds of testing,
we saw no one was editing. And so we were just like, if we just put a button here, maybe
people will like I just hit start a lot. I think like we see that too. Like most people
hit start. Like, it's like the I'm feeling lucky. Yeah. Yeah. All right. So like, I can
just add up add a step here. And what you'll see is it should like refine the plan and
show you a new thing to propose. Here we go. So it's added step seven, find information
and milk and meat labeling requirements in the US and the year. Or you can just go ahead
and hit start. I think it's still like a nice transparency mechanism, even if users don't
want to engage, like you still kind of know, okay, here's at least an understanding of why
I'm getting the report I'm going to get, which is kind of nice. And then while it browses
the web and Morgan, you should maybe explain kind of how it browses. We show kind of the
websites it's reading in real time. Yeah. I'll preface this if I haven't, I forgot to
explain the roles. You're a PM and you're a tech lead. Yes. Okay. Yeah. Just for people
who don't know. Oh, okay. We maybe should have started with that. Yeah. Yeah. We do
each other's work sometimes as well, but more or less. That's the one. Yeah. Yeah. Yeah.
So so what's happening behind the scenes actually is we kind of give this research plan
that is a contract and that you know, has been accepted. But then if you look at the
plan, there are things that are obviously parallelizable. So the model figures out which
of the sub steps that it can start exploring in parallel. And then it primarily uses like
two tools. It has ability to perform searches. And it has abilities to go deeper within, you
know, a particular webpage of interest. Right. And oftentimes it'll start exploring things
in parallel. But that's not sufficient. Many times it has to reason based on information
found. So in this case, it, one of the searches could have led the EU Commission has these
additives banned. It wants to go and check if the FDA does the same thing. Right. So this
notion of being able to read outputs from the previous turn, a ground on that to decide
what to do next. I think was was key. Otherwise you have like incomplete information and your
report becomes a little bit of a like a high level bullet points. So we wanted to go beyond
that blueprint and actually figure out, you know, what are the key aspects here. So yeah,
so this happens iteratively until the model thinks it's finished all its steps. And then
you kind of enter this analysis mode. And here there can be inconsistencies across sources.
You kind of come up with an outline for the report, start generating a draft. The model
tries to revise that by self-critiquing itself, you know, to finalize the prompt, finalize
the report. And that's broadly what's happening behind the scenes.
What's the initial ranking of the websites? So when you first started it, there were 36,
how do you decide where to start? Since it sounds like, you know, the initial websites
kind of carry a lot of way to because then they inform the following.
Yes. So what happens in the initial turns? Again, this is not like a it's not something
we enforce. It's mostly the model making these choices. But typically we see the model exploring
all the different aspects in the in the research plan that was presented. So we kind of get
like a breadth first idea of what are the different topics to explore. And in terms of
which ones to double click on, I think it really comes down to every time you search the model
to get some idea of what the pages and then depending on what pieces of it, sometimes
there's inconsistency. Sometimes there's just like partial information. Those are the ones
that double clicks on. And yeah, you can continually like iteratively search and pause until it
feels like it's done.
Yeah, I'm trying to think about how I would code this. A simple question would be like,
do you think that we could do this with the Gemini API? Or do you have some special access
that we cannot replicate? If I model this with so call of like search, double click, whatever.
Yeah, I don't think we have special access per se. It's pretty much the same model. We
of course have our own post training work that we do. And y'all can also like you know, you
are confined in from the base model and so on.
I don't know that we can do this. I don't know if you had fine-tuning.
Well, if you use our Gemma open source models, you could find you. Yeah. Yeah. So I don't
think there's a special access per se, but a lot of the work for us is first defining these
or that needs to be a research plan and how do you go about presenting that and then a bunch
of post training to make sure, you know, it's able to do this consistently well and with high
reliability and home. Okay, so 1.5 pro with deep research is a special edition of 1.5 pro.
Yes. So it's a post training or a 1.5 pro? It's a post.
This also explains why you haven't just you can't just toggle on 2.0 flash and just
yeah. Right. Yeah. But I mean, I assume you have the data and you know, it should be doable.
Yeah. There's still this like question of ranking. Yeah. Right. And like, oh, it looks like you're
already done. Yeah. Yeah. We're done. We can look at it. Yeah. So let's see. It's put together this
report and what it's done is it sort of broken started with like milk regulation. And then it
looks like it goes into meat probably further down and then sort of covering how the US approaches
this problem of like how to regulate milk comparing and then, you know, covering the EU. And then
yeah, like I said, like going into the meat production. And then it'll also what's nice is it kind of
reasons over like, why are there differences? And I think what's really cool here is like,
it's it's showing that there's like a difference in philosophy between how the US and the EU regulate
food. So the EU like adopts a precautionary approach. So even if there's inconclusive scientific
evidence about something, it's still going to prefer to like ban it. Whereas the US takes
sort of the reactive approach where it's like allowing things until they can be proven to be
harmful. Right. So like, this is kind of nice is that you you also on like get the second order
insights from what it's being put what it's putting together. So yeah, it's kind of nice. It
takes a few minutes to read and like understand everything, which makes for like a quiet period
during a podcast, I suppose. But but yeah, this is this is kind of how it how it looks right now.
Yeah. And then from here, you can kind of keep the usual chat and iterate thing. So this is more
if you were to like, you know, compare it to other platforms, it's kind of like a
anthropic artifact or like a chat GPD canvas, we're like, you have the document on one side and
like the chat on the other and you're working on it. Yeah. This is something we thought a bit about.
And one of the things we feel is like your learning journey shouldn't just stop after the first
report. And so actually, what you probably want to do is while reading, be able to ask follow-up
questions without having to scroll back and forth. And there's like broadly a few different kinds
of follow-up questions. One type is like, maybe there's like a factoid that you want that isn't
in here, but it's probably been already captured as part of the web browsing that it did, right?
So we actually keep everything in context, like all the sites that it's read remain in context.
So if there's a piece of missing information, it can just fetch that. Then another kind is like,
okay, this is nice, but you actually want to kick off more deep researcher. Like I also want to
compare the EU and Asia, let's say in how they regulate milk in me. For that, you'd actually want
the model to be like, okay, this is sufficiently different that I want to go do more deep research
to answer this question. I won't find this information in what I've already browsed. And the third is
actually maybe you just want to like change the report, like maybe you want to like condense it,
remove sections, add sections, and actually like iterate on the report that you got. So we
broadly basically have tried and teach the model to be able to do all three. And the kind of side
by side format allows sort of the user to do that more easily. So as a PM, there's an open end docs
button there, right? How do you think about what you're supposed to build in here versus kind of
sounds like the condensing and things should be a Google Docs. Yeah, bar extensions is different.
It's just like an amazing editor. Like sometimes you just want to direct edit things. And now Google
Docs also has Gemini in the side panel. So the more we can kind of help this be part of
your workflow throughout the rest of the Google ecosystem, the better, right? Like,
and one thing that we've noticed is people really like that button and really like exporting it.
It's also a nice way to just save it permanently. And when you do export all the citations, in fact,
I can just run it now, carry over, which is also really nice. Gemini extensions is a different feature.
So that is really around Gemini being able to fetch content from other Google services
in order to inform the answer. So that was actually the first feature that we both worked on on the
team is actually building extensions in Gemini. And so I think right now we have a bunch of different
Google apps as well as I think Spotify and a couple, I don't know if we have and Samsung apps as well.
Who wants Spotify? I have this whole thing about it.
Like who wants Spotify? I don't know if I want that in a deep research.
In deep research, I think less, but like the interesting thing is like we built extensions
and we didn't, we weren't really sure how people were going to use it. And a ton of people are doing
really creative things with them. And a ton of people are just doing things that they loved on
the Google Assistant. And Spotify is like a huge, like playing music on the go was like a huge
value. Oh, it controls Spotify. Yeah, for deep research. Yeah, yeah, yeah, yeah.
But this is, otherwise, yeah, like you can, you can have Gemini go.
Yeah, you have YouTube maps in search for flash thinking experimental with apps,
the newest, longest model name that has been launched. But like, yeah, I think Gmail is obvious one,
calendars obvious one. Exactly. Those I want. That's probably fine.
Fair enough. Yeah. And obviously, feel free to dive in on your other work. I know you're not
just doing deep research, right? But you know, we're just kind of focusing on deep research here.
I actually have asked for modifications after this first run, where I was like, oh, you stopped.
Like actually, what do you need to keep going? Like what are these other things? And then
continue to modify it. So it really felt like a little bit of a co-pilot type experience, but more
like an agent that would research. I thought it was pretty cool. Yeah, one of the challenges is
currently we kind of let the model decide based on your query, like amongst the three categories.
So some there is there is a boundary there, like some of these things, depending on how deep you
want to go, you might just want a quick answer versus like kick off another deep research.
And even from a UX perspective, I think the panel allows for this notion of, you know,
not every follow-up is going to take you like five minutes. Right now it doesn't do any fall.
Does it do follow-up search? It always does. It depends on your question. Since we have the
liberty of like really long context models, we actually hold all these, all the research
material across dance. So if it's able to find the answer in things that's fun, you're going to
get a faster reply. Yeah, otherwise it's just going to go back to planning. Yeah, yeah. A bit of a
follow-up on since you brought a context, I had two questions. One, do you have an HTML to mark down
transform step, or do you just consume raw HTML? There's no way you consume raw HTML, right?
We have both versions, right? So there is the models are getting like every generation of
models are getting much better at native, native understanding of these representations.
I think the markdown step definitely helps in terms of, you know, there's a lot of nice,
like, as you can imagine, with the pure HTML scripts. So yeah, when it makes sense to do it,
we don't artificially try to make it hard for the model. But sometimes it depends on the
kind of access of what we get as well. Like, for example, if there's an embedded snippet
that's HTML, we want the model to, you know, be able to work on that as well. Yeah, and no vision
yet, but currently, you know, yes. The reason I ask all these things is because I've done the same.
Like I haven't done vision. Yeah, so the tricky thing about vision is I think the models are getting
significantly better, especially if you look at the last six months, natively being able to do,
like, VQA stuff and so on. But the challenge is the trade-off between having to, you know,
actually render it and so on, the gap, the trade-off between the added latency versus
the value add you get. You have a latency budget of... Yeah, yeah, yeah, yeah. It's true.
In my opinion, the places you'll see a real difference is like, like, I don't know, a small
part of the tail, especially in like this kind of an open domain setting. If you just look at what
people ask, there's definitely some use cases where it makes a lot of sense to it. But I still feel
it's not in the head cases. And we do it when we get there. The classic is like, it's a JPEG
that has some important information, and you can't touch it. Yeah. Okay, and then the other
technical follow-up was just you have 1 million to 2 million total context. Has it ever exceeded
2 million? And what do you do there? Yeah, so we had this challenge sometime last year where we said,
when we started, like, wiring up this multi-turn where we said, "Hey,
let's see how long somebody in the team can take DR," you know. Yeah, what's the most challenging
question you can ask that takes the longest? Yeah, no, we also keep doing it. For example,
here, you could say, "Hey, I also want to compare it with how it's done." Okay, so you're guaranteed
to bust it. Yeah, yeah, yeah. We also have, we have retrieval mechanisms if required. So we
natively try to use the context as much as it's available beyond which, you know, we have, like,
a drag setup to figure out. Okay, this is all in house tech. Yes. Okay, yes.
What are some of the differences between putting things in context versus drag? And when I was in
Singapore, I went to the Google Cloud. Well, when I was in Singapore, I went to the Google Cloud
team and they talk about Gemini plus grounding. Is Gemini plus search kind of like Gemini plus
grounding or like, how should people think about the differentiates of, like, I'm doing retrieval
and data versus I'm using deep research versus I'm using grounding? Well, sometimes the labels can
be hard too. Yeah, I can let me try to answer the first part of the question. The second part,
I'm not fully sure of the grounding offering. So I can at least talk about the first part of the
question. So I think you're asking like the difference between like being able to, when would
you do drag versus rely on the low context? I think we all, we all get that. I was more curious,
like, from a product perspective, when you decide to do a rag versus shit. Like this, you didn't need
to, you know, do you get better performance? Yeah. Just putting everything in context or...
The tricky thing for rag, it really works well because a lot of these things are doing like
cosine distance, like a dot product kind of thing. And that kind of gets challenging when your
query side has multiple different attributes. The dot product doesn't really work as well.
I would say, at least for me, that's my guiding principle on when to avoid rag, that's one. The
second one is I think every generation of these models are like the initial generations, even
though they offered like long context, their performance as the context kept growing was,
you would see some kind of a decline. But I think as the new generation models came out,
they were really good, even if you kept filling in the context in being able to piece out like
these really fine-dram information. So I think these two, at least for me, are like guiding principles
on when to... Just to add to that, I think like, just like a simple rule of thumb that we use is like,
if it's the most recent set of research tasks where the user is likely to ask lots of follow-up
questions, that should be in context. But as stuff gets 10 tasks ago, it's fine if that stuff is in
rag because it's less likely that the user needs to do very complex comparisons between what's
currently being discussed and the stuff that you asked about 10 turns ago. So that's just like a
very, like the rule of thumb that we found. And so from a user perspective, is it better to just
start a new research instead of like extending the context? Yeah. I think it's a good question.
I think if it's a related topic, I think there's benefit to continue with this thread because you
could... The model, since it has this in memory, could figure out, "Oh, I've found this niche thing
about, I don't know, milk regulation in this case, in the US, let me check if you're in a
follow-up country or place also has something like that." So these kind of things, you might have not
caught if you started a new thread. So I think it really depends on the use case,
if there's a natural progression and you feel like this is like part of one cohesive kind of a
project, you should just continue using it. My follow-up term is going to be like, "Oh, I'm just
going to look for summer camps or something." Then yeah, I don't think it should make a difference,
but we haven't really pushed that and tested that aspect of it for us. Most of our tests are like
more natural transitions. How do you evaluate deep research? Oh boy, yeah, this is a hard one.
I think the entropy of the output space is so high. It's like people love
moderators, but it brings its own set of challenges. So for us, we have some metrics that we can
auto-generate. So for example, as we move, when we do post-training and have multiple models,
we kind of want to make sure the distribution of certain stats, like for example, how long
is spent on planning, how many iterative steps it does on some dev set. If you see large changes
in distribution, that's kind of like an early signal of something has changed. It could be for
better or worse. So we have some metrics like that that we can auto-compute.
So every time you have a new version, you run it across a test suite of cases, and you see how
long it takes. Yeah, so we have a dev set and we have some kind of automatic metrics that we
can detect in terms of like the behavior end to end. Like for example, how long is there a search
plan? Do we like this? Does a new model produce really longer? Many more steps.
Just a number of characters. Like number of steps in case of the search plan. In the plans,
it could be like we spoke about how it iteratively plans based on like previous searches,
how many steps does that go on an average over some dev set. So there are some things like this
you can automate, but beyond that, there are moderators, but we definitely do a lot of
human events. And there we have defined with product about certain things we care about and
mean super opinionated about is it comprehensive, is it complete, like groundedness and these kind
of things. So it's a mix of these two attributes. There's another challenge, but a lot of you.
Is this where in other challenges that sometimes you just have to have your PM review examples?
And unfortunately, the human human reader, the human reader. But broadly, what we tried to do
in is for the eval question is like, we tried to think about like, what are all the ways in which
a person might use a feature like this? And we came up with what we call an ontology of use cases.
Yes. And really what we what we tried to do is like stay away from like verticals, like travel
or shopping and things like that, but really try and go into like, what is the underlying
research behavior type that a person is doing? So there's queries on one end that are just,
you're going very broad, but shallow, right? Things like shopping queries are an example of that,
or like, I want to find the perfect summer camp. My kids love soccer and tennis. And really,
you just want to find as many different options and explore all the different options that are
available. And then synthesize, okay, what's the TLDR about each one, kind of like those journeys
where you open many, many Chrome tabs, but then like need to take notes somewhere of the stuff
that's appealing. On the other end of the spectrum, you know, you've got like a specific topic,
and you just want to go super deep on that and really, really understand that. And there's like
all sorts of points in the middle, right? Around like, okay, I have a few options, but I want to
compare them or like, yeah, I want to go not super deep on a topic, but I want to cover slightly
more topics. And so we sort of developed this ontology of different research patterns,
and then for each one came up with queries that would fall within that. And then that's sort of
the eval set by which we then run human evals on, and make sure we're trying to doing well across
the board on all of those. Yeah, you mentioned three things. Is it literally three, or is it
three out of like 20 things? How wide is this? I basically just told the full set. Yeah, I told
them. No, no, I told you the like, extremes, right? So like, yeah, and then we had like several
several midpoints. So basically, yeah, going from like something super broad and shallow to
something very specific and deep, we weren't actually sure which end of the spectrum users
are going to really resonate with. And then on top of that, you have compounds of those, right? So
you can have things where you want to make a plan, right? Like a great one is like, I'm going to plan
a wedding in, you know, Lisbon, and I, you know, I need you to help with like these 10 things, right?
And so that becomes like a project with research enabled, right? And so then it needs to research
planners and venues and catering, right? And so there's there's sort of compounds of when you
start combining these different underlying on apology types. And so that we also thought about
that when we when we tried to put put together already, well said, what's the maximum conversation
length that you allow or design for? We don't have any hard limits on the how many turns you can do.
One thing I will say is most users don't go very deep right now. Yeah. It might just be that it
takes a while to get comfortable. And then over time, you start pushing it further and further.
But like right now, we don't see a ton of users. I think the way that you visually present it
suggests that you stop when the doc is created. Right. So you don't actually really encourage,
the UI doesn't encourage ongoing chats that as though it was like a project.
Right. I think I think there's definitely some things we can do on the UX side to basically
invite the user to be like, Hey, this is the starting point. Now let's keep going together.
Like, where else would you like to explore? So I think there's definitely some some
explorations we could do there. I think the in terms of sort of how deep I don't know,
we've seen people internally just really put this here to quite, quite.
I think the other thing I think will change with time is people kind of uncovering
different ways to use deep research as well. Like for the wedding planning thing, for example,
it's not one of the, you know, first thing that comes to mind when we tell people about this product.
So that's another thing I think as people explore and find that this can do these various different
kinds of things. Some of this can naturally lead to longer conversations. And even for us, right,
when we docked footed this, we saw people use it in like face we hadn't really thought of before.
So that was because this was like a little new, like we didn't know, like we'll use this wait
for five minutes. What kind of tasks will are they, you know, going to try for something like that
takes five minutes? So our primary goal was not to specialize in, you know, in a particular vertical
or or target one type of user. We just wanted to put this in the hands of like, like we had like
this busy parent persona and like wait is different user profiles and and see like what people try
to use it for and learn more from that. And how does the ontology of the DR use case
type back to like the Google main product use cases? So you mentioned shopping is one ontology,
right? There's also Google shopping. Yeah. To me, this sounds like a much better way to do
shopping. They're going on Google shopping and looking at the the wall of items. How do you
collaborate internally to figure out where I goes? Yeah, that's a good question. So when I meant
like shopping, I sort of tried to boil down underneath what exactly is the behavior and that's
really around like, I called it like options exploration, like you just want to be able to see.
And whether you're shopping for summer camps, or shopping for a product, or shopping for like
scholarship opportunities, it's sort of the same action of just like, I need to curate from a large,
like I need to sift through a lot of information to curate a bunch of options for me. So that's
kind of what we tried to distill down rather than like thinking about it as a vertical.
But yeah, Google searches is like awesome. If you want to have really fast answers,
you've got high intent for like, I know exactly what I want. And you want like super up to date
information, right? And I still do kind of like Google shop, because it's like multimodal,
you see the best prices and stuff like that. I think creating a good shopping experience
is hard, especially like, when you need to look at the thing, if I'm shopping for shoes,
and like, I don't want to use deep research, because I want to look at how the shoes look.
But if I'm shopping for like HVAC systems, great, like, I don't care how it looks, or I don't even
know what it's supposed to look like. And I'm fine using deep research, because I really want
to understand the specs and like, how exactly does this work and the voltage rating and stuff
like that, right? So like, and I need to also look at contractors who know how to install each HVAC
system. So I'd say like, where we really shine when it comes to shopping is those that kind of
end of the spectrum of like, it's more complex, and it matters less what it like, it's maybe less
on the consumer side of shopping. One thing I've also observed just about the, I guess the metrics
or like the communication of what value you provide. And also this goes into a latency budget,
is that I think there's a professor's incentives for research agents to take longer and be perceived
to be better, to people are like, Oh, you're, you're searching like 70, 70 websites for me, you know,
but like 30 of them are irrelevant, you know, like, I feel like right now we're in kind of a
honeymoon phase where you get a password all this, but being inefficient is actually good for you,
because, you know, people just care about quantity and not quality, right? So they're like, Oh, this
thing took an hour for me, like is doing so much work, like, or it's slow.
That was super counterintuitive for us. So actually, the first time I realized that,
what you're saying is when I was talking to Jason Calacanis, and he was like,
do you actually just make the answer in 10 seconds and just make me wait for the balance? Yeah,
which we hadn't expected that people would actually value the like work that it's putting in,
because he's actually worried about it. We were really worried about it. We were like,
I remember we actually built two versions of deep research. We had like a hardcore mode
that takes like 15 minutes. And then what we actually shipped is a thing that takes five minutes.
And I even went to end and I was like, that has to be a hard stop, by the way,
it can never take more than 10 minutes. Yep, because I think at that point, like users will
just drop off. Nope. But what's been surprising is like, that's not the case at all. And it's been
going the other way, because when we worked on Assistant, at least, and other Google products,
the metric has always been if you improve latency, like all the other metrics go up,
like satisfaction goes up, retention goes up, all of that, right?
And so when we pitch this, it's like, hold on, in contrast to like all Google Orthodoxy,
we're actually going to slow everything right down. And we're going to hope that like users
still stay on purpose. Not on purpose. Yeah, I think it comes down to the trade-off like,
what are you getting in return for the wait? And from an engineering slash modeling perspective,
it's just trading off inference, compute, and time to do two things, right? Either to explore
more, to be like more complete, or to verify more on things that you probably know already.
And since it's like a spectrum and we don't claim to have found the perfect spot,
we had to start somewhere and we're trying to see where, like there's probably some cases where
you actually care about verifying more than the others in an ideal world based on the query and
conversation history, you know what that is. So I think, yeah, it basically boils down to these
three things. From a user perspective, am I getting the right value add? From an engineering slash
modeling perspective, are we using the compute to either explore effectively and also verify and
go in depth for things that are vague or uncertain in the initial steps? The other point about the
more number of websites, I think, again, it comes with a trade-off. Like, sometimes you want to
explore more early on before you kind of narrow down on either of the sources or the topics you
want to go deep. So that's one of the, if you look at like the way, at least for most queries,
the way deep research works here is initially it will go broad. If you look at the kinds of
websites, it's time to explore all the different topics that we measured in the research plan,
and then you would see choices of websites getting a little bit narrower on a particular topic,
or a particular entity that it has come across and so on. So that's roughly how the number
kind of fluctuates. So if you don't do anything deliberate to either keep it low or, you know,
try to... Would it be interesting to have an explicit toggle for amount of verification
versus amount of search? I think so. I think, like, users would always just hit that toggle.
I think, I worry that, like, makes everything... Yeah, if you, like, give a max power button,
users are always just going to hit that button, right? So then the question comes, like, why don't
you just decide from the product POV, where's the right balance? OpenAI has a preview of this,
like, I think it's either an orthopedic or openAI, and there's a preview of this model routing feature
where you can choose intelligence, cheapness, and speed. But then they're all zero to one values,
so then you just choose one for everything, right? Obviously they're going to, like, do a normalization
number thing, but users are always going to want one, right? We've discussed this a bit. Like,
if I have my pure user hat, I don't want to say anything. Like, I come with a query,
you figure it out. Like, sometimes I feel like there will be based on the query. Like, for example,
right? If I'm asking about, "Hey, how does rising rates from the Fed house ordering come from a
middle class, and how has it traditionally happened?" These kind of things, you want to be very accurate,
and you want to be very precise on historical trends of this, and so on, and so on.
Whereas there is a little bit more leeway when you're saying, "Hey, I'm trying to find
businesses near me to go celebrate my birthday," or something like that. So, in an ideal world,
we kind of figure that trade-off based on the conversation history and the topic.
I don't think we are there yet as a research community, and it's an interesting challenge,
right? So, this reminds me a little bit of the notebook alarm approach. We also asked this
thing to rise, and she was like, "Yeah, just people want to click a button and see magic."
Yeah, like you said, you just hit start every time, right? Most people don't even...
My feedback on this, if you want feedback, is that I am still kind of a champion for Devon,
in a sense that Devon will show you the plan while it's working the plan, and you can say,
"Hey, the plan is wrong," and I can chat with it while it's still working.
Anyway, live update the plan and then pick off the next item on the plan.
I think it's static, right? While you're working on a plan, I cannot chat.
It's just normal. Bolt also has this. That's the most default experience,
but I think you should never lock the chat. You should always be able to chat with the plan
and update the plan, and the plan scheduler, whatever orchestration system you have under the hood.
You should just pick off the next job on the list. That would be my two cents.
Especially if we spend more time researching, because right now, if you watched that query,
we just did. It was done within a few minutes, so your opportunity to chime in
was actually... Or it left the research phase after a few minutes, so your opportunity to chime
in and steer was less. But especially imagine you could imagine a world where these things take
an hour and you're doing something really complicated. Then, yeah, your intern would
totally come check in with you, be like, "Here's what I found. Here's some hiccups I'm running
into the plan. Give me some steer on how to change that, or how to change direction,
and you would do that with them." So, I totally would see, especially as these tasks get longer,
we actually want the user to come engage way more to create a good output.
I guess Devin had to do this because some of these jobs take hours.
Right. So, yeah. And it's perverse in senses where they charge by hour.
So, they make more money the slower they are. I'm calling this out because everyone is like,
"Oh my god, it takes hours. It does always work autonomously for me." And they are like,
"Okay, it's good." But this is a honeymoon phase. At some point, we're going to say like,
"Okay, but it's very slow." Anything else that, I mean, obviously within Google, you have a lot of
other initiatives. I'm sure you sit close to the Notebook L.M. team in any learnings that are
coming from shipping AI products in general. They are really awesome people. They are really nice,
friendly, thought. Just like as people, I'm sure you met them and realized this with Razer and
stuff. So, they've actually been really cool collaborators or just people to bounce ideas off.
I think one thing I found really inspiring is they just picked a problem and hindsight is 2020,
but in advance, just like, "Hey, we just want to build the perfect IDE for you to do work,
and be able to upload documents and ask questions about it, and just make that
really, really good." And I think we were definitely really inspired by their vision of just like,
"Let's pick up a simple problem, really go after it, do it really, really well, and have
be opinionated about how it should work, and just hope that users also resonate with that."
And that's definitely something that we tried to learn from.
Separately, they've also been really good at, and maybe Morgan, you want to chime in here,
just extracting the most out of Gemini 1.5 Pro, and they were really friendly about just like
sharing the ideas about how to do that. Yeah, I think you learn a bit like when you're trying to
do the last mile of these products and pitfalls of any given model and so on.
So, yeah, we definitely have a healthy relationship, and I'm trying not to sign it.
Like you're doing the same for other products. You will never merge, right? It's just different
teams. They are different teams. So, they're in like labs as an organization that the mission
of that is to really explore kind of different bats and explore what's possible.
Even though, I think there's a paid plan for Nopokalum now.
Yeah, and it's the same plan as us, actually. So, it's more than just the labs, is what I'm saying.
It's more than just labs, because, I mean, yeah, ideally you want things to graduate
and stick around. But hopefully, one thing we've done is
not create a different skews, but just being like, "Hey, if you pay the playground school."
Yeah, whatever you get, you get everything.
The thing.
What about learning from others? Obviously, I mean, opening ISD for research,
literally, that's the same name. I'm sure there's a lot of contention.
Is there anything you've learned from other people trying to build similar tools?
Like, do you have opinions on maybe what people are getting wrong that they should do differently?
It seems like from the outside, a lot of these products look the same.
Ask for a research, get back a research, but obviously, when you're building them,
you understand it once is a lot more.
When we built deep research, I think there was a few things that we took a few different bets
around how this should work and what's nice is some of that is actually where we feel like
was the right way to go. So, we felt like agents should be transparent around telling you upfront,
especially if they're going to take some time, what they're going to do. So, that's really
where that research plan, we showed that in a card. We really wanted to be very publisher
forward in this product. So, while it's browsing, we wanted to show you all the websites it's reading
in real time, make it super easy for you to double click into those while it's browsing.
And the third thing is putting it into a side-by-side artifact so that you could
ideally easy for you to read and ask at the same time. And what's nice is, as other products come
around, you see some of these ideas also appearing in other iterations of this product.
So, I definitely see this as a space where everyone in the industry is learning from each other
good ideas get reproduced and built upon. And so, yeah, we'll definitely keep iterating on
and kind of following our users and seeing how we can make our feature better. But yeah, I think
it's like, this is the way the industry works. It's like everyone's going to kind of see good
ideas and want to replicate and build off of it. And on the model side, opening IS-03 model,
which is not available through the API, the full one, have you tried already with the
two model? Is it a big jump or is a lot of the work on the post-training?
Yeah, I would say stay tuned. Definitely, it currently is running on 1.5. The new generation
models, especially with these thinking models, they unlock a few things. So, I think one is obviously
the better capability in analytical thinking, like in math, coding, and these type of things.
But also this notion of, as they produce thoughts and think before taking actions,
they kind of inherently have this notion of being able to critique them, the partial steps that
they take, and so on. So, yeah, we're definitely exploring multiple different options to make
better value for our users as we trip. Yeah.
I feel like there's a little bit of a conflation of inference time compute here.
In a sense of like, one, you can infasign compute within the thinking model, right?
And then, two, you can infasign compute by searching and reasoning or iterative.
I wonder if there gets in the way, like when you presumably you've tested thinking plus deep research,
if the thinking actually does a little bit of verification, so maybe saves you some time,
or it tries to draw too much from its internal knowledge, and then therefore searches less,
you know, like does it step on each other? Yeah, no, I think that's a really nice call out.
And this also goes back to the kind of use case. The reason I bring that up is there are certain
things that I can tell you from model memory last year, the Fed did X number of updates and so on,
but unless I sourced it, it's going to be hallucinated. Yeah, like, one is the hallucination,
or even if I got it right, as a user, I'd be very wary of that number, unless I'm able to like
source the .gov website for it and so on, right? So, that's another challenge. Like, there are
things that you might not optimally spend time verifying, even though the models, like,
like, this is a very common fact the model already knows, and it's able to, like, reason over,
and balancing that out between trying to leverage the model memory versus being able to ground this
in, you know, some kind of a source is the challenging part. And I think as, like, you're rightly
called out with the thinking models, this is even more pronounced because the models know more,
they're able to, like, cloth second-order insights more just by reasoning over.
Technically, they don't know more, they just use their internal knowledge more, right?
Yes, but also, like, for example, things like math. I see, they've been post-trained to do
better math. Yeah, I think they just, they probably do a better job, and in, like,
in drugs, so in that sense, they... Yeah, I mean, obviously reasoning is a topic of huge interest,
and people want to know what engineering best practices, like, we think we know, like, you know,
how to prompt them better, but engineering with them, I think, also very, very unknown.
Again, you guys are going to be the first to figure it out.
Yeah, definitely interesting times, and, yeah, it's a pressure market.
Yeah, you do have tips that I know. While we're on the technical elements and technical
bands, I'm interested in, like, other parts of the deep research tech stack that might be
worth calling out. Any hard problems that you solved, just more generally?
Yeah, I think the iterative planning one to do it in a generalizable way.
Yeah. That was the thing I was most wary about. Like, you don't want to go down the route of
being able to teach how to plan iteratively per domain or, like, per type of problem.
Like, like, even in the outgoing, back to the ontology, if you had to teach the model for every
single type of ontology, how to come up with these traces of planning, that would have been
nightmarish. So, trying to do that in a super data efficient way by, you know, leveraging a lot of,
like, things, model memory, as well as, like, there's this very tricky balance when you work on,
like, on the product side of any of these models, is knowing how to post train it just enough
without losing things that it knows in pre-training, basically not overfitting in the most trivial
sense, I guess. But, yeah, so the techniques, the data augmentations there and multiple experiments
to tune this trade-off, I think, that's one of the challenges, yeah.
On the orchestration side, this is basically, you're spinning up a job. I'm an orchestration nerd.
So, how do you do that? It's like a sub-internal tool.
Yeah, so we built this asynchronous platform for deep research, which is basically to,
like, most of our interactions before this was, like, syncing iteratively, like, for a chat.
The guys are syncing, right? Exactly. And now you can leave the chat and come back.
Exactly. And close your computer here. And now with some Android, and...
Yeah, I'm holding on to IOS. I saw you, I saw you, we switched on sometimes.
Okay, you're reminding him, right? Yeah, we wrapped on all Android phones, and then iOS is this week.
But, yeah, what's neat, though, is, like, you can close your computer.
You get an notification on your phone. Right, so on.
So, it's a kind of coming sync engine that you need.
Yes, so the other... One is this notion of syncing in the city and the users are able to leave.
But, also, if you build, like, five, six-minute jobs, they're bound to be, like, failures,
and you don't want to, like, lose your progress, and so on. So, this notion of, like, keeping state,
knowing what to retire, and kind of keep the journey going.
Is there a public name for this, or... No, I don't think there's a public name for this.
Data scientists would be like, this is a spark job, or, you know, it's like a rave,
you know, thing, or whatever. In the old Google days might be, like, MapReduce, or, you know,
whatever. But, like, it's a different scale and nature of work than those things.
So, I'm trying to find a name for this. And right now...
We can name it now.
This is our opportunity.
Yeah, we can name it now.
Yeah.
Yeah.
Well, the question is, I used to work in this area.
I see, I see.
It's more flows.
Yeah.
It's sort of durable.
This is, like, back when you were in the eight-year-old.
I see.
So, Apache Airflow, Temporal.
You guys were both at Amazon, by the way.
Yeah, AWS Step Functions would be one of those, where you define a graph of execution,
but Step Functions are more static and would not be as able to accommodate deep research-style
backends.
What's neat, though, is we built this to be, like, quite flexible.
So, like, you can imagine, once you start doing our or multi-day jobs, like...
Yeah, you have to model what the agent wants to do.
Exactly.
And, but also, like, ensure, like, it's stable, you know, from, like, hundreds of LLM calls.
Yeah.
It's boring, but, like, you know, this is the thing that makes it run autonomously, you know.
Right.
Yeah.
So, like, it's...
Yeah.
Yeah.
Anyway, I'm excited about it.
Just to close up the opening, I think.
I would say opening, I easily beat you on marketing.
And I think it's because you don't launch a benchmarks.
And my question to you is, should you care about benchmarks?
Should you care about humanity's last exam or...
Not even more of you, but whatever.
They're like, I think benchmarks are great.
The thing we wanted to avoid is, like, the day Kobe Bryant entered the league,
who was the president's nephew and, like, weird, like, benchmarks?
Benchmarks.
Okay, perfect.
Just, like, these, like, weird things that, like, nobody talks that way.
So, like, why would we over-solve for, like, some sort of benchmark that doesn't necessarily
represent the product experience we want to build?
Nevertheless, like, benchmarks are great for the industry.
And, like, rally a community and help us, like, understand where we're at.
I don't know.
Do you have any...?
No, I think you kind of hit the point.
I think the...
For us, our primary goal is, like, solving the deep research user value
for the user use case.
The benchmarks, at least, the ones that we are seeing,
they don't directly translate to the product.
There's definitely some technical challenges that you can benchmark against.
But they don't really...
Like, if I do great on HLE, that doesn't really mean I'm a great deep researcher.
So, we want to avoid going into that rabbit hole a bit.
But we also feel like benchmarks are great, especially in the whole Genai space with,
like, models coming every other day and everybody claiming to be like...
So, it's tricky.
The other big challenge with benchmarks, especially when it comes to, like,
the models these days, is the output space entropy is like...
Everything is, like, text and...
So, there's a notion of verifying, even if you got the right answer,
different labs do it in, like, different ways, but we all compare numbers.
So, there's a lot of, you know, art/figuring out, like, how you verify this,
or how you run this in a level plane.
But, yeah, so I think the straight offs is definitely value to doing benchmarks,
but at the same time, we also...
So, like a selfish PM perspective, benchmarks are a really great way to motivate researchers.
Like, make number go up.
Exactly.
Or just, like, prove you're the best.
Like, it's like a really good way of, like, rallying the researchers within your company.
Like, I used to work on the MLperf benchmarks and, like, that was, like...
Yeah, you'd put, like, a bunch of engineers in a room and in a few days,
they do, like, amazing performance improvements on our TPU stack and things like that, right?
So, just, like, having a competitive nature and a pressure, like, really motivates people.
There's one benchmark that is impossible to benchmark, but I just want to leave you with it,
which is that deep research, most people are chasing this idea of discovering new ideas.
And deep research right now will summarize the web in a way that, you know, is much more readable,
but it won't... you know, what will it take to discover new things from the things that you've searched?
First, I think the thinking-style models definitely help you,
because they are significantly better on how they reason natively.
And being able to, you know, draw these second-order insights, which is, like, very premise.
Like, if you can't do that, you can't think of doing what you mentioned.
So, that's one step in...
The other thing is, I think it also depends on the domain.
So, sometimes, you can drift with a model for, like, new hypothesis,
but depending on the domain, you might not be able to verify that hypothesis, right?
So, like, coding math, there are reasonably good tools that the model already knows to interact with,
and you can run a verifier, test the hypothesis, and so on.
Like, even if you think about it from a purely agent perspective saying,
"Hey, I have this hypothesis in this area, go figure out and come back to me," right?
But let's say you're a chemist, right?
So, what are you going to do there?
We don't have, like, synthetic environments yet,
where the model's able to verify these hypothesis by playing in a playground
and have this, like, a very accurate verifier or a reward signal.
The computer uses another one, where there are...
There's both in the open source, the search, and so on.
There's, like, nice playgrounds coming up.
So, I think, for...
If you're talking about truly being able to come up with,
my personal opinion is, the model doesn't...
Has to do the second-order thinking, and so on, that we're seeing now with these new models,
but also be able to play and test that out in an environment
where you can verify and give it feedback so that it can continue trading.
Yeah, so, basically, like, code sandboxes for now.
Yeah, yeah.
So, in those kind of cases, I think, yeah, it's a little bit more easy to envision this,
like, end-to-end, but not for all domains or vertical engines.
Yeah, yeah.
So, if you think about agents more broadly,
there's, like, a lot of things that go into it.
What do you think are, like, the most valuable pieces that people should be spending time on?
Like, things that come to mind that I'm seeing a lot of early-stage companies,
there's, like, memory, you know, like, we already touched on emails.
We touched a little bit on a tool call.
There's kind of, like, the odd piece, like, should this agent be able to access this?
If yes, how do you verify that?
What are things that you want more people to work on that will be helpful to you?
I can take a stab at this from the lens of, like, deep research, right?
Like, I think some of the things that we're really interested in how we can push this agent
are one, like, similar to memories, like, personalization, right?
Like, if I'm giving you a research report, the way I would give it to you,
if you were a 15-year-old in high school, should be totally different to the way I give it to you
if you were, like, a PhD or a postdoc, right?
You can prompt it.
You can prompt it, right?
But the second thing, though, is, like, it should, like, ideally know where you're at
and, like, everything you know up to that point, right?
And kind of further customize, right, have this understanding of, like, where you are
in your learning journeys.
I think modality will be also really interesting.
Like, right now, we're texting text out.
We should go multimodal in, right?
But also multimodal out, right?
Like, I would love if my reports are not just text, but, like, charts, maps, images,
like, make it super interactive and multimodal, right?
And optimize for the type of consumption, right?
So the way in which I might put together an academic paper should be totally different
to the way I'm trying to do, like, a learning program for a kid, right?
And just the way it's structured, ideally, like, you want to do things with generative
UI and things like that to really customize reports.
I think those are definitely things that I'm personally interested when it comes to, like,
a research agent.
I think the other part that's super important is just, like, we will reach the limits of
the open web and you want to be able to, like, a lot of the things that people care about
are things that are in their own documents, their own purposes, things that are within
subscriptions that they personally really care about, right?
Like, especially as you go more niche into specific industries.
And ideally, you want ways for people to be able to complement their deep research experience
with that content in order to further customize their answers.
There's two answers to this.
So one is, I feel, in terms of, like, the approach for us, at least, for me, rather,
trying to figure out the core mission for, like, an agent building that.
I feel like it's still early days for us, like, to try to platformatize or, like, try to build these.
Oh, there are these five horizontal pieces and you can plug and play and build your own agent.
My personal opinion is we are not there yet.
In order to build a super engaging agent, I would, if I were to start thinking of a new idea,
I would start from the idea and try to just do that one thing really well.
Yes, at some point there will be a time where, like, these common pieces can be pulled out
and, you know, platformatized.
I know there's a lot of work across companies and in the open source community about providing
these tools to really build agents very easily.
I think those are super useful to start building agents.
But at some point, once those tools enable you to build the basic layers,
I think me as an individual would, you know, try to focus on really curating one experience
before going super broad.
Yeah, we have Brett Taylor from CRN.
He's had the mostly built everything in-house.
We have anything in-house, which is very sad for VCs.
I want to find the next great framework and tooling and all that.
No, but the space is moving so fast.
Like, the problem I describe might be obsolete six months from now and I don't know, like...
Well, we'll fix it with one more LLM Ops platform.
Yes, yes.
Okay, so just a final point, just plugging your talk.
People will be hearing this before your talk.
What are you going to talk about?
What are you looking forward to in New York?
I would love to like actually learn from you guys.
Like, what would you like us to talk about?
Now that we've had this conversation with you,
yeah, what do you think people would find most interesting?
I think a little bit of implementation and a little bit of vision,
like kind of 50/50 and I think both of you can sort of fill those roles very well.
Everyone, you know, it looks at you.
You're very polished Google products and I think Google always does polish very well.
But everyone will have to want like deep research for their industry.
You know, they invested in deep research for finance and they focus on their thing.
And they will be deep researchers for everything, right?
Like you have created a category here that OpenAI has cloned.
And so like, okay, let's talk about like what are the hard problems in this brand of agent
that is like probably the first real product market fit agent.
I will say more so than the computer use ones.
This is the one where like, yeah, people are like, yeah, easily pays for $200 worth,
a month worth of stuff, probably 2000 once you get it really good.
So I'm like, okay, like let's talk about like how to do this right from the people who did it.
And then where is this going?
So yeah, that's a very simple app.
I hope you don't know what that sounds like.
Yeah, thank you.
Yeah, yeah.
For me as well, you know, I'm also curious to see you interact with the other speakers
because then, you know, there will be other sort of agent problems.
I mean, I'm very interested in personalization and very interested in memory.
I think those are related problems, planning, orchestration, all those things.
Often security is something that we haven't talked about.
There's a lot of the web that's behind off walls.
Can I, how do I delegate to you my credentials so that you can go and search the things that
I have access to?
I don't think it's that hard.
You know, it's just, you know, people have to get their protocols together.
And that's what conferences like that are hopefully meant to achieve.
Yeah, no, I'm super excited.
I think for us, like it's, we often like live and breathe within Google.
And which is like a really big place, but it's really nice to like,
take a step back, meet people like approaching this problem at other companies
or totally different industries, right?
Inevitably, at least where we work, we're very consumer focused space.
I see.
Right?
Yeah.
And so it's to be here.
It's also really great to understand like, okay, what's going on within the B2B space
and like within different verticals?
Yeah, the first thing they want to do is do research for my own docs, right?
Like my company docs.
Yeah.
Yeah.
Obviously you're going to gas for that.
Yeah.
I mean, there'll be, there'll be more to discuss.
I'm really looking forward to your talk.
And, yeah, thanks for joining us.
Yeah, thanks for having us.
Thanks so much, guys.
Yeah.

