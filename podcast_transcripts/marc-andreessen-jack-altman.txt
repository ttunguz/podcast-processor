--- METADATA START ---
Show: a16z Podcast
Episode: Marc Andreessen & Jack Altman:â€¦
Host: Jack Altman 
Guests: Marc Andreessen
Source URL: https://podcasts.apple.com/us/podcast/marc-andreessen-jack-altman-venture-capital-ai-media/id842818711?i=1000712432788
--- METADATA END ---

1
Here's what I would encourage people to do.
2
Here's the thought experiment to do.
3
Write down a piece of paper two lists.
4
What are the things that I believe that I can't say?
5
And then what are the things that I don't believe that I must say?
6
And just write them down.
7
What happens when startups don't just sell the tools, but decide to take over the entire industry?
8
On today's episode, Mark Andreessen, co-founder of A16Z, sits down with Jack Altman, co-founder and CEO of Lattice, to unpack how the venture industry is changing from small C funds to multi-billion dollar barbell strategies and what that means for founders, funders, and the future of innovation.
9
Mark explains how the classic playbook of picks and shovels investing gave way to full-stack startups Uber and Airbnb, and why the biggest tech companies today are not just building tools, but replacing entire sectors.
10
He also talks about the realities of fund size, venture returns, power laws, early stage conflict dynamics, and why missing a great company matters far more than backing a bad one.
11
And then it gets even bigger.
12
Mark dives into AI as the next computing paradigm, U.S.-China geopolitical risk, and why Mark thinks we're in a capital T test for the future of civilization.
13
This episode is about asymmetric bets, ambition at scale, and the deep forces reshaping tech and power.
14
Let's get into it.
15
As a reminder, the content here is for informational purposes only, should not be taken as legal business, tax, or investment advice, or be used to evaluate any investment or security, and is not directed at any investors or potential investors in any A16Z fund.
16
Please note that A16Z and its affiliates may also maintain investments in the companies discussed in this podcast.
17
For more details, including a link to our investments, please see a160z.com forward slash disclosures.
18
I am so excited to be here with Mark Andreessen.
19
And Mark, thank you so much for doing this with me today.
20
Jack, it's a pleasure.
21
So, what I wanted to start with was the topic of small funds, big funds.
22
We had Josh Koppelman on the podcast, and he made a point that resonated around fund size, the outcomes in venture, and just looking at the math of all of it.
23
And I think as venture funds have grown, it spoke to a lot of people about what the plan is and how tech is going to go.
24
And so, I guess to start, I'd be curious to hear your thoughts around that whole dynamic.
25
Obviously,, you've got a big venture firm, and so I just want to hear your perspective on this whole topic to start.
26
So, start by saying,, Josh is a longtime friend, and I think he's a hero of the industry.
27
And I say that because he started First Friend of Ventures back in the very dark days.
28
I forget the exact year, but, back during the dark days of after the 2000 crash.
29
And in fact,, there was a period of time back there when the total number of angel investors or seed investors operating in tech was maybe eight total.
30
And,,, Ben and I were two of them, but, this was the heyday of Ron Conway and Reid Hoffman and a very small group of people who were brave enough to invest in new companies at a point in time when basically everybody believed the internet was over, the whole thing was done.
31
And so I just think that that was an incredibly heroic, brave act.
32
It obviously worked really well.
33, turns out by low, sell high is a good strategy.
34
It's very good.
35
It's very nerve-wracking when you're trying to do it, but it does work.
36
And he had brilliant timing for when he started.
37
And the companies that he supported have gone on to become incredibly successful.
38
And we've worked with him a lot.
39
So we're a big fan of his.
40
And then, second, as I would say, I didn't, I heard there was a discussion.
41
I never, as a rule, I never read or watch anything I'm involved in.
42
That's good.
43
So I totally agree.
44
Well, it wasn't about,, I totally missed it.
45
And to summarize, basically, what he was saying is he coined this venture arrogance score idea.
46
But basically, the idea is:, if you're going to own 10% of a company at exit and you want to have a 3x fund and you're probably going to have a power law of outcomes, you basically need your big outcome to be really big.
47
And so, how's the math shakeout?
48
And basically,, the question he was posing broadly is: are the outcomes going to be much bigger?
49
Are you going to own a lot more?
50
Are you going to hit a lot more winners?
51
But it was that math question.
52
So, I'd say a couple things.
53
So, one is, look, venture is a customer service business in our view.
54
So, start with this.
55
So, it's a customer service business.
56
There are two customers.
57
They're the LPs and they're the founders.
58
And we think of them both customers.
59
And so,, at the end of the day, the market's going to figure this out and the LP money is going to flow to where obviously they think the opportunities are.
60
And the founders are certainly,, as, the best founders definitely pick who their investors are.
61
It's a very unusual asset class.
62
It's the only asset class in which the recipient of the capital picks the cares where the money comes from and picks it.
63
So the market will figure this out.
64
I think the big thing, so responding to your general point, I think the big thing is the world has really changed.
65
And so,, modern venture capital in the form that we understand it is basically,, there were examples of venture capital going back to the 15th century or something with Queen Isabella and Christopher Columbus and whalers off the coast of Maine in the 1600s and so forth.
66
But modern venture capital was basically a product of the 50s and 60s.
67
Originally this guy, Jock Whitney from the Whitney family created the model.
68
George Dorio, who's an MIT professor, created a version of it.
69
And then,, then the great,, the great heyday of the 1960s VCs, Arthur Rock and those guys and everybody that followed, Don Valentine and Pierre Lamond and Tom Perkins and so forth, Gene Kleiner,, all those guys.
70
Basically, it was basically from that period, it's called the 1960s through call it 2010.
71
There was a venture playbook, and it became a very well-established playbook.
72
And it consisted in two parts.
73
One was a sense of what the companies were going to be, right?
74
And then the other was what the venture affirm should be.
75
And so, the playbook was: the companies are basically tool companies, right?
76
Basically, all successful technology companies that were venture-funded in that 50-year stretch were basically tool companies, right?
77
Picks and shovel companies.
78
So, mainframe computers, desktop computers, smartphones, laptops, internet access, software, SaaS, databases, routers, switches, disk drives, all these things were processors, tools, right?
79
And so,, you buy the tool, the customer buys the tool, they use the tool.
80
But it's a general purpose technology sold to lots of people.
81
Basically, around 2010, I think the industry permanently changed.
82
And the change was the big winners in tech more and more are companies that go directly into an incumbent industry, right?
83 insert directly.
84
And I think the big turning point on this was Uber and Airbnb, right?
85
Where Uber could have been,, Uber in 2000 would have been specialist software for taxi dispatch that you sell to taxi cab operators.
86
Uber in 2010 was screw it, we're doing the whole thing.
87
Airbnb in 2000 would have been booking software for bed and breakfasts, right, running on a Windows PC.
88
Right?
89
And then Airbnb is just, screw it, we're doing the whole thing.
90
And so, and, Chris Dixon came up with this term, the full stack startup, which he meant.
91
But the other way to think about that is just you're the company is delivering the entire basically promise of the technology all the way through to the actual customer.
92
Which is basically quicker to get there.
93
Also, I suppose you get more margin capture when you do it that way, and you just get the technology seeped in rather than having to sell it through.
94
Is that the idea?
95
Prior to 2010, there were two kinds of tool companies: consumer tool companies and business tool companies, right?
96
So,, B2C, B2B, right, as we called them in those days.
97
And,, the consumer side was great, but,, consumer,, it's selling video games and consumer software.
98
It's great,, Flying Toaster screensavers, it was great, but there was only so far that was going to go.
99
And then the B2B side for things taxi dispatch or for bed and breakfast bookings.
100
The problem is you're selling advanced technology into incumbents that are not themselves technology companies.
101
And so are they going to take those tools and then build the thing that the technologist knows should get built?
102
More modern version of that is what you see now happening with cars, right?
103
So who's going to build the self-driving electric car, right?
104
Is it going to be a incumbent who's able to adjust, who's buying good components to be able to do that?
105
Or is it going to be a Tesla or a Waymo?
106
Yeah.
107
Right.
108
That's going to do that.
109
Same with SpaceX and NASA, I suppose.
110
Exactly.
111
Yeah.
112
There are many companies that sell technological components that go into rockets.
113
But was any of that going to lead to the existing rocket companies making the rocket that's going to land on its butt and then be relaunched within 24 hours?
114
Right.
115
And so, and by the way, same thing, Airbnb, or Uber.
116
Had you sold the Uberized version of taxi dispatch software to the taxi?
117
One of the things that would it have resulted in the Uber customer experience?
118
And so I think basically what happened was, and there's,, these, as Peter says, these things are over determined.
119
So it's a bunch of things that happened, but it was the, it was the smartphone completed the diffusion challenge for getting computers in everybody's hands.
120
And then mobile broadband completed internet access in everybody's hands.
121
And then the minute you had that, there was just no longer, you just had this ability to get directly to people in a way that you just never had.
122
You didn't have to have a giant marketing campaign.
123
You didn't have to,, have a giant established consumer brand.
124
And so there was a way to get to market that didn't previously exist.
125
And then,, and then look, also, consumers just evolved.
126
And,, people, especially,, Gen X and then millennials were just much more comfortable with technology than the boomers were.
127
And they,, the Gen X was entering,, and boomers and millennials were entering their consumer prime at the time this happened.
128
And then you started having these big successes.
129
And so you started lining up Uber, Airbnb, and Lyft and SpaceX and Tesla.
130
And you start stacking these up.
131
And at some point, you're, all right, there's a pattern here, right?
132
There's a thing that's happening.
133
And that's what's happened.
134
And we're 15 years into that.
135
And what's happened now is basically that idea now has blown out basically across every industry.
136
And so the tech industry used to be a relatively narrow tools, picks, and shovels business.
137
Today, it's a much larger and broader and more complicated basically process of applying technology into basically every area of business activity.
138
The result of that is that the companies are much bigger.
139 when you're the whole company, when you're both the picks and the shovels to yourself of the whole company, you're much bigger.
140
And that changes venture math.
141
Yeah, you eat the market, right?
142
And so Tesla ends up being worth more.
143 there have been points in time in the last five years when Tesla has alone been more valuable than the entirety of the entire auto industry put together.
144
And SpaceX is,, you go through this.
145
And Uber is worth far more than the totality of every black cab operator and taxi cab company that ever existed.
146
Airbnb is worth far more than the bed and breakfast industry ever was.
147
And by the way, it turns out some of these markets just turn out to be much larger than people think.
148
When we do a retrospective on our analysis over 15 years, one of the things that's been hardest for us to do is to do market sizing.
149
And sometimes we overestimate market size, but it's more often it's the other way.
150
More often, well, for the winners, more often it's the other way.
151
Yeah, I guess the net blend is that you underestimate it.
152
Yeah, and this goes to venture economics.
153
You'll talk about it.
154
So the core thing on venture bets, right, is because venture doesn't run on leverage, right?
155
Because nobody will bank, nobody will bank a startup or a venture firm for leverage because there's no assets when these things start.
156
It's asymmetric.
157
You can only lose one X.
158
But you can potentially make a thousand X.
159
And so that means then there's two errors in venture.
160
There's the error of commission, where you invest in the thing that fails, and then the area of omission, where you don't invest in the thing that succeeds.
161
And of course, just in the math, overwhelmingly, the error that matters is the error of omission.
162
And so if you run an analysis that says, and by the way, lots of people did this.
163
You run an analysis that says ride sharing is only ever going to be as big as taxi cabs.
164
That leads you to the error of omission and not making the bet, and therefore the difficulty with market sizing.
165
In your view, does that only apply up to a certain size?
166
Or,, when you look at some of the rounds that now happen at huge valuations in companies that would otherwise be a large IPO, let's say somebody's raising 10 billion at 100 billion or something that.
167
Does the power law still apply up there?
168, how do you think about that type of round?
169
Or do you see venture capital turning into private equity at some level at the higher end of things?
170
Yeah.
171
So I think there's two questions embedded in there.
172
One is, why aren't these companies public?
173
That's one question.
174
And then the second question is,, even whether they're public or not,, can they lose one, win-20 type of dynamic?
175
Yeah.
176
So I think there's a bunch of ways to look at that.
177
So the smartest public investors I've met with basically have the view that the public market works just the private market with respect to this dispersion of returns.
178
The extreme case I'll make sometimes is it may be that there's no such thing as a stock.
179
It may be that there's only an option or a bond.
180
So the reason is because there's fundamentally two ways to run a company.
181
One is to try to shoot the moon.
182
One is to try to build for the future.
183
And then the other way is to try to harvest the legacy.
184
And if you're shooting for the moon, the big risk of that is,, you might fail, right?
185
You might, it might not work, but if it works, you have this telescoping effect in the public market just as much as you have in the private market.
186
And historically, the returns in the public market have been driven by a very small number of the big winners in exactly the same way that they've been driven by that in the private market.
187
In fact, you see that playing out right now in the SP 500.
188
So, one of the things I've been saying for years now is the SP 500 is not, it's no longer the S P 500.
189
It's the SP 492 and the SP 8.
190
So, there's 492 companies in the SP that have no desire at all, right?
191
Just watching their behavior to really charge hard at the future.
192, they don't want to do it, they won't do it, they're not doing it.
193
And then eight are betting everything.
194
Eight are all in, right?
195
And then I always say,, who are they eight?
196
And everybody always knows who the eight are because it's completely obvious who the eight are because they're the ones that are building all the new things.
197
And then, and then, and then again, if you, if you disaggregate public market returns over the last 10 years, you see the it's just you see this just dramatic,, explosion of value among the eight, and you see a relatively modest growth of the of the 492.
198
So, even the SPA 500 is having a portfolio of bonds and options, yeah.
199
And it's, it's, it's incredibly bar-built.
200
And so, I just, I think, and then, and then people, people get cynical on this and they say, well,, if not for the eight,, the stock market.
201
You're, yeah, but that's the whole point.
202
That's the whole point, right?
203
If you have a healthy, functioning, capitalist economy, the whole point is some number of these things are going to go non-linear.
204
This is when someone says, oh, they're not a very good investor, but they invested in, name that $100 billion companies, they got lucky.
205
Well, you're, okay, yeah.
206
That's the point.
207
That's the job.
208
That's the desired outcome.
209
That's the thing.
210
Any of us who, this is the classic joke, joke of venture, it's, isn't there just a way to invest in the good companies and not the bad companies?
211
It's, yeah,, okay, for 60 years, we've been trying to figure that out.
212
Here's a fun fact that you find in the analysis.
213
Over the last 60 years, every one of the really great venture firms through that period missed most of the great companies while they were investing.
214
The best firms in the world, whether it's Kleiner Perkins in the 90s or Benchmark in the 2000s or Sequoia in the 2010s or whatever, they just flat out missed most of the winners in each cohort.
215
On the one hand, you're just, wow, can't you do better than that?
216
But you've had these super geniuses for a very long time trying to do better than that.
217
And we could have a whole separate conversation about why this is so difficult.
218
The thing you said about companies building the whole stack.
219
Roll-ups are super popular.
220
Should I, is it fair to take from what you said that you're bullish on that strategy or not necessarily?
221
And basically, just to walk out and, instead of building accounting software and selling it to the accounting firms, just buy an accounting firm, become an accounting firm, AIFY yourself, which I think is becoming a more popular strategy.
222
Do you that or is there a nuance why it's different to buy something rather than build it yourself from the beginning?
223
What do you think of this whole roll-up thing?
224
Yeah, let's come back to the venture question because I feel I was still lining up into that.
225
However, this is also relevant to that.
226
So, yeah, so there are a bunch of great, really good firms that are trying to do this roll-up thing.
227, the opportunity with it is very obvious.
228
The challenge with it is just cultural change of an incumbent is just a legacy company is just really difficult.
229
Charlie Munger was once asked a few years ago, he said,, GE, I think, was the company that was going through a big issue at the time.
230
And he was asked at a shareholder meeting, how would you fix the culture at GE?
231
And he's, I have no idea.
232
I don't even know how you would change the culture at a restaurant.
233
Yeah.
234
That's funny.
235
Right.
236, how do you do that?
237
It's really hard.
238
Right.
239
It's really hard.
240
And so,, you have to have a theory on that.
241, the people doing it do have theories.
242
I think we're much more oriented towards just trying to back.
243
Well, I think it gets a little into this private equity mind.
244
It's a little bit of the venture private equity blend I see happening is related, not even just in dollar size, but in the mindset here.
245
Well, this is where I go back to my bonds versus options thing.
246, fundamentally, the way I'd always describe venture is, fundamentally, we are buying long-dated out-of-the-money call options.
247
Yes.
248
Which seems completely insane, except when they pay off, they pay off spectacularly.
249
But a lot of them expire out of the money.
250
And statistically, top-end venture capital has a 50-plus percent.
251
Yeah, yeah, yeah.
252
Okay, well, yeah, I just want to get your hot take.
253
I really wanted to hear about this, but yeah, we can go back to the venture mapping because I think there's a lot more in there.
254
Okay, good.
255
So look, so anyway, so what's happened is the world has changed.
256
The number of companies that are being founded that are going to be important, it keeps expanding.
257
The number of categories that those companies are in keeps expanding.
258
Those companies are more complicated now because they're full stack.
259
They're in these incumbent industries.
260
And then the winners are getting bigger.
261
And again, you just look at that in the market.
262, look, we have,, of the S<unk>P 8, they're, oh, they're all venture-backed, right?
263
Every single one of them is venture-backed.
264
They are on any given day, any one of them is bigger than the entire national stock market of countries Germany and Japan and the UK.
265
And so the telescoping effect.
266, numbers are just absurd.
267
The telescoping effect of victory is just incredible.
268
And so what Ben and I did is we looked at it and we started our firm as this was happening and we looked at it and we said, all right, this is different.
269
You could sit here and do things the old-fashioned way, but the world is moving on.
270
And then this goes back to the customer service aspect.
271
The founders who are starting these kinds of companies need something different.
272
It's not sufficient anymore to just,, to have say to have investors who were operating the way that they were investing for the previous 50 years.
273
That's not the value proposition that they need.
274
That's not the help that they need.
275
And so there's a different way to do it.
276
And so I think what's happened is the industry, the venture industry, it had to restructure in order to basically accommodate the change in the market.
277
Now, having said that, I don't think that's an argument that it's just therefore, big firms win everything.
278
That's definitely not my thesis.
279
And by the way, that's also not how I'm deploying my own money, which I don't want to talk about because I'm living what I'm about to say.
280
Which is, I think, what happens is what Nassim Taleb calls the barbell.
281
And the way to think about the barbell is basically draw, you basically have a continuum, and on the one side of the continuum, you have high scale, and on the other side, you have high specialization.
282
And what you see in industries that mature and develop in this way, including many industries in the last hundred years, basically what happens is as they mature and enter their full state, as they flower, what happens is they often start with generalists that are neither subscale nor particularly specialized.
283
And then over the fullness of time, what happens is they get disintermediated.
284
And then there's scale players on the one side and there's specialist players on the other side.
285
The most obvious example of this in everybody's lives is retail.
286
When I was a kid, there were these things called department stores.
287
Pretty good selection at pretty good price.
288
But not a great selection and not a great price, right?
289
And then sitting here today, those are all out of business.
290
They're just gone.
291
And it gets crushed by Amazon on one end and then amazing retail on the other end.
292
Exactly, exactly.
293
Right.
294
And so, and why do you go to Amazon or Walmart or,, the big, and by the way, there were even these big box guys,, Toys R Us and so forth.
295
And then over time, Amazon and Walmart, even ate that.
296
Because when you go to Amazon or Walmart, what you get is just an unbelievable selection of basically anything that's a commodity, right?
297
You just buy at super low prices.
298
And it's basically impossible to compete with that if you're sub-scale on the one hand.
299
And then to your point, and then the specialist retail experiences the Gucci store, the Apple store, the $15 candle.
300
They gave us some Perrier when you walk in.
301
Oh, they love you.
302, they're so happy to see you.
303
Exactly.
304
Right.
305, they'll do private showings for you and port the champagne.
306
And it's, it's, it's an entire experience.
307
And so what's happening is, and you just, again, you see this in the return, you just look on this return standpoint.
308, this is what's happened.
309
This is where this is, this is how the value is.
310
And then what happens is that just gaps way out and it never comes back together again.
311
And then what the consumer does is they build a portfolio of their experiences.
312
And so they buy things at unbelievably cheap prices at Walmart and Amazon.
313
And then that gives them more spending money to be able to spend on the boutique.
314
So this middle, the bar that's in the middle that's screwed.
315
Yes.
316
What is the mechanic by which they're in trouble?
317
Is it because the customers go away?
318
The founder customers go away.
319
Yeah.
320
Yeah.
321
The founder customers go away and then the officials.
322
Who are neither getting the size and scale value nor are they getting a special focus of support?
323
Exactly.
324
Can you do focus?
325
Can you be a specialist with a $2 billion fund, let's say?
326
So obviously we're at scale, but we do have a specialist approach inside the scale.
327
And we have investment verticals.
328
They're discrete teams.
329
They have, in some cases, discrete funds.
330
And by the way, they have trigger puller trigger authority.
331
They can make investment decisions.
332 we don't run the firm where Ben and I sit and decide is this a good investment or a bad investment.
333 our specialists make those decisions.
334
And do you basically determine that by this is the size we think you can function?
335
This is the biggest you can function as a specialist in a highly successful way.
336
And then we're just going to put a bunch of those together.
337
Is that what defines the size?
338
Yeah.
339
So it's, it's two, it's two, yes, yes, but it's two parts.
340
One is what's the, what's the external view is what's the size of the market opportunity?
341
Just how much money does this strategy, does this vertical need?
342
How many companies are it going to be?
343
How many different,, how complex is it?
344
And then the other is the internal dynamic, which is,, you want every, if you're going to have a team, you need everybody around the table being able to have a single discussion.
345
And that puts natural limits on how big that can be.
346
What's your limiting reagent to building an even bigger firm?
347
Is it number of productive partners that can do this then?
348
Conflicts, conflict policy.
349
Conflicts.
350
Conflict policy.
351
That's the single biggest issue by the way.
352
Really?
353
So if you had 50 kills, if you had all the great GPs all wanted to work here and you had,, that would still be the issue.
354
Yeah.
355
There would be issues.
356
There will, there would be issues for sure to your point that would come with.
357
So what's the conflicts then?
358
The conflicts thing.
359
So the conflicts thing is the mainline venture firms forever, meaning that the firms that do series A, Series B, Series C's, especially series A's and B's, the relationship with the founder is just so it's too deep.
360
And if you as a venture firm invest in a direct competitor, it's just, it's a giant issue.
361
The founder you're already invested in will be extremely upset with you.
362
By the way, do you think that's practical?
363
Do you think it's all emotions?
364, do you think it's correct that firms shouldn't do conflicts?
365
I would say when we were startup founders, we felt this very deeply.
366
It's just, it's, it's, okay, so when you're a startup founder, and I'll channel the other, the other side, when you're a startup founder, the whole thing is so tenuous, right?
367
It's just, is this thing going to work?
368
There's 18,000 things that can go wrong.
369
People are telling you no every day.
370
No, I'm not going to come work for you.
371
No, I'm not going to invest in you.
372
No, I'm not going to.
373
And then your board member invests in a competitor and you're dagger to the heart.
374
Dagger to the heart.
375
And then you literally what happens is the founder is you have to go to the all-hands meeting and explain why your investor has given up on you.
376
Yes.
377
Right.
378
And you go in there and you do some song and dance about it.
379
And they're just saying the employees are just, basically your employees look at you and they're just, you, the founder, are so weak and lame.
380
Yeah.
381
Right.
382
You can't even get your board member to not invest in a competitor.
383
Exactly.
384
What about the marginal stuff though?
385
Because,, all these companies are near each other.
386
They blend.
387
They evolve over time.
388
So, how is this, how does this play out on a practical level for firms?
389
It almost never plays out the way that the founders think it's going to play out.
390
And I say that in two dimensions.
391
Number one, the company, this historically what we've seen is the founders who think that they're directly competing with each other generally end up not doing so because one or the other of them changes strategies and then they diverge.
392
Which by the way is natural because it's specialization.
393
The company specializes, they end up not competing.
394
But the other thing that happens is two companies that were not competing, that you're already invested in, pivot into each other.
395
Yeah.
396
And then they're mad at you.
397
And then they're mad.
398
Yes, and then they're very upset.
399
And you have to remind them that,, that,, you didn't know that that was going to happen and it's not your fault.
400
And then they're still upset.
401
And so I would say the founders are not, the founders, and also we have very low predictability in terms of where the conflicts are going to be, but that doesn't ameliorate any of the emotion at the time.
402
And so it doesn't help.
403
It doesn't help for us to explain to the founder, oh, don't worry about this guy who you think is directly competitive because he won't be in a year.
404
Because you can't prove that.
405
And the issue is in the moment.
406
What does that leave your?
407
How does that impact your strategy?
408
Meaning, if conflicts are this huge issue and you've got a big aggregate fund, and so it's very important to catch winners.
409
And then you invested in Blue Origin, which is really good, but SpaceX is bigger or whatever happens.
410
What does that imply for your strategy when it comes to, should we,, doing seeds and nays and things that?
411
Correct.
412
Versus, say, what?
413
Let's just wait till the D, let's have D be our early stage.
414
That's right.
415
So the most obvious thing you do is you're just, oh, we just need to wait because we need to wait for clarity.
416
Just don't deal with this whole issue.
417
Right.
418
Just wait, just wait.
419
Just keep delaying and keep delaying until it's obvious what the answer is.
420
If it's big, it's going to be really big so we can buy later.
421
But then the problem with that is, all right, now you're out of the venture business.
422
Right.
423
Because now you're doing, as you're getting, as you said, now you're basically doing series Ds.
424
Now you're a pure growth investor.
425
And by the way, there are very good pure growth investors, but our determination is to stay a venture investor.
426
Yeah.
427
Because we think that that's the whole point.
428
Why is it so important?
429
Is that just because it's what you, or is there a strategic reason that it's important to stay doing early?
430
So we've always wanted,, that's the way we've always thought about it, is we've always wanted to be the founder's best partner and to be the one who's the closest in, the one that can really be relied upon, the one that's going to be around for the longest amount of time, the one who they can really trust.
431
And it only happens early.
432
Yeah.
433 it's, yeah, it's your early guys.
434
And so it's hard to insert after that.
435
Yeah.
436
And then, look, the other thing is,, there are great growth firms that do invest later and have done very well, but we just think there's so much information at the early stage.
437, so, for example, when we make a growth investment, because we have the active venture business that we have, by the time we make a growth investment,, we have either invested in the company for several years or at the very least, we've met with them repeatedly over time.
438
And so we just end up with just enormous amounts of information.
439
And then the other thing, by the way, is, there's there's there's time arbitrage, which is, sometimes the right and the right answer is just, okay, just invest in SpaceX or whatever later on.
440
But sometimes the answer is no, there's a new thing.
441, totally.
442
You invest in the MyState Growth round at The Facebook, the Facebook seed round.
443, and if you, if, if you're not in the early stage, you won't know that because you won't see the you won't see the early things.
444
Yeah.
445
And then by the way, the other thing I just say is financially, one of the things people say that is inaccurate is they say if you're running a big fund, you're not going to have the time to spend on the early stage opportunities because you can't justify it before you're putting the money.
446
But that's not true in venture because the aggregate dollar return opportunity on early stage is just as high as any growth investment.
447
Right.
448
Because if you get the right venture investment and you can make $10 billion on the upside case, it's definitely worth my time to spend with you.
449
So I spend as much time as I can with the early stage founders,, for that reason.
450
So the barbell, there's,, there's big on one end, there's something me on the other end.
451
Selfishly, I would love to know,,, I would assume you think it's better to be the big version, but, if you were conditioned on needing to be me at the small end of the barbell, how would you approach it?
452
And what's they're both good.
453
They're both good.
454
This is the thing is, they're both good.
455
They're both good.
456
And if I were, for some reason, not doing this, I would immediately do what you're doing.
457
Right.
458
So that's good to hear.
459
Yes, 100%.
460
And then, and then I would say I invest this way.
461
So my liquid assets are basically tied up in either A16Z funds on the one side, or I run a very aggressive personal investment program in early, early, basically Angelin and early stage seed funds.
462
And it's because I believe in the barbell.
463
I believe in the barbell so much.
464
And so, but the conflict thing I wanted to explain because that's the issue.
465
So, the big further, we do seed investing, it's just we have this problem every single time we're looking at a seed investment, which is, are we really fully convicted that this is going to be the winner?
466
Even at seed, it creates a conflict or a board seed.
467
There's debates.
468
There's always debates on this.
469
It's,, do the seed ones care as much?
470
Do the growth ones care as much?
471
Do the crypto ones care as much?
472
What I tell you is, it's not a logical question.
473
It's an emotional question.
474
And we're just very sympathetic to the founder that needs to be able to justify their authority.
475
You also definitely can't ask while you're making.
476, if somebody asked me while they were making an investment, hey, is it okay if we invest in a conflict in a couple of years?
477
I'd be, what are you talking about?
478, we've done these things.
479
We've tried to, we used to have this thing.
480
We used to have this separate branded thing called A16C Seed, and we were, well, we have a different conflict policy on this.
481
And it's great in theory, but it's, no, it's A16C.
482
And so the way I think about it basically is the more successful you are as a venture firm, the bigger the issue this is going to be because the more the people that you are investing in are going to care.
483
And so it's the downside of success, but success.
484
Yeah, right, right.
485
The only people who,, the only investors you don't care whether they invest if they're, it's literally if you don't care what they think about anything, right?
486
If they, if they just don't matter at all, and everybody knows that they don't matter at all.
487
So there's that.
488
So therefore, it can be simultaneously, both of these things are true.
489
Number one is we still, we definitely do lots of early stage investing and we will do, we will do, we do make seed bets, but it's just also true that we can't structurally for it for this reason.
490
We cannot do all of the seed investments that we would to do.
491
In fact, we can't even do a tiny fraction of them.
492
It's just strategically, we just, structurally, we just, we just can't do it.
493
And so, and again, this goes back to the barbell.
494
So that means structurally, it's the same reason why Amazon can't give you the champagne experience, right?
495
It's the same thing.
496
They're not set up for it.
497
They can't do it.
498
It's not a scalable strategy.
499
And so, what has to happen is there has to be the other side of the barbell.
500
There has to be the specialization and intense focus and deep relationship thing.
501
And that's the role of the angel investor and the seed investor.
502
And that's, and of course, in startups, that's incredibly important because that's the most formative, right, fraught time in the life of these companies is when they're first getting started.
503
And as, right, half the time, these are people who haven't,, they haven't started a company before, they haven't run a company before.
504
Some of them haven't had a job before.
505
And so,, they need to learn a lot and they need people to work with them on being able to do this.
506
And they need to figure out how to do these things.
507
And so there have to be, and there are incredibly high-quality seed investors, angel investors on that side of the barbell.
508
The big firms, presumably, if we succeed, we succeed by generating large numbers of aggregate dollars and a very good percentage return.
509
The seed investors have this perpetual opportunity to just absolutely shoot the lights out on upside.
510
And you can have,, there are seed funds that generate 200x, 300x returns.
511
And so these are both good strategies.
512
They're both adapted to the current reality of the market.
513
There's just two things that fall out of that.
514
One is the death of the middle, which is it just doesn't make sense to have the old-fashioned series A, Series B, six GPs, $300 million funds sitting on Santo Road, waiting for people to walk in the door.
515 those days are over, and those funds are,, those funds are shutting down.
516 that, that model's going away.
517
And then the other thing that happens that causes some of the tension is what does a successful seed investor do, right?
518
He raises more money and wants to become a venture investor.
519
But then you're going from one side of the barbell back to the middle and you're creating that same problem.
520
And I think that's where the tension is coming from.
521
I also feel the mechanic that happens a lot of times is when you grow the fund, the only you,, you raise a huge fund and then you start deploying it into things just because you've got to deploy at some pace.
522
And so the threshold for if I've got to deploy 400 million this year and I only see $700 million worth of investable things, I'm going to do four-sevenths of them versus,, presumably if you only had to do one-seventh of it, you would,, you'd pick better, hopefully, which I think is a huge we can do.
523
I think that's part of it, but I think the related thing is your competitive set has changed.
524
Yeah.
525
And what we what we find with seeing investors who migrate up and then regret it later, what we find is what they didn't realize was their competitive.
526
So right, because now they're going for bigger, more competitive rounds against Seguyu and Sequoia.
527
Yeah, all of a sudden, okay, now you're competing for $60 million B, good luck.
528
Right, right, exactly.
529
And so it's just, and look,, I'm a market fundamentalist, if you have a better value proposition than Sequoia, you should go, you should, you should go off for that.
530
But I just, I would not, I would not accidentally end up competing with Sequoia for Series Ace.
531, I would just say that's a bad way to live.
532
Yeah.
533
And I think that's what happened.
534
That is what has happened to a bunch of the seed funds that have gotten larger.
535
Why is it so rare for somebody to break through and get,, you did it, and that's one that happened in the last 15 years.
536
Maybe there's a couple others, maybe, but why is it as rare as it is?
537
It seems almost more rare than a new big company in a way.
538
Yeah, that's true.
539
In fact, our analysis when we started was there hadn't been, I think there had been two firms, Andy Recliffe.
540, Thrive also.
541
So Thrive was after us.
542, they've done great, but in the 30 years before us, we think that there were only two new VCs that punched through to become top tier.
543
In other words, VCs that were not either firms that were built in the 60s and 70s or firms that weren't derivations of those firms.
544
Founders Fund?
545
No, no, no, no, no.
546
Founders Fund started around the same time we did.
547
They were a little bit earlier, but they were around the same time.
548
But, over the preceding 50 years.
549
Okay.
550
Seven Rosen.
551
You won't even.
552
No.
553
This is the thing.
554
You won't even recognize you.
555
I just need to read a book or something.
556
So, Seven Rosen was the venture firm that famously funded Compact Computer, which was the big, the big winner.
557
And then they went on to become a successful firm.
558
This guy Ben Rosen, early leader in the space.
559
And then there was a firm called Hummerwind Blad, which was a software specialist firm in the late 80s, early 90s.
560
Those are the only two that punched into the top end while they were operating.
561
Wow.
562
Neither one of them sustained it, but they got there for a bit.
563
But that was the success case.
564
So this is a little bit Elon looking at the history of the car industry and saying,, Tucker Automotive in the 1960s.
565
It's so rare.
566
It's very, very rare.
567
So why is it?
568
Okay, so two reasons I think it's rare.
569
So number one, there's the intimate reason for it, and then I'm macro reason for it.
570
The intimate reason for it is just you're going to have this incredible, as the founder, you're going to have this incredibly intimate experience,, very close trust relationship with whoever you're working with.
571
And it's,, can you reference them?
572, do they have a history and track record of the kinds of behavior that you need and the kinds of insight that you need?
573
And it's just it's very hard to do that.
574
It's very easy for an existing firm that has a long track record of success to prove that.
575
It's very hard if you don't.
576
So that's that's the close-in reason.
577
But then the other reason goes back to the way the world is changing is we always believe the thing that you want from your venture firm is power.
578
So the thing as a startup that you want is you want them to fill in all the missing pieces that you don't yet have when you're starting a company that you need you need to succeed.
579
And so you need power.
580
And so you need power.
581
That means you need the ability to be able to go meet customers and have them take you seriously.
582
You need the ability to go get publicity and major channels used to be media now it's podcasts and be able to get taken seriously.
583
You need to be able to be taken seriously by recruits right because there's thousands of startups recruiting for engineers.
584
What makes your stand out?
585
I sometimes describe it as venture firm as providing a bridge loan of a brand new film.
586
Until you have your own brand that's big or bigger for your own space, then the VC, you're borrowing your VC's brand.
587
Exactly.
588
And then that has been very effective for a long time.
589
And that was how we looked at it when we were founders.
590
That's why you did media from the beginning?
591
Yeah.
592
Oh, that's one of the reasons.
593
Yeah, it's one of the reasons, yes, but a very, but a very, very powerful one.
594
Yeah.
595
A very, very major one.
596
Yeah.
597
And then, by the way, you also need ability to raise downstream money, right?
598
You're going to have to need to raise money again.
599
And so they either need a lot of money or they need to be connected to a lot of money.
600
Yeah, exactly.
601
Right.
602
Exactly.
603
And so you just better if they just have it.
604
Yeah.
605
Being full stack.
606
Well, then, by the way, now you're getting also, again, you think tools companies just never got into, for example, politics, right?
607
Or just, let's just say global affairs, global events.
608, what's happening with,,, what's happening with how do you navigate the world?
609
Right?
610
How do you navigate Washington?
611, when the regulators show up and they want to kill you,, how do you navigate that?
612
Or you're getting some,, giant fight with the EU or what?
613, so, so, especially these full-stack companies, they're, they're, they're getting involved in very complicated macro political, geopolitical situations, much more early.
614
And they have to,, in some cases, they have to escalate up to,, senior government officials, heads of state,, major heads of sovereign wealth funds.
615
They need to get to,, CEOs of major companies.
616, how do you get to the CEOs?
617, you're a new AI, you're a new AI company and you're trying to redefine visual production for movies.
618
How do you get to the studio heads?
619
Yeah.
620
Right.
621
The studio heads just don't have time to meet with a thousand startups.
622
So where are they going to meet with you?
623
Right.
624
So basically, it's projection of power.
625
And this has been one of our theories, how we built our firm is you optimize for maximum amount of power in order to be able to give the startups access to it, right?
626
Both the startups that are already in your portfolio, but also the startups that don't even exist yet.
627
And again, this goes to why the scale thing matters so much.
628
It's just, all right, there's just a scale aspect to power.
629
There's a big difference between being able to get to everybody who matters and not.
630
Why is it rare for people to be able to accumulate power even if they were, let's say everybody was trying to do it?
631
It's not everybody could do it.
632
What's the cause of the rarity to be able to build enough power in that sense?
633
It started with you have to want to.
634
And so we met with all the GPs of all the top firms basically when we were starting out because we wanted to,, see who we could be friends with.
635
And it worked very well in some cases and not well in other cases.
636
But one of them told us, this is a GP at a top firm in 2009.
637
And he said, yeah, the venture business is going to the sushi boat restaurant.
638
All right.
639
And so the sushi boat restaurant, it's the sushi restaurant where they've got the boats.
640
It's got a water belt.
641
Conveyor belt.
642
Right.
643
And the little sushi boat comes out.
644 I loves them.
645
And there's a two-in-one roll and there's a shrimp roll and there's this or that.
646
And you, and he said, basically, you just sit on Sandhill Road.
647
And you're, we're going to crush these guys.
648
And the startups are going to come in.
649
And he said,, if you miss one, it doesn't matter because there's another sushi boat coming up right behind it.
650
And he's just, you just sit and watch the sushi go by.
651
And every once in a while, you reach into the thing and you pluck out a piece of sushi.
652
And we walked out of that sink,, what the hell?
653
That's funny.
654, in what industry is 2009 or something?
655
2009.
656
Yeah.
657, that was a very common.
658
This again is the mid, this was the mid-sized venture.
659
One of the reasons when I came,, look, in 1994,, it might have been that.
660
It was.
661
It was.
662
When I came to Silicon Valley in 1994, I had never heard the term venture capital.
663
I didn't even know the thing existed.
664
And then as my business partner, Jim Clark, explained it to me, and I was, there are guys, they're just sitting there waiting to give you money.
665
But you see this and you're, this is going to get seasonal life.
666
Of course, this is absurd.
667, the minute anybody takes this seriously, it's all going to change.
668
And so it was this very clubby cartel,, basically thing.
669
And again, it was fine as long as the ambitions of the industry were constrained.
670
And then, but then again, look, the tools companies, they didn't need all the power.
671
They needed some of the power, right?
672
But they didn't need all the power.
673, they weren't dealing with governments, right?
674
Or,, these big macro issues,, at least,, in the early years.
675
Well, okay, so here's another thing that's happened.
676
It's just the world is globalized.
677, so startups 30 years ago, you would spend your first decade just in the US and then you would start to think about Europe and global expansion.
678
And now you just, you have to think about being a global company up front because you're going to, if you don't, you're, other people are going to do it.
679
Yeah.
680
Right.
681
And so you you just you have to chin up as an entrepreneur the expectations are much higher than they used to be maybe one final question on this topic of fund size and then i want to go to ai what do you think and i know you thought about this a lot what do you think is the limiting factor for the creation of a lot more really big companies do you think it's founders do you think it's capital do you think it's market maturity do you think it's underlying tech stuff if you had to pinpoint the one or two things that you think would allow for there to be way more big companies what is it so there's the holy trinity of venture startups which is people market and technology and i think the answer is all three and the way i would describe it is there's some limiting issue with just market size just how many markets are there how big are they how how ready is the market to take something new then there's the technology question which is when is the technology from the venture perspective technology moves in stair steps right and so things become possible in the world of smartphones that just weren't possible you couldn't do uber with when everybody had a laptop you had to wait till they had phones yeah right and so technology moves in a stair step you get these paradigm shifts platform shifts And those just they come when they come yeah and until they come you you can't do it and then and then the people side and this is the one that i say vexes me the most which is okay how do you just get more great great founders yeah right and i think part of that is you i think there is definitely a training thing that is real and getting people into the right scene in the right way and the thing that combinator does or the thing that the teal fellows do those are real things and those help a lot.
682
But also i there is an inherent,, there are just certain there's there are not an infinite number of people running around who have the.
683
You probably figure there's a lot of people who could have built big companies who haven't, though.
684
And hopefully.
685
There's a lot.
686
Yeah.
687
A few.
688
Yeah, I don't know.
689
I don't know.
690
Some number.
691
But there must be people who are just in academia or government or education, who are just doing something completely different, who if they were attracted to startups, would have built a big company.
692
So yes, but then the other question is, well, okay, then why didn't they?
693
Why didn't they do the things required to get themselves in that position?
694
Well, it could have been then 2001.
695
It was just too many people were too scared to do it or didn't know about it or whatever.
696
But what does that tell you about the people who didn't do it?
697
Yeah.
698
They were heard.
699
I can tell you who didn't listen to that, right?
700
It was Mark Zuckerberg.
701
Are there more good.
702
But let's just press this point harder for a moment, which is, I always describe this as, I always call this the test with capital T, which is, okay, if you're not in position to do the thing, is the fact that you're not positioned to do the thing meant that you flunked the time.
703
You've already flunked it.
704
Well, I guess the question would be, is there a subset of people who could build Facebook who, other than being too scared to do it, would have had all the other ingredients.
705
And so when everybody's not scared, you get more Facebooks.
706, there's a line in the movie.
707
I never saw the movie, but there's a line in the movie.
708
If you could have built Facebook, you would have built Facebook.
709
Yeah, yeah, there is a line in that.
710
Yeah, yeah, yeah.
711
That's right.
712
That was a good line.
713
Right.
714
And so this is the thing.
715
It's,, are there more great founders today than when you were, let's say, in Netflix?
716, do you think there are more now than there were 20 years ago?
717
I believe there are, but, I, maybe there's, how many more are there, right?
718
Is it five times more?
719
Is it 50% more?
720
Or is it?
721
Well, so look, the number of wins is increasing.
722
So the, so we used to talk about the 15, 15 a year that matter.
723
It's that up numbers probably, if you do the analytics, probably up 10x.
724
There's 150 companies.
725
150 companies a year that really matter.
726
And the reason is because there's so many more sectors now, right?
727
So, you're getting the industry maturation.
728
And so, by inference, there have to be.
729
You're saying the markets are better more than you're saying the founders are better.
730
Well, maybe a little bit of both.
731
Look, also, I think the founders are getting better.
732
Part of the founders are getting better is they have better training.
733
They're all on the well, to start with, they're just all online.
734
So, so when I showed up here in 1994, literally, there's three books in the bookstore, and I don't know which were that great.
735
Yeah, it's not that the DNA is better, it's that they're now the ecosystem has matured to teach people better.
736
Yeah, and people come in and they've watched every video,, they watched every episode of, your podcast, and, right, and they just walk in knowing all this stuff.
737, and then, yeah, look, and then look, the Y Commoner didn't exist, and, that definitely helps, And, teal fellows didn't exist, and that definitely helps.
738, there's, Brian Eno has this great term, senius, scene,, scene plus genius, right?
739
And so, it's just, the individual genius on his own is always, it's hard to get things done.
740
Yeah, some people do, but it's difficult.
741
It's more often, more often in a profession where you're seeing creativity happen.
742
Yeah, there's almost always a scene,, as, Silicon Valley is definitely a scene in that way.
743
People come here and they just get, I don't know, they just get better.
744
They just,, they meet more people who are them, they're able to aggregate together, they learn from each other.
745
So, yeah, so look, the founders are getting better, there's more of them, but is there, does that mean there's now 10,000 as opposed to a thousand?
746
Yeah, I don't know.
747
There's and there's eight billion people on planet Earth.
748
Why are we why are we debating whether it's a thousand or ten thousand?
749
Yeah, right.
750
And so, I just, I, that, that I don't know.
751
Yeah, I would hope over the next, years and decades, we'll all figure out a way to go make sure we get everybody who can do it and get them to do it.
752
That's a good segue into AI.
753
Do you feel that we're now at the beginning of what is the new next important paradigm?
754, is this cloud butt on steroids?
755
Oh, yeah, much, I think, much, I think much larger, and I'll explain why.
756
So,, yeah, so I described,, I described, I described before, right,, the triangle people technology market.
757
The technology is, ultimately, the driver is the technology, the technological, for venture, the technological step function changes drive the industry, and they always have, right?
758
And so, if you talk to the LPs, you can see this.
759
It's when there's a giant new technology platform, it's an opportunity to reinvent a huge number of companies and products that now have become obsolete and create a whole new generation of companies, often generally end up being bigger than the ones that they replaced.
760
And so in the venture returns, map this.
761
And so they come in waves, and the LPs will tell you it's just, yeah, there was the PC wave, the internet wave, the mobile wave, the cloud wave.
762
That was the thing.
763
And then, by the way, in venture, when you get stuck between waves, it's very hard, right?
764
Because you've seen this for the last five years.
765
For the last five years, it's, how many more SaaS companies are there to found?
766
We're just out of ideas.
767
They're just out of category.
768
Yeah.
769
Done.
770
And so it's when you have a fundamental technology paradigm shift that gives you an opportunity to rethink the entire industry.
771
It would have been very sad, by the way, if the AI breakthrough didn't happen.
772
The state of venture would be sad, I think.
773
Three years ago, this was,, so when we were talking to our LPs three years ago, we're just, basically,,, we're in,, we're so Chris Dixon has this framing he uses.
774
He calls it, you're at venture, you're either in search mode or hill climbing mode.
775
And in search mode, you're looking for the hill.
776
And it was search mode.
777
Right.
778
And three years ago, we were all in search mode.
779
And that's how we described it to everybody, which is, we're in search mode and there's all these candidates for what the things could be.
780
And AI was one of the candidates, right?
781
It was a known thing, but it hadn't broken out yet in the way that it has now.
782
And so we were in search mode.
783
Now we're in hill climbing mode.
784
Thank goodness.
785
Yeah.
786
Big time.
787
Yeah.
788
And then,, look,, as I say, on the technology breakthrough itself, I think a year ago, you could have made the argument that, I don't know if this is really going to work because LLMs,, hallucinations, it's great that they can write Shakespearean poetry and hip-hop lyrics.
789
Can they do math?
790, can they do, can they write code?
791
No, it obviously is.
792
And now they obviously can.
793
And this, I think for me, the turning point moment, the moment for certainty for me was the release of 01.
794
So, 01 from OpenAI, The Reasoner, and then DeepSeek R1.
795
The minute I, then those happened back-to-back.
796
And the minute those popped out and you saw what's happening with that and the scaling law that was around that, you're just, all right, this is going to work because reasoning is going to work.
797
And in fact, that is what's happening.
798, it's, it's, it's,, and I would say just every day I'm seeing product capabilities.
799
Yeah,, I'm seeing new technologies I never thought I would live to see.
800 really profound.
801
I think the analogy isn't to the cloud or to the internet.
802
I think the analogy is to the invention of the microprocessor.
803
I think this is a new computer.
804
Being a new computer means that essentially everything that computers do can get rebuilt, I think.
805
So we're investing against the thesis that basically all incumbents are going to get nuked.
806
Yeah.
807
And everything is going to get rebuilt.
808
Just across the board.
809
Just across the board.
810
Now, we'll be wrong in a bunch of those cases because some incumbents will adopt.
811
But the power law, the things that are right will be super right.
812
Will be super right.
813
Exactly.
814
And then, look, the AI makes things possible that were not possible before.
815
And so there's going to be entirely new categories.
816
By the way, is your mindset there that you should just bet on?
817, obviously, incumbents are going to win some percentage and startups are going to win some, but it's basically the dominant strategy as a venture capitalist to just plan to bet that startups are going to win it all and go for the power law?
818
Yeah, that's right.
819
That's right.
820
Well, and again, the reason is to remember two customer sets.
821
The way the LPs think of us, the way the LPs think of us is as complementary to all their other investments.
822
And so our LPs all have major public market stock exposure.
823 they don't need us to bet on incumbent healthcare,, whatever company, right?
824
They need us to fit a role in their portfolio, which is,, to try to maximize Alpha based on,, based on disruption.
825
And then again, and then just again, the basic math adventure, which is you can only lose one X, you can make a thousand X, and you just slam that forward as hard as you can.
826
So when you have a moment in time worldview this, do you,, as a firm leader, do you give a directive that's basically, hey, everybody, we need to deploy in this way right now?
827
Or do you just build a system that's always picking birds out of the flock from the bottoms up?
828
And you're just, well, they're smart.
829
They're going to see that every opportunity is good.
830, how much is it a top-down guidance versus,, the market's just obviously good all around?
831
Yeah, so we don't do, I said, we don't do top-down investment decision making.
832
And so Ben and I aren't sitting saying,, we need to invest in category X or we need to invest in this company versus that company.
833
And we don't run.
834
We run, we have a legal investment committee, but we don't run a process where they come to us to get approval.
835
Because you're letting the leader of each group make those.
836
Yeah.
837
And often in those groups, it's delegated further.
838
It's delegated to the individual individual GP or checkwriter.
839
And the reason for that is we just think that the knowledge of knowing what's going on and which one's likely to win is going to be focused in the mind of the person who's closest to the specific thing.
840
But do you have a risk slider?
841
Are you, hey guys, let's get a nine right now?
842
So this is the funny thing.
843
So venture is the only asset class in which the leaders of the firm are in the position of trying to get the firm to take more risk, not less risk on a regular basis.
844
Exactly.
845
Because the natural orientation towards any anybody who's in an existing business, there's a natural organizational incentive to try to reduce risk because you just want to hold on to what you have and not offset the alpha cart.
846
And so Ben and I are generally on the side of take more risk.
847
One of the applications of this is the old Sequoia adage, which is they say when in doubt, lean in.
848
So for example, so you see this, I'm sure, when you do it, it's just, okay, there's this thing, there's this company that is potentially very interesting, but there are these issues, right?
849
And it's just, it's too early and this and that and this weird guy's got a weird background and this, that, that, and he's in a,, whatever, I don't know, issues and,, there's a hair.
850
Yeah.
851, there's hair on the deal.
852
There's no hair on the GP.
853
That's fine.
854
But there's hair on it.
855
There's hair on the deal.
856
The founders tend to have really good hair.
857
There's hair on the deal.
858
And it's just, all right,, what do you, what do you, how do you calibrate that, right?
859
And, and, and the history, and again, the history of venture is when you see something that's very promising and there's a lot of hair on it, sometimes when you invest, it's going to go to zero because the hair is going to kill it.
860
And then sometimes when you invest, it's going to be the next thing.
861
But it's something where you're, I love that, I hate that.
862
It's much better than, yeah, everything's fine.
863
100%.
864
And this is the way we describe this is invest in strength, not in lack of weakness.
865
Or another way to think about it is it's not good versus great.
866
It's very good versus great.
867
Differentiating good from great is very straightforward.
868
Differentiating very good from great is very hard.
869
And again, the risk-reducing way to try to do that is, as you alluded to, it would be the checkbox thing, which is, very good team, very good market, very good this, very good that.
870
And then you have this other one where it's they've got six great things and nine horrible things, right?
871
Yeah.
872
Okay, which is the better bet?
873
Totally.
874
Usually, usually it's the thing with the greater strengths.
875
Statistically, by the way, this shows up in the return data from the LPs, which is the top decile firms have a higher loss rate than everybody else, which is called in baseball called the Babe Ruth effect, which is the home run hitters strike out more often.
876
So the top performing venture firms statistically tend to have a higher loss rate than the mediocre firms.
877
And it's for this reason.
878
They're willing to invest in the thing that just looks completely nuts, but has that magic something.
879
And so when Ben and I think about trying to get the team to take more risk, it's almost always, it's basically either that thing, which is, look, and what you're doing is you're telling the person closest to it, go with your gut.
880
If your gut tells you there's something magical here, go ahead.
881
It's okay because we're going to have some losses.
882
So it's okay to make the bet.
883
If it breaks because of the hair, that's fine.
884
But then the other form of risk we try to do, and I do this a lot, is just,, I am trying to push the firm constantly, is, go earlier.
885
Yeah.
886
Right.
887
Because again, as we discussed earlier, the natural inclination is to wait.
888
Right.
889
And it's, no, no, no, go earlier.
890, we do want to make these,, we'll make some C bets, but we definitely want to make a lot of A bets.
891
Yeah.
892
And again, we're going to lose a bunch of those.
893, we're going to screw those up and miss the winner or whatever.
894
But, we have to do that because we have to get into some of these things early.
895
We have to,, get the level of percentage you get in the A,, that relationship.
896
Yeah, and I guess there's risk that's of the flavor of do things that are more asymmetric where there's hair but also brilliance.
897
Correct.
898
There's also the flavor that's just, well, sometimes something I struggle with is the deals where I just barely said yes and just barely passed.
899
I'm, I don't have that much confidence that I can tell the difference between those.
900
There's another flavor of be more aggressive, which would just say, just do a higher percentage of those ones where you're right on the line.
901
Do you give that guidance?
902, do you think that too, where you're, it's not just do the more out there things and we're swinging for the fences, but it's also, let's just do a little bit more right now in general.
903
Yeah.
904
So we used to run this process we call the anti-portfolio and the shadow portfolio.
905
And so the shadow portfolio was, we used to track this statistically for the first five years exactly on this point, which is every time we do an A, every time we do it, pull the trigger on an A round, let's put in the shadow portfolio the other company we were looking at at around the same time that we didn't end up pulling the trigger on.
906
And then let's build up representative portfolio, build up the ultimate,, the Earth 2 portfolio.
907
I'm so curious.
908
Well, so the good news is it turns out generally that the main portfolio did better than the shadow portfolio.
909
But the shadow portfolio did really well.
910
Yeah.
911
Right.
912
Exactly the point.
913
And so, and then you're okay.
914
So then you're just, okay, you're not that smart, but you're just, okay, obviously, what does that mean?
915
It means do them both.
916
Right.
917
And again, this goes to the thesis of how big should these firms get?
918
It's just, well, if you had the opportunity to do both, the portfolio and the shadow portfolio, you should do them both.
919
What's the constraint on that, as we discussed, is conflicts.
920
But generally speaking, you should try to do both.
921
And by the way, this is the, I don't know if it was Josh or the other, the other podcast that they were talking about this, but at least I saw a reference to a statistical analysis of win rate or whatever, return,, percentage returns or whatever, or percentage of wins.
922
It's just it doesn't, in venture math, it doesn't matter.
923
The thing that matters is were you in the next big thing as early as you could get in and buy as much as you did?
924 that's the only thing that matters because if you don't do that, you miss out on the thousand X gain.
925
The 1x losses don't matter.
926
They wash right out.
927
And so this idea that somehow there's some virtue to being a small, we only make a few bets, we have a higher percentage.
928
It does.
929
How much is that?
930
I'm glad people think that that's a I would to encourage people to think that that's a virtue that they should shoot for.
931
It seems it's very hard to assemble lots of very good, productive GPs into the same firm.
932
It's just objectively rare.
933
Yeah, that's right.
934
You've done it, but it's doesn't happen very often.
935
Do you, I guess my first question on this is do you think of just finding greatness and then you can't really teach it much?
936, so you're basically just going to hire people and see how it goes?
937
Or do you think that it's about creating a system and conditions in which people do great work and you can create good investors?
938
Yeah.
939
So I think it only works if there's a point, if there's a reason why you would have an aggregation of GPs in the first place.
940
And our answer to that is power, right?
941
Our pitch to GPs as to why they should join us as opposed to go to a smaller firm or start their own thing is if you come here, you just plug into this engine.
942
It's just massively powerful.
943
And so everything that you do, the effects of it are going to just be blown completely out.
944
It was much more satisfying.
945
And you're going to be able to help the companies a lot more.
946
And you'll probably see more companies anyway.
947
Yeah.
948
So everything probably gets better.
949
Yeah, that's right.
950
That's right.
951
And by the way, some people want to have colleagues.
952
Some people don't want to have colleagues, but some people do want to have colleagues.
953
And you'll be working with people you and who care about the same things you do.
954
So, but there has to be a point to it.
955
And of course, it's on us to keep proving that, right?
956
Because the devil's in the details of whether they'll buy that.
957
But so far, a lot of really good, great people have.
958
And then, yeah.
959
And then the second part of the question is, okay, who do you put in those roles?
960
Historically, we had our old model was basically we only hire GPs.
961
We were not developing, and we could go through why that was the case.
962
We changed that eight years ago.
963
We now develop our own GPs.
964
We've evolved to where I think that's working quite well.
965
I think the answer to your question is it's a two-part question: there's some level of just objective,, are they good at doing the job?
966
Here's a big thing we focus on when we evaluate them, which is it's fine to invest in a category five years early or whatever, something goes wrong, that's fine.
967
What's not fine is you invested in the wrong company and you could have invested in the right company.
968 at the moment you made the investment, you could, you made the wrong decision in that moment of which one you should invest in and you could have known.
969
And so it's, did you do the work to fully address the market?
970
How do you handle the fact that you don't know that until six years later?
971
And now you're going back and you're, hey, you made this mistake six years ago.
972
This isn't going to work out now.
973
So it's generally that is a giant problem.
974
And I would say that when we started,, when we talked to our friends in the business, what they said basically was, they said, number one, you don't know if somebody's a good GP for 10 years because you don't have the return data.
975
And then they said, number two, is nobody ever wants to admit that they made a mistake.
976
And so they never fire anybody.
977
So what they do is they just keep them on the masthead and they just gently retire them out.
978
They sit and pollute.
979
One of the guys running one of the big firms 15 years ago told me he said they hired a partner.
980
It's an older firm.
981
So they hired a partner in 1984 who was a big deal at the time in the industry.
982
And the LPs were very fired up about it.
983
And he said he then proceeded to just nearly ruin the firm over the next 20 years.
984
That's crazy.
985
Because he said he wanted, he said, all of his investments were bad, but then it was even worse that he talked them out of all the other good investments they come in.
986
And he said we couldn't get him out.
987, the reputational damage was too great.
988
So, this is a long run.
989
And then, by the way, a lot of these firms are partnerships.
990
The problem with the partnership is partnership sounds good.
991
The problem is you end up with lots of internal dissension and then you can't make decisions.
992
So, this is a big issue.
993
I guess what I would say is, for example, the thing I talked about, it's just what I just described is a process issue, not an outcome issue, right?
994
Which is, are you doing the work?
995, it's an actual job.
996, are you doing the work?
997
If you're not doing the work, it's relatively clear you're not doing the work, and you're probably not doing the work, not just on one thing.
998
You're probably not doing it.
999
So, you do try to really look at the inputs.
1000
Oh, yeah, very much so.
1001
Yeah, we evaluate the inputs just as much as the outputs.
1002
What do you do with an investor?
1003
I'm sure you've had this at some point where the inputs are not particularly good.
1004
They hit this one outlier thing.
1005
The outputs are objectively now good.
1006
And so, you're looking at that situation or the inverse.
1007
So, this is the other.
1008
So, this is the other part of it.
1009
The other part of it is I think there's just a subjective criteria for venture, which is just, are you good at it?
1010
Yeah.
1011
And,, do you have taste?
1012
Yeah.
1013
Which is unquantifiable.
1014
Isn't that one of the nice things about your model, too, where you somebody gets to make a call versus in these partnerships?
1015
I think it would be very hard when nobody gets to make calls this.
1016
Because at some point, someone has to just make a determination on this stuff.
1017
Yeah, that's right.
1018
And then, even,, even who even made the call,, gets lost.
1019
Yeah.
1020
So, so, so, I think there's a taste thing.
1021
And then, look, I think there's also just a net, there's a network cohort branding thing, which is the startups come in waves.
1022
And it's not just new technology, it's also new people.
1023
And they,, these new scenes form.
1024
And,, are you in the scene or not?
1025
Right.
1026
And if you're not in the scene,, I can't fix that for you.
1027
There's also a ton of path dependence, it seems, where,, you make an investment that gets you in the scene.
1028
Now, other founders want to work with you because you invested in this really cool company.
1029
And then it just snowballs.
1030
And you're, well, I can't go back and, change history and get you into the snowball.
1031
Yeah.
1032
Yeah.
1033, and again, this is what I'm going to call this.
1034
This is the test with the capital T.
1035
There's just different versions of the complaint, right?
1036
So you brought up the one of the founder who's, well, I could have done this, but I wasn't in a position to do it.
1037
All right.
1038
That's your own fault.
1039
There's another version of it, which is this is the anti-VC narrative: these VCs are so arrogant, they don't see my unique genius.
1040
Right?
1041
Right?
1042
You're the, the VCs are only as a critique.
1043
They always apply against Paul Graham as, he wrote this post on pattern matching and he always gets attacked.
1044
It's,, he pattern matches.
1045
He's not looking for quality, he's just looking for pattern matching.
1046
And,, it's, and it does founders don't match the pattern.
1047
It's the single, at least, raising is very important for founders to understand.
1048
Raising money from venture capitalists is the easiest thing you will ever do as a startup founder.
1049
We are sitting here with checkbooks waiting to write checks.
1050
Yeah.
1051
We are dying for the next person to walk in the door and be so great that they convince us to write the check.
1052
We don't care where they come from.
1053
We don't care what country they're from.
1054
We don't care what,, doesn't none of it matters.
1055
It's just, do they know what they're doing?
1056
Are they going to be able to do it?
1057
We're just dying for that.
1058
Everybody else they're ever going to deal with candidates and customers and downstream investors and everybody else is going to be much harder to deal with than we are.
1059
And so if they can't pass the test of raising money, they're not going to be able to do it.
1060
And it's the same thing with the GP.
1061, if you can't network your way in and make good investments, that's the job.
1062
Okay, on that point, right?
1063
Because there's going to be, I completely agree with what you just said about how it's,, the easiest part of building a company.
1064
There's going to be a lot of,, frustrated founders hearing that who are, why can't I raise,, what's going on here?
1065
One of the things that I'm really,, you've done this for enough time now.
1066
When founders get a pass note, it's usually about something that's related to the market or the product or whatever.
1067
And a lot of times it's what you just said, which is that,, I just want the founder to be great.
1068
Right.
1069
But nobody says that to them.
1070
And so they don't get the actual feedback.
1071
And so I guess this whole dynamic of people aren't giving it, because it's,, what they're saying is not you're not great, but it's I didn't perceive you as great or something that.
1072
Is there some way for there to be a more honest, useful back and forth around this?
1073
Or is it just one of the impossible structural things and founders just have to go around frustrated that people are saying their market's too small or it's too big or whatever?
1074
And really what it Is they're just not landing as great.
1075, it's, yeah,, I think you think your baby's beautiful, but I think he's really ugly.
1076
Right.
1077
Yeah.
1078, this kid's going to have a really hard time in life, man.
1079
He's really unattractive.
1080
It's really hard.
1081
It's really difficult.
1082
And by the way, you embedded two things in there.
1083
One is,, one is do they come across as good, which in theory is fixable, but the other is, some people are better than other people at doing this.
1084
Definitely.
1085
And some people should not be sure.
1086
Some people should just be on a team.
1087
Yeah, sometimes it's a correct assessment.
1088
Sometimes it's an incorrect.
1089
There are some people who in the early days can't rate.
1090, there's a lot of great people who now we all know are really great, but they couldn't raise a lot of money.
1091
So they must have shown up in six D V C meetings as not great or whatever.
1092
And look, VCs make and again, yeah, exactly.
1093
It's we don't, we don't know.
1094
Yeah.
1095
And we have to say we make lots of mistakes on a mission.
1096, so we, I said, most, even the great VCs most of the time are screwing up.
1097
And so that's all true.
1098
The thing I always tell founders is the, it's the, Steve Martin was asked this question about becoming a great stand-up comic, and he wrote this whole book, a great book called Standing Out Bush.
1099
He talks about this.
1100
And he says the secret to being a great, he said, the secret is be so great they can't ignore you.
1101
If your business gets good enough and you prove that you're really good, you don't have to show up in the one hour with the VC is impressive.
1102
You just proved it on the field.
1103
We're dying for people to come in and just be, wow.
1104
Right.
1105
And just be, I cannot believe how good this is.
1106
I can't believe how good this product is.
1107
I can't believe how much the customers love it.
1108
I can't believe how much this person has gotten done in a very small amount of money.
1109
It's the exact same thing about a talented, I'm just dying for the young community to get up on stage and make me laugh.
1110
I also think the founders who really struggled to raise a round or two and then the business got working, I think there's a real strength that comes out of that.
1111
So it's not the worst thing that ever happened.
1112
No, look, having said that, there's breakage along the way.
1113
Yeah.
1114
And also, it sucks.
1115
It's really unpleasant.
1116
Yeah, I had a habit.
1117
It sucks.
1118
Yes.
1119
So, but look, look, I just say,, I,, having been a founder,, it's an it's an incredible privilege to be in a, in a, in a, in an industry, in a world, and in a country at a time when you can do this.
1120
Yeah.
1121,, in most of history and most places, you just, this thing can't happen.
1122
And then,, look, we are genuinely trying to find the anomalies, right?
1123, our business is defined by anomalies.
1124
It is true.
1125
The thing you said about it's an audience that wants to laugh.
1126
It's totally true.
1127
So desperate.
1128
I can't wait for somebody to finally tell a good joke.
1129
So, on AI, I want to talk about not just the startup side, but maybe just some of your takes on the broader lens of AI.
1130
I guess my first question is around AI going wrong.
1131
And I know this is a very hard thing, but I'm just for fun, really curious what you think.
1132, the downside case that people are very afraid of would be something AI embodies humanoid robots, and now we have a Terminator situation on our hand.
1133
It gets agency.
1134
We have a big problem.
1135, that's one end of the spectrum.
1136
The happy path is that it's just the sickest software that anybody's ever seen.
1137
And, it's a tool that humans use and everything's great.
1138
Do you think about this?
1139
If so, do you have any opinion on it?
1140
Or are you just it's going to be what it's going to be?
1141
Start by saying it's an important new technology.
1142
Any important new technology is what they call dual use.
1143
It can be used for good things.
1144
It can be used for bad things.
1145
The shovel.
1146
It can dig a well and save your life.
1147
You can bash somebody over the head with it and kill them.
1148
Fire the computer, the airplane.
1149
The airplane can take you on a most marvelous vacation with your new spouse.
1150
It can also bomb Dresden.
1151
And so it's just,, atomic power was the big one because atomic power could be unlimited clean energy for the entire world or it could be nuclear bombs.
1152
As it turns out, there we just got the bombs.
1153
We didn't get the unlimited clean energy.
1154
And so that's just generally true.
1155
These things are double-edged swords.
1156
The question is, all right, what are you going to do about that?
1157
And are you going to somehow put it back in the box?
1158
Are you going to somehow try to constrain it and control it?
1159
The nuclear example is really interesting because there was a very big concern around, obviously, nuclear weapons and then nuclear.
1160
There's a big moral panic that developed around nuclear power.
1161
We messed up with that.
1162
We very badly messed up with it.
1163
And what happened was the green movement in the 60s and 70s created something called the precautionary principle, which is now there, which the same kinds of people are now trying to apply to AI, which basically says, unless you can prove that a new technology is definitely going to be harmless, you should not deploy it.
1164
And of course, that literally rules out everything, right?
1165
That's just no fire, no shovels, no cars, no planes, no nothing, no electricity.
1166
And so, and that is what happened to civilian nuclear power, which is they just killed it.
1167
The story I tell on that is President Nixon in 1971, the year I was born, he declared, he saw the oil crisis coming, the Middle East.
1168
He declared something called Project Independence.
1169
He said the American needs to build 1,000 nuclear power, civilian nuclear power plants by the year 2000, go completely clean, carbon zero, completely electric, cut the entire,, they had electric cars 100 years ago, so it was just obvious you just cut over to electric cars at some point.
1170
And basically we need to do that.
1171
And then we're not entangled in the Middle East and we don't need to go,, do all the stuff there.
1172
He then created the EPA and the Nuclear Regulatory Commission, which then prevented that from happening.
1173
Absolutely killed the nuclear industry in the U.S., right?
1174
And then the Germans are going through the new version of that with Ukraine, which is they keep shutting,, Europe ex-France keeps shutting down their nuclear plants, which just makes them more dependent on Russian oil.
1175
And so they end up funding the Russian war machine, which invades Ukraine.
1176
And then,, they're always worried now it's going to invade Russia.
1177
And so the social engineering, I would say the moral panic and then the social engineering that comes out of this, the history of it is been quite bad, in terms of its thinking and then in terms of its practical results.
1178
I think it would be a very, very, very big mistake to do that with AI.
1179
To regulate early.
1180
Yeah, yeah, absolutely.
1181
100%.
1182
To try to offset the risks in order to, and then cut off the benefits.
1183
So start with that as number one.
1184
Number two, just say, look, we're not alone in the world.
1185
And we knew that before, but especially after DeepSeek, we really know that.
1186
And so there is a two-horse race.
1187
This is shaping up to be the equivalent of what the Cold War was against the Soviet Union.
1188
In the last century, it is shaping up to be that.
1189
China does have ambitions to basically imprint the world on their ideas of how society should be organized and how the world should be run.
1190
And they obviously intend to fully proliferate their technology, which they're doing in many areas.
1191
And the world,, 50 years from now is going to be running on,, 20 years from now is going to be running on Chinese AI or American AI.
1192 those are your choices.
1193
You think that's how it'll basically play out?
1194
Yeah, it's going to run on one or the other.
1195
How will that play out?
1196, let's say it's one or the other.
1197
So AI is going to be the control layer for everything.
1198
So my view is AI is going to be how you interface with the education system, with the healthcare system, with transportation, with employment, with the government, with law, right?
1199
It's going to be AI lawyers, AI doctors, AI teachers.
1200
Okay.
1201
Do you want your AI teacher?
1202
You want your kids to be taught by a Chinese AI?
1203
Really?
1204
Yeah.
1205, they're really good at teaching you Marxism and Xi Jinping thought.
1206,, it's the cult, there's another way to put it, is the culture's in the weights.
1207
Yeah.
1208
Right.
1209
And so,, how these things are trained and who they're trained by,, really, really deeply matters.
1210
And so, and by the way, this is already an issue in lots of countries because they're, number one, they may not want Chinese AI, but number two, do they want super woke Northern California AI?
1211
It's another open question, right?
1212
So there are big questions on this.
1213
And so I just think there's no question,, if you had a choice between AI with American values versus the Chinese Communist Party values,, for me, it's just crystal clear where you'd want to go.
1214
By the way, there's also going to be direct military, there's a direct military version, national security version of this, which is: okay, do you want to live in a world of all CCP-controlled robots and drones and airplanes and Mars?
1215, is that really what you want?
1216
Warfare and Defense, I guess, just is going to fully go AI over the next 20 years or something.
1217
I think that's very much true.
1218
And I think this robots plus AI, basically.
1219
There's these signal.
1220
Well, there's a signal that you probably saw the Ukrainian attack on the Russian airplanes.
1221
So those are autonomous drones.
1222
And then they were doing AI targeting of structural, the right structural points to be able to attack the planes and destroy the planes.
1223
And so, yeah, 100% that's happening.
1224
This is a major issue with our defense doctrine with respect, for example, to potential invasion of Taiwan.
1225
Ukraine has been fielding AI-piloted jet skis.
1226
So they take a jet ski, take a jet ski, put an autonomous pilot on it, and they strap both explosives.
1227
And you could send out 10,000 of those against an aircraft carrier.
1228
And you could just keep sending them, right?
1229
Because there's no loss of light.
1230
You just keep sending them until you get through.
1231
And so, yeah, so the entire, I think the entire, the entire supply chain, the entire defense industrial base, all the doctrine of warfare all changes.
1232, the idea of human beings in planes or on submarines just doesn't make any sense.
1233
It's all going to change.
1234
And then the symmetry or asymmetry between defense and attack is going to change.
1235
You used the word dual use.
1236
And obviously, with previous technologies, they got used.
1237
At some point, I'm wondering, does it blend from getting used to being the user?
1238 a business, a benign business example would be if you could tell an AI, hey, I want you to,, hey, prompt, I want you to build me a software company,, make it roughly do this, serve these users, and run that for the next five years and just wire me the money to this bank account.
1239
Go.
1240
And if,, if that worked at some point,, in the middle of those five years,,, what's happening?
1241
Is it doing its own thing?
1242
Are you telling them what to do?
1243
Does that also happen in a warfare scale?
1244
And I guess that's maybe the thrust of, to me, where,, where it turns into something scarier, particularly when you get into,, the embodied version in warfare, where it's just,, the prompt is, hey, just,, fight this, fight this war for the next year or something.
1245
That's right.
1246
That's right.
1247
So the good news, the mastery version of it is straightforward, I think, which is we have U.S.
1248
law, Western law has a concept of responsibility, accountability.
1249
If you use a machine to do something, illegally is your fault.
1250
That's your problem.
1251
But by the way, if the machine goes wrong for reasons having to do with not with you, then it's a manufacturing, it's a product liability issue.
1252
The manufacturer is liable.
1253
But if you use it, if I buy a shovel and I bash you over the head with it, right?
1254
It's my,, the shovel killed you, but I'm to blame.
1255
And so I think your example of the autonomous corporation, I think legally, the legal system is perfectly prepared to deal with that, which is, yeah, it was your bot.
1256
You set the whole thing up.
1257
It's your fault.
1258
And so there's a natural constraint.
1259
I think there's a natural constraint on that.
1260
The most obvious version of the military version of the question is autonomous targeting and trigger pulling.
1261
And this has been an issue in drone warfare for the last 15 years, which is, is there a human in the loop on pulling the trigger?
1262
So predators flying overhead, da-da-da-da, sees a bad guy.
1263
Okay, how is the decision made for the predator to launch the missile on the bad guy?
1264
And by the way, the way that worked for a very long time was it had to be an Air Force combat pilot who would pull the trigger on the drone very specifically.
1265
Even if he wasn't otherwise responsible for operations of the drone, you'd still get somebody whose job it was to make those decisions in the loop.
1266
There are a lot of people in the defense field who are, it's absolutely mandatory that in all cases it is required for the human being to make the kill decision.
1267
And maybe that is the, maybe that is the correct answer.
1268
There's a very powerful argument as to why that should be the case because it's the biggest decision that any human that anybody can make.
1269
And even if you don't believe in the sky net scenarios, just the idea of a human being not being responsible for that decision sounds ethically, morally, very scary.
1270
There is a counter argument, which is human beings are really, really bad at making those decisions.
1271
It's a self-driving car thing.
1272
If it's safer than a human driver, then who's,, yeah, there will be accidents, but there's fewer.
1273
Correct.
1274
And so every post-analysis of any combat situation that you read or any war later on, you discover all these shocking things.
1275
So one is friendly fire.
1276 there's just huge amounts of deaths caused by friendly fire, people shooting at their own troops.
1277
They're confused.
1278
Number two is fog of war.
1279
It's just it turns out the commanders have very little idea what's going on.
1280
They had some battle plan and immediately go sideways.
1281
They don't know what's going.
1282
They literally don't know what's going on.
1283
They don't have the information to be able to make decisions.
1284
Everything's confusing.
1285
Number three, the physiological impact of stress, adrenaline.
1286
It's it's one thing to be on a shooting range making these decisions.
1287
It's another thing to be,, have a severe leg wound coupled with,, adrenaline,, overload, coupled with two hours of sleep the night before.
1288
And, is the human, is even the highly trained person making the decision right?
1289
Yeah.
1290
And then there's just a more basic thing, which I think this is a World War II retrospective.
1291
It's something in a lot of combat situations.
1292
It was estimated only 25% of the soldiers even fired their rifles.
1293
Wow.
1294, just generally, a lot of people just don't act.
1295
Right.
1296
And so, anyway, so the more you look at this, you're just, wow, the human being is really bad at this.
1297
And then all these other issues around collateral damage,, and they should,, accidentally shoot the civilian.
1298
And so, so, yeah, you're back in the self-driving car situation, which is, all right, if you had, if you're, if you could, if you knew you could get better outcomes by having the machine make the decision, better, safer, less loss of life, less collateral damage.
1299
And so, I, and I would say I don't believe I have an answer to this, but I think that is a very fundamental question.
1300
I guess this feeds into the next topic, which to me is: I think tech has now gotten to a place where with the government and politics, it's now undeniable.
1301
It used to be an underdog, but now for reasons this and a bunch of others, it's just too important to not be in the mix at the national stage now, which I think has really changed the dynamic even insularly for Silicon Valley.
1302
Because now,, people are looking at what people are doing, not just in tech, but pretty broadly now.
1303
Yeah, that's right.
1304
Yeah.
1305
So, I would say I deeply agree with that.
1306
I believe it is mostly our fault.
1307, the current situation is mostly our fault in tech, which is there's an old Russian old Soviet joke, which is you may not be interested in politics, but politics is interested in you.
1308
Yeah.
1309
And so, I think we, we, we, and I would include myself in this, I think we all got complacent, or a lot of us got complacent between 1960 and 2010 that basically just said we could just sit out here, we can do our thing, we can talk about how important it all is, but it's never gonna,, these are never gonna be big social or cultural or political issues.
1310
Yeah, and we can just get away with not being engaged.
1311
And then I, for all the reasons we've discussed.
1312
You're saying, and then once it was undeniable, we weren't prepared.
1313
And then we weren't prepared, and we weren't even, I would say, remotely prepared, and then they're using the metaphor, the dog that caught the bus, and the dog is being dragged behind the bus, tailpipe in his mouth, doesn't know what to do with the bus.
1314
And look,, geography, I think, has a lot to do with this.
1315
We're 3,000 miles away.
1316, it's just hard to get there.
1317
They don't come here very often.
1318
And yeah, so I guess I would say it worked.
1319
We, we always wanted to build important things.
1320
We are building important things.
1321
There are obvious political, cultural, social consequences to them.
1322
If we don't engage, nobody's going to.
1323
And then, by the way, the other thing I'll say is,, it's not there's unanimity even in the industry on a lot of these issues, right?
1324
And so there's,, I would say two giant divisions right now: big companies versus small companies.
1325
Yeah.
1326, there's often do not have aligned incentives right now and aligned agendas.
1327
And then the other is,, just on AI, obviously there's a big dispersion of views even in the industry.
1328
I guess this probably goes to why it's important for to some extent at least some VCs to have relationships with the government because big tech has the resources to do it themselves, small tech can't.
1329
And so if this is the state of the world, we, as an industry, need somebody to be doing it on behalf of little tech.
1330
Yeah, that's exactly right.
1331
That's why we're doing what we're doing.
1332
Yeah.
1333
On media in particular, I thought it was really interesting.
1334
I can't remember how many years ago, but Biology many years ago started talking about some fracturing about the relationship between tech and the media was going downhill.
1335
I think this was mostly talking about media and inside tech, but I think probably also at the major publications and at a larger scale.
1336
From my read as often,, I think this was right.
1337
And from where I sit, it seems it did continue to degrade the relationship.
1338
What's interesting to me recently is I've seen a little bit of life,, in the tech publication stuff, but it's been from the inside.
1339
And so,, Eric, who you just brought on his GP, is awesome and he's been really good at doing this.
1340
TBPN's really cool.
1341
And I don't think I've seen something that pop up maybe ever inside tech.
1342
What's your read, I guess, within our bubble of the tech-media relationship and where it's been?
1343
So, my background in this is: I,, I have a weird history because of what happened in the 90s, but, I started dealing with the national press and the tech press, business press in 1993, 1994.
1344
And I did an annual press tour to the East Coast,, probably a week out of each year, usually in the spring.
1345
And,, what that means is you go around and you meet with all the publishers, editors, and reporters,, who cover everything.
1346
And I would say basically the stretch from 94 to 2016 was generally I thought it was a quite healthy, normal, productive relationship.
1347, they would run,, they would do investigative reporting and they would run stories they don't, but generally they,, the big, the big, the major publications in each of those categories were trying to understand what was going on and were trying to be,, honest brokers and trying to,, represent what was happening.
1348
And so the meetings were super interesting.
1349
They always wanted to learn.
1350
They always had tons of questions.
1351
They were super curious about everything that was happening.
1352
That was great until 2016.
1353
It was the spring of 2017 that I went on the press tour and it was somebody had flipped a light switch and they were across the board, unbelievably hostile.
1354 unbelievably, completely, and across the board, 100% sweep.
1355
Do why?
1356
Absolute hostility.
1357
I think the obvious answer is Trump got nominated and they got elected and then they blamed Tech for both of those.
1358
By the way, there are a bunch of other factors, including that was when the, it's the, there's a business side to it, which is there was the fear that the internet was going to eat the news business in the 90s.
1359, didn't happen.
1360
And, 2015, I think, was the best year in history for revenues to newspapers.
1361
And then it was really after 2015, social networking went big, and then their businesses started to collapse.
1362
And they started having lots of layoffs.
1363
And so that didn't help.
1364
And then,, look, they would say, look, that was also,, they would say, hey, smart guy, that's also when you started doing all these things that matter more, right?
1365
And so,, everything we've been discussing, the tech industry changed.
1366
And so,, you're going to get a different level of scrutiny because you deserve it because you're doing different things now.
1367
The political thing was just a giant swamping factor.
1368
And they, and,, this was a big,, I don't want to get into the politics per se, but if you just,, this whole thing ran in parallel with everything that's in Jake Tapper's book about,,, so it's just they just, they, they got locked in on a mode of interaction that just became very polarized.
1369
Yeah.
1370
And very polarized, very lockstep.
1371
And,, from the outside, you just, you read it and you're just, wow, these people, they're all really wrapping themselves around an axle.
1372
I think one of the other hard things is as the truth has become more accessible by other people, you more often see something in the news that about and you're, wait, that's super backwards.
1373
And then somebody posts about how backwards it is.
1374
And now,, you see a clip of some major publication and here's the truth and everybody can tell.
1375
And it's, okay, so should we just believe the rest of it or not?
1376
I think the truth fact-checking went way up too with social media.
1377
That's right.
1378
And I would say there,, the clichÃ© has been, and there's some truth to the cliche that social media is where lies spread.
1379
And there's some truth to that.
1380
There's lots of lies spread on social media.
1381
But the other side of it is what you're saying, which I think is right, which is the truth spreads on social media.
1382
And so the way I describe it is social media is an x-ray machine.
1383
And exactly to your point, anytime there's a, and you see this in any domain of activity right now, is anytime there's a thing and there's just evidence that it's just not the way it's being portrayed, it is going to show up.
1384
People are going to see it.
1385
And that is, there's this guy, Martin Guru, who wrote this book called Revolt to the Public in 2015.
1386
And he was a CIA analyst who did what's called open source analysis for 30 years, which was studying basically what was in newspapers and magazines for the purpose of political forecasting.
1387
And his prediction in 2015 in his book was that basically social media was going to completely destroy the authority of all incumbent institutions.
1388
And the way that it was going to do that was it was going to reveal through this x-ray effect that basically none of them deserve the credibility.
1389
Do you think that's happened?
1390
I think that's exactly what's happening.
1391
And I think there's statistical evidence that's happening.
1392
Gallup polls, they do an annual poll now for 50 years on trust in institutions of every different major institution, including the press, and all the numbers are collapsing.
1393
In light of widespread social media, what would be the correct function or role of journalism?
1394, look, I'm a believer in the original.
1395
I the original idea, right?
1396, I don't know, I'm a romantic.
1397
I what journalism says that it is.
1398
I would it to be that.
1399
I what the universities say that they are.
1400
I would it to be that.
1401
I what the government says that it is.
1402
I would it to be that.
1403
Which should be just to name it.
1404
Yeah.
1405
Well, for journalism, it's just, all right, number one,, tell us correctly and accurately what's happening.
1406, there's a conflict at the heart of the journalism question, which is that journalists say two different things.
1407
There's one is they say,, basically be fair and objective, right?
1408
And then the other thing they say is they say,, hold power to account.
1409
Or they'll sometimes say, they have this phrase, they'll say, comfort the afflicted and afflict the comfortable.
1410
And, there's, there's an inherent tech,, are you an objective truth telling?
1411
Well, yeah, I was going to say that has nothing to do with the truth.
1412
It's just unbelievable to the truth.
1413
Exactly.
1414
And so there was already a conflict at the heart of the industry.
1415
And there's a selection process where the people who go into journalism tend to be critical by nature, right?
1416
They tend to want to be on the outside looking in, to be critical, because they wouldn't be journalists.
1417
And so, so there is an issue there.
1418
But look, do we need people to tell us the truth?
1419
Yes, we do.
1420
Do we need people to hold a powerful account?
1421
Yes, we do.
1422, I would them to do that.
1423
Do you think they can be for-profit corporations?
1424
And it works?
1425
Because, I think another problem is they're getting all their distribution on social media.
1426
Eyeballs are what drives the revenue.
1427
People want to,, stay employee,, so that also is unrelated to the truth.
1428
In fact, it's antithetical to the truth a lot of times.
1429
Yeah.
1430
So there's two mentalities come out of that.
1431
One is, yeah, the profit incentive warps it, and you want it to not have a profit incentive, so it could be true to itself.
1432
The other argument is, if you don't for-profits, you're really not going to nonprofits.
1433
Yeah.
1434
Because at least for-profits have at least for-profits have a market test.
1435
At least there's some discipline.
1436
Nonprofit just becomes somebody, this is my agenda.
1437
I'm going to do what I feel.
1438
Arbitrarily crazy.
1439
They can go arbitrarily nuts.
1440
It does sound worse.
1441
Yes.
1442
And they're completely unaccountable.
1443
They're completely unaccountable, right?
1444
In fact, it's the opposite of accountability because of the tax break.
1445
You were paid as a donor to invest in the things that are the most unaccountable.
1446
Interesting.
1447
Right.
1448
And so, and then they can spin into crazy land.
1449
Yeah.
1450
And they don't come back.
1451
I don't know if they don't come back.
1452
There's a history here.
1453
Yeah.
1454
They don't come back.
1455
And so it's weird because the citizen journalism thing is a helpful fact check.
1456
It's good to have.
1457
And sometimes, but it does feel it's not quite sufficient to tell the full story on everything all the time.
1458
So I do think that there's an important role.
1459
I just feel it still feels it's very in limbo right now.
1460
So here is a theory that would be a reason for optimism, which is the last eight years were basically, the human animal adapting to the existence of social media.
1461
It's basically the assembly of the group brain, and you slam eight billion people into a chat room together and it's just we're not used to it.
1462
We weren't wired for it.
1463
We're not involved for it.
1464
And it's just, oh my God, everything goes bananas.
1465
Marshall McLuhan,, the great media theorist, he talked about this.
1466
He had this term called the Global Village.
1467
It's what happens when everybody gets networked together.
1468
And, what people miss about it is he didn't mean in a good way because the nature of a village is basically gossip and innuendo and fighting and reputational destruction and civil war.
1469
That's what happens in a village.
1470
Which functions at a certain size.
1471
Yeah, up to 150 people, you can deal with that.
1472, at the size of New York City, it gets quite complicated.
1473
At the scale of the world, it's a disaster.
1474
It's a disaster.
1475
But you could say, look, we went through this eight-year period where everybody went, just say everybody went nuts.
1476
Everybody went nuts in a thousand different ways.
1477
And then, but maybe that was just we had to get used to it, right?
1478
Maybe we just had to adapt to it.
1479
And, if you talk to, I don't know, if you talk to young Zoomers now,, a lot of times what they'll tell you is, yeah, we don't take any of that stuff seriously.
1480
Yeah.
1481, I just, of course, you don't believe what you see on,, whatever TikTok.
1482
Yeah, which is wild.
1483
It's just all ops.
1484, of course, it's all ops,, whatever, right?
1485
And they just have their adaptive.
1486
And I'm glad people know.
1487
It's just that's a crazy state of the world.
1488
Yeah.
1489
Yeah.
1490
Yeah, exactly.
1491
So probably how people feel about the news, too.
1492
Well, so this is the thing on the news.
1493
So then this is the other thing on the news, which is, was the news ever as we were told that it was?
1494
And so my favorite example of this is people always cite Walter Cronkite as being the great truth teller.
1495
And the thing that they cite for you young people who used to be on TV.
1496
I've never heard of it.
1497
He was this guy where he would show up on TV, everybody would say, oh my God, he's going to tell you the truth.
1498 he was, he was the voice of the truth.
1499
And the way that he built that reputation is because he went negative on the Vietnam War in 1968.
1500
In 1968, he came out and he said the Vietnam War is unwinnable and we need to pull out of this.
1501
And they aired all these reports that showed that that was happening.
1502
Everybody said he's the guy who told the truth and hold power to account, tell the truth.
1503
Well, it's just the problem with that is he went negative.
1504
The fact that he went negative on the war in 1968, right, he was positive on it before that.
1505
Right.
1506
Exactly.
1507
Right.
1508
What did he know the day before he said that that he wasn't sharing?
1509
Yeah.
1510
And, and then by the way, what else happened in 1968?
1511, which is the White House went from a Democrat to a Republican.
1512
So the Vietnam War was created by Kennedy and Johnson, and then it was inherited by Nixon in 1968.
1513
And isn't it convenient and interesting that he went negative on it when it became Nixon's war as opposed to being Kennedy's and Johnson's war?
1514
And so then it's, all right,, what was going on there?
1515
What was happening in the preceding five years?
1516
And was he on his side the whole time?
1517
And then there's just the reality of it, which is, I grew up in rural Wisconsin.
1518
We always thought the press was out to get us.
1519
Yeah.
1520, we always thought the press was the coast basically passing sneering judgment on the center of the country.
1521, we never believed the stuff to start with.
1522
And we were always, where I grew up, people are super resentful of the stuff in the media and how it portrays them.
1523
And so I think there's also a more fundamental underlying issue here, which is,, objective truth is a objective truth is a high bar.
1524
Yes.
1525
People have agendas.
1526 maybe we just need to get all this out on the table.
1527
Particularly in politics, objective truth is not really how a lot of people are, oh, that's a lie.
1528
I'm, well, it's not a lie.
1529
It's just an interpretation of a situation that I wouldn't characterize, but, sure.
1530
Something that.
1531
Complicated.
1532
And these are complicated topics.
1533, the ordering of society is a complicated topic.
1534
Yeah.
1535
Right.
1536
And the functioning economy is a complicated topic.
1537
And it's just not so easy to understand.
1538
And so I think part of it might, the optimistic view would be humanity adapting to being in the global village is basically just taking on a little bit of a more humble attitude, basically saying, all right, look, there's not going to be, we're not going to have a lot of objective truth tellers running around.
1539
We're not going to have, but also at the same time, we don't want to be in a complete panic about everything all the time.
1540
And we need to be able to,, take a deep breath, touch grass, be a little bit more skeptical, be a little bit more open, be a little bit more understanding, right?
1541
And so maybe we're starting.
1542
And by the way, I think that's happening.
1543
I mentioned that Jake Tapper, without getting into partisan politics, but the Jake Tapper book, I happened to went to an event that he did this weekend out here.
1544
And, it's a that book and the reaction to the book, and if you watch the interviews on YouTube and the crowd response to that book, it feels people are just, oh, if we just take a step back for a moment from all the intense partisanship of it all, there's some, maybe we can get back a little bit more.
1545
I thought it was that book is a very positive step forward to where it's just a little bit of a calmer approach on these things.
1546
And by the way, the other book I'd promote on that is the Ezra Klein book on abundance, which I think is, I think, is somebody who's supported a lot of Democrats for a long time.
1547
I think it's the most positive manifesto that's come out, basically saying, whether you're on the right or the left, we need to build things.
1548
And I think that's also a healthy moment.
1549 related to this topic, a little bit adjacent, but I saw you talking about preference falsification recently.
1550
And I think this is a super interesting topic in general, but particularly in the last, I don't know, call it five-ish years, I think a lot of preference falsification became made apparent.
1551
So I'd be curious first to hear a little bit about what you think happened over the last some number of years where these changes happened.
1552
Maybe we can start there and then I've got to follow up on it.
1553
Yeah, so the preference falsification, just a sketch and outline, it's when people, it's, there's two different definitions, there's two different elements of it.
1554
It's when people are required to say something in public that they don't believe, or they are prohibited from saying something in public that they do believe, right?
1555
So again, so commission omission issues.
1556
And then the theory of it, there's this great book by Timur Karan on it.
1557
The theory of it basically is it's easy to think about what this happens in the case of a single person, which is, are you telling the truth or is there your public statements mirroring what you think or not?
1558
The thing that gets complicated is when that happens across a group or across a society.
1559
And the thing that happens is if there's widespread preference falsification in society, you not only have people lying about what they think or hiding it, but you also, everybody loses the ability to know what the distribution of views are.
1560
Yeah.
1561
Right.
1562
And he says basically, if you look at the history of political revolutions, a political revolution happens when a majority of the country realizes that a majority of the country agrees with them.
1563
And they didn't realize it.
1564
Right.
1565
So that whatever system they were in had convinced them that they were in a very small minority.
1566
And then you get at some point, there's the boy who points out.
1567
It's a catalyst.
1568
There's a catalyst, catalytic moment.
1569
And then basically there's what he calls a preference cascade.
1570
And then all of a sudden...
1571
It's the correct prisoner's dilemma's box to live in.
1572
All of a sudden flips.
1573
Everybody realizes it at once.
1574
Yes, exactly.
1575
And he said you can see this in you can see this in a crowd with a speaker, a controversial speaker, where basically you'll have a controversial speaker and then there'll be silence in the crowd.
1576
And then one brave person will start clapping.
1577
And that person is a severe peril because if they're the only asshole standing up clapping, that's it, they might get killed.
1578
But then if it cascades, then a second person starts clapping, and then a third and a fourth and a fifth, and then you get the snowballing effect, and then the entire auditorium is clapping.
1579
And then that's everybody realizing that they are on the side of the majority, which they didn't realize before.
1580
By the way, this is what comedy, this is by comedy song, but this is what comedy does well because people can't control the involuntary response of laughter.
1581
Yeah.
1582
And so when you get an entire group of people in a room laughing out loud at something that individually they all swear is that funny they can't help and then the stress relief from that because they all know that they're part of it they've rebonded the community right you're you're you're back and being a part of a community and it's just such an incredibly powerful feeling yeah yeah okay so so it's very easy to apply this theory to the soviet union right or The The The, the eastern europe,,,, in the cold war or whatever yeah,, Maoist china yes it's a lot,, trickier to apply this theory to,, your current society.
1583
I believe that,, we've lived in an era of intense preference falsification.
1584
I think the last five years, probably the last 10 years, were way more intense preference falsification than the preceding 40 at least.
1585, probably going back to, I don't even know.
1586, you have to go for sure back to the 60s, if not the 1920s or something to find an analogous period.
1587
I think this period was characterized both by people who were saying things they didn't believe, but critically not saying things they did believe.
1588
I think there are many reasons this happened.
1589
And look, this has happened many times in history.
1590
And so a lot of people want to say this is caused by social media.
1591
Right.
1592
Well, when you phrase it the way that you said, it makes a lot of sense when it's just if people are going to be in a part of this prisoner's dilemma matrix, it just gets caused by nothing other than itself.
1593 it doesn't really need an outside catalyst for people to get into their own box.
1594
That's true.
1595
Although there needs to be, I know that's a good question.
1596
Does there need to be some oppression?
1597
Does there need to be some motivation for the cascade to have started where people end up in that box?
1598
It's a social pressure.
1599
So yeah.
1600
Specifically, I think the thing that happened the last five years was...
1601
I guess it needs to be a high-stakes enough issue for it to matter.
1602
Otherwise, it's just, who cares whether you think the clouds are pretty or not?
1603
Yeah, that's right.
1604
So at least it has to be that.
1605
Yeah.
1606
And the way I think Team McCron would describe it is it needs to have political, social, cultural salience.
1607
It needs to get to something fundamental about how the community is organized.
1608
We call that politics, but this predates even the concept of politics.
1609
And by the way, look, you don't even necessarily want to say that all preference falsification is bad because I don't know that you want everybody out telling the truth about everything.
1610
I don't think you do.
1611
I think at least in a social, a lot of social graces come from people saying it's great to meet you when I didn't feel saying it was great to meet you.
1612
Your baby, I believe your baby is very fair.
1613
Effective, exactly.
1614
So, some of it's written.
1615
So, yeah, but yeah, as your point, you get wedgedge in this box.
1616
And so, I think the specific thing that happened.
1617
So the good news is preference falsification in a lot of totalitarian societies was administered at the point of a gun.
1618
You say the wrong thing, they shoot you.
1619
Yes.
1620
That for the most part is not what happens in our society.
1621
What happens in our society is the nonviolent version, which is ostracized, canceled, ostracized, reputation is ruined, fired, become unhireable, lose all your friends, lose all your family, can't ever work again.
1622
Still really bad.
1623
Still really bad.
1624
So you said it sounds pretty bad.
1625
Very bad.
1626
And so, and it just turned out, I think part of, the optimistic view would be part of adapting to the existence of social media was social media just turned out to be, among other things, a very effective channel to destroy people reputationally, right?
1627
And this is the social media mobbing effect, right?
1628
We're not all familiar with it.
1629
And you think that helped create basically more false preferences?
1630
Yeah, big time.
1631
Big time.
1632
Do you think it also unwound them?
1633
Well, so this is the thing.
1634
And this is maybe the thing that happened in the 2024 election, right?
1635
Which is just, oh, okay, we don't have to live this way anymore.
1636, certain views become safer to say out loud.
1637
Also, the censorship regime, we lived under a very specific censorship regime.
1638
Even in tech for 2024 election versus 2016, regardless of what you think, who you wanted, at least everybody can agree that it was taboo to support Trump in 2016, and it was not taboo to support Trump in 2024 in tech.
1639
And so something changed there.
1640
Something changed.
1641
Peter had this great line in 2016.
1642
He said, because he was one of the only people, maybe the only person in tech who was pro-Trump in 2016.
1643
And he said, he said, this is so strange.
1644
He says, this is the least controversial, contrarian thing I've ever done.
1645
He's, half the country agrees with me.
1646
He's, I've never had a point of view on anything else in my entire life where half the country agrees with me.
1647
And yet somehow this is such a heresy that I'm the only one.
1648
And so, yeah, so there was that, that that definitely changed.
1649
And then, I just think, in general, I said, I think they're optimistically, you could say there's a process of adaptation, right?
1650
Where it's just, all right, we're just, if we all just decide that we're just not going to live life by mobbing and scapegoating and personal destruction, and just because somebody's offended by something doesn't mean it's going to destroy,, somebody says one thing, it's going to destroy their lives.
1651, we don't have,, you don't have to do that.
1652
Do you think it's basically been unwound now, or do you think there are still a lot of falsified preferences?
1653
I would say it's radically different than it was two years ago.
1654
I would say there's still a lot of falsified preferences.
1655
I would, but, but again, I would say, and I think probably in any healthy society, there's lots of falsified preferences.
1656
So, do you have any guesses for something that is currently falsified that will become unfalsified, or is it too hard to call it?
1657
Sure, yeah, sure.
1658
Okay, great.
1659
Well, but it's far too dangerous to say.
1660
All right, fine.
1661
We'll move on.
1662
Yeah.
1663
Dang.
1664
Gosh.
1665
But again, when you ask that, that is a very key question.
1666
Here's what I encourage: break the fourth wall.
1667
Yeah.
1668
Here's what I would encourage people to do.
1669
Here's the thought experiment to do.
1670
Just write down two leaves in the middle of the night with nobody around, doors locked.
1671
Write it down on a piece of paper and let's pull it out in 10 years.
1672
Write down a piece of paper, two lists.
1673
What are the things that I believe that I can't say?
1674
And then what are the things that I don't believe that I must say?
1675
And just write them down.
1676
Yeah.
1677
And I bet,, if you're a reasonably introspective person,, the quote-unquote NPCs can't do this, but if you're a reasonably introspective person,, most of us probably have 10, 20, 30 things on both sides of that ledger.
1678
Right.
1679
And again, most of those are things where you've got to,, I don't know, don't want anybody to ever see that piece of paper.
1680
Maybe five or 10 years from now, we'll be back and everybody can reopen their papers and we'll see and it'll be safe to say whatever people wrote down at that point.
1681
Exactly.
1682
Okay.
1683
A few final topics I wanted to ask you about.
1684
One is you're probably in a spot to be giving just life or career advice to young people a lot now, both in general, but also maybe specifically with AI and the current set of tech,, changes right now.
1685
What do you most often find yourself repeating to a really smart,, recent grad about,, if they're, what should I be doing with my career if they get the chance to ask you that?
1686
To start with, I never took any advice.
1687
So advice is, yeah, there's something there.
1688
But a lot of people do.
1689
So maybe fair enough.
1690
That's the,, if you could have built a Facebook thing.
1691
Maybe, yeah, maybe it's maybe that, maybe the best people probably shouldn't take any advice for the rest of us.
1692
But I would just say, especially for young people, and again, I say this,, people are very different.
1693, I believe very deeply.
1694
Some people are very happy being in the middle of chaos.
1695
Some people are very unhappy.
1696
Some people are very unhappy being in the middle of chaos and they will get themselves out of a chaotic situation as fast as they can.
1697
Other people love chaos so much that if they don't have any, they will create it.
1698
Right.
1699
And so you have to, there's a level of understanding here.
1700,, not everybody should be in a high growth, high-risk tech company because it might just be too nuts.
1701
So I don't think there's a one-size-fits-all thing at all.
1702
Having said that, let's narrow it.
1703
So the young person who wants to be in tech, I think a big part of it is, I think it's, as I would say, it's run to the heat,, or the seed thing we were talking about.
1704, where are the interesting things happening?
1705
And that's a conceptual question, and it's also a place question and the community question, network question.
1706
And so,, run to that as fast as you can.
1707
And it doesn't mean running to the fads, but it means trying to identify.
1708
Trying to get into those hot network or ideas or projects, basically.
1709
Yeah, yeah, exactly.
1710
And look, there's a geographic component to that.
1711
And I think we all wish it wasn't the case, but there really is.
1712
And AI, I think, has very successfully unwound the geographic dispersion of what was happening in tech in a huge way, yeah.
1713
In a huge way.
1714
It's slammed everything back into Northern California.
1715
I don't think that's good, really, for a lot of reasons, but I think it just is the case.
1716
And so I would say,,, if you're going to do AI, get here.
1717
Yeah.
1718
And then look, and then the other thing is it's the Steve Martin thing.
1719
Be so good they can't ignore you.
1720 time spent on the margin getting better at what you do is almost certainly better than most of the other uses of time.
1721
The old adage of you are the average of the five people you spend the most time with is also true.
1722
You want to do that.
1723
So you want to pick that carefully.
1724
And then I guess what I would say is when I talk to people about what company to go to, there are certain people who should only be in a raw startup and there's certain people who should only be at a big company.
1725
I think the general advice is it's the high growth companies.
1726
It's the companies that we would describe as between being between Series C and Series E probably or something.
1727
Yes.
1728
Where it's they've hit product market fit, they've hit the knee and the curve and they're on the way up.
1729
On average, that's going to be the best place to go because you're not going to have the downside risk of a complete wipeout usually.
1730
And then people who get into that position, at those high growth companies, if you're talented, you can pick up new responsibility very quickly.
1731
Yep.
1732
Okay, next is your Andrew Huberman thing that I see on Twitter.
1733 what's, I can't completely parse what it is.
1734
What's going on with that?
1735
So we have a completely fake beef.
1736
We're good friends.
1737
We're very good friends.
1738
And we're neighbors in Malibu.
1739
And I've been on his podcast and we're very good friends.
1740
But you don't follow his protocol?
1741
I don't do anything that he says.
1742
I don't do a single thing that he says.
1743
With one exception, we'll talk about.
1744
But yeah, I don't do any of it.
1745
He says maintain a regular sleep schedule.
1746
There's no place.
1747
You're all over the place.
1748
He says, always get up,, get up,, see sunlight as early as you can.
1749
I'm, no, I don't want, it's a sea sun.
1750
The last thing I want to do when I wake up is see sunlight.
1751
You don't drink caffeine for the first two hours of the day.
1752
It's NFW.
1753
It sounds torch.
1754
It sounds being in a North Korean concentration camp.
1755, I can't even imagine.
1756
Do you drink a lot of coffee?
1757
A lot of coffee.
1758
Hot plunge, cold plunge thing.
1759
I'm not.
1760
The cold plunge is miserable.
1761
I'm not doing any of that shit.
1762
Yeah.
1763
Do you think it's good for you, though?
1764
Oh, I'm sure it's good for you.
1765
I'm just not, I'm not going to do any of it.
1766
It all sounds just completely miserable.
1767
That's good.
1768
The one thing that he says that I do is stop drinking alcohol.
1769
And I would say I am physically much better off as a result, but I'm very bitter and resentful.
1770
It is poor.
1771
Towards him specifically.
1772
Why'd you do that one?
1773
Because it's much better for you physically.
1774
It really is.
1775
It fixes sleep and energy problems.
1776
So it's the most tolerable of all of these.
1777
And you're, fine, I'll do one.
1778
Well, no, no, it's completely intolerable.
1779
It's horrible.
1780
Okay.
1781
I don't recommend it.
1782
I think it's a horrible way to live.
1783
I'd much rather be drinking alcohol.
1784
Does he think even a glass of wine at night's bad?
1785
He does, yeah.
1786
Just all of it.
1787
He did one of the great, he's had, I think, big influence on the culture.
1788
And this is very, in seriousness, this is very positive, I think, at least for health.
1789
He did this big thing.
1790
There's all these alcohol.
1791
So what happened is there's all these alcohol, there's all these fake alcohol studies, basically.
1792, it says red wine, and then it's all heart protective and all this stuff.
1793
And it basically, it basically turned out that really sick people either drink a lot or nothing.
1794
And then healthy people tend to drink a little.
1795
Yeah.
1796
Right.
1797
So one is healthy people tend to be very well disciplined.
1798
Right.
1799
And then I guess is that correlation or causation?
1800
It's all in the sample set.
1801
So it turns out there's no health benefits to alcohol.
1802
That was all completely fake.
1803
In other words, just because healthier people drink a moderate amount of alcohol does not mean that drinking a moderate amount of alcohol makes you healthy.
1804
I see.
1805
Michael Crichton called this: wet streets cause rain.
1806
Okay.
1807
Wet streets, rain.
1808
Yes.
1809
Right.
1810
So for some reason, unhealthy people stop drinking alcohol.
1811
Unhealthy people stop drinking because they're,, I can't handle this.
1812
Their doctor says if you keep drinking, you're going to die.
1813
Or, by the way, they drink a lot, right?
1814
Because they're right.
1815
And then there's this fundamental thing, which is healthy people tend to be very disciplined.
1816
But discipline is not, discipline is, there's a big inherent component to it.
1817
Yeah.
1818
Right.
1819
And so people who are disciplined, people who are disciplined who drink moderate amounts of alcohol also do moderate amounts of exercise, also experience moderate amounts of stress.
1820
Also,, you go to the doctor on a regular basis.
1821
They take the medication they've prescribed.
1822
They live all aspects of their health in it.
1823
I guess it'll take a while to see, but it feels it should be a good thing that Andrew and other people have gotten so many more people interested in health.
1824
It's good for it's good physically.
1825
Right.
1826
Yeah.
1827
Might not be good mentally.
1828
No, I'll try.
1829
I'll be funny again.
1830
It's catastrophic emotionally.
1831
It's made me a much less happy person.
1832, you think that well, so I really, it's the alcohol is a time thousands of years.
1833
People have been using it, number one, to fundamentally relax.
1834
And then there's a very important social lubricant component to it.
1835
And the de-stressing could be healthy.
1836
Well, let's just say maybe it's not accident that the birth rate is crashing at the same time that we all stop breathing.
1837
I don't think Andrew would argue you should not live your life purely maximizing for just physical health.
1838
That'd be a miserable way to live.
1839, it's, what are you going to do?
1840
Just never leave the house, never take the risk crossing the street.
1841
And so,, he certainly doesn't judge people for drinking moderate amounts of alcohol.
1842
He just says, look, scientifically, you have to understand it is a poison.
1843
Now, having said that, as, speaking of scenes, as, the displacement thing that's happening is people are in our world, they're not drinking alcohol.
1844
Instead, they're doing hallucinogens.
1845
Why are you saying that is not necessarily an improvement?
1846
Because you, Jack, I know very little.
1847
Yes.
1848
Yes, tell us about your latest ayahuasca.
1849
Yeah, you're so much different than you were last time, I saw this.
1850
Your personality has clearly completely changed.
1851
I do feel different.
1852
So the other theory would be there's a law of conservation of drug use, which is every society is going to pick some drug and abuse it.
1853
And apparently, in our case, it's going to be LSD and mushrooms.
1854
It's a good one.
1855
Okay.
1856
Okay.
1857
My last question.
1858
When I tweeted out a request for questions, I got almost ratioed by one question.
1859
So I'm going to ask this one nearly verbatim.
1860
It was by an anon named Signal if you were frozen for a hundred years and you woke back up and you looked around what would be the piece of data that you'd want to know that would tell you whether or not your dominant worldview turned out to be correct in the fullness of time.
1861
Yeah, so I will pick a very unfashionable answer to this, and I would say United States GDP, just straight out U.S.
1862
GDP, because I would say embedded in that is the question of technological progress, which is if you have rapid technological progress, you'll have rapid productivity growth, which means you'll have very rapid GDP growth.
1863
If you don't, you won't have rapid GDP growth.
1864
So you'll see that in the GDP numbers immediately.
1865, number two is,, well, number two would be just our market's a great way to organize.
1866
And the U.S.
1867
is the best market.
1868
And so,, is that going to keep working?
1869
And then third is, is the U.S.
1870
going to be a great country?
1871
And you're along all of this?
1872
I am very long, all three of those.
1873
I am very convicted on all three of those.
1874
But,, if I'm wrong about something big, it's going to be something in there and it will show up in that number.
1875
Mark, this is amazing.
1876
Thank you so much again.
1877
Good.
1878
Awesome.
1879
Thank you, Jack.
1880
Thanks for listening to the A16Z podcast.
1881
If you enjoyed the episode, let us know by leaving a review at rate thispodcast.com slash A16Z.
1882
We've got more great conversations coming your way.
1883
See you next time.