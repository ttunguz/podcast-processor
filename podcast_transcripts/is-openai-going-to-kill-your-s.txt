--- METADATA START ---
Show: The AI Daily Brief (Formerly The AI Breakdown): Artificial Intelligence News and Analysis
Episode: Is OpenAI Going to Kill Your Sâ€¦
Host: Unknown
GUESTS: None 
Guests: None
Source URL: https://podcasts.apple.com/us/podcast/is-openai-going-to-kill-your-startup/id1680633614?i=1000711768326
--- METADATA END ---

1
Today on the AI Daily Brief, is open AI going to kill your company, even if by accident?
2
Before then in the headlines, is human customer service a VIP thing in the future?
3
The AI Daily Brief is a daily podcast and video about the most important news and discussions in AI.
4
All right, friends, quick announcement section.
5
First of all, thank you to today's sponsors, KPMG, Blitzy, Vanta, and Superintelligent.
6
And if you are looking for an ad-free version of the show, go to patreon.com/slash AI Daily Brief.
7
One other note before we dive in.
8
Believe it or not, even though it's only June, we are quickly selling sponsor slots for the fall.
9
If you are interested in sponsoring the AI Daily Brief, shoot me a note, nlw at breakdown.network with the word sponsor in the subject.
10
For now, though, let's get into the headlines.
11
Welcome back to the AI Daily Brief Headlines Edition, all the daily AI news you need in around five minutes.
12
We kick off today with the latest from Klarna.
13
Quick TLDR on their AI transformation if you haven't been following along.
14
A couple of years ago, the company set out to rip out their SaaS services and use AI coding to replace them.
15
Then the company also laid off around 700 customer service workers to replace them with AI chatbots and voice agents.
16
Recently, however, it seemed like they had been going back to a more hybrid structure where there would be a combination of AI service and human customer service.
17
And CEO Sebastian Semitkowski seems to be thinking along those lines.
18
At the London edition of the South by Southwest conference, he said, Two things can be true at the same time.
19
We think offering human customer service is always going to be a VIP thing.
20
We can use AI to automatically take away boring jobs, things that are manual work, but we are also going to promise our customers to have a human connection.
21
Basically, the plan is to combine the best of both worlds, which seems to me to be exactly the pattern that we're likely to see in other areas.
22
Now, Semitkowski also noted that the company's engineering positions haven't shrunk as much as other departments, even though they're all using AI to increase their productivity.
23
He did note that, quote, what I'm seeing internally is a new rise of business people who are coding themselves.
24
I think that category of people will become even more valuable going forward.
25
Going a little bit deeper, Semitkowski was not arguing that all of a sudden business people are going to replace the coders, but that by being able to code even in a very basic manner, they're better able to understand and communicate the specs of what they need to be built.
26
This would mirror the pattern that we're seeing certainly in Super Intelligent and lots of other startups, where feature discussions are now entirely had with prototypes thanks to things like Lovable and Bolt.
27
So, for those keeping score at home, we are still very in the midst of this transformation, but Clarita continues to be an interesting case study for those who want to see how this all might shake out.
28
Moving over to Redmond, Washington, Microsoft has reshuffled their executive lineup for a big push in enterprise agents.
29
Interestingly, Ryan Rolansky, the CEO of the LinkedIn division, has been appointed to lead the teams in charge of the Office productivity suite.
30
Rolansky has been at the head of LinkedIn since 2020, leading a big growth push, and within office, he will be tasked with speeding up the deployment of AI tools and driving enterprise adoption.
31
His new role will report into Rajas Ja, one of the company's top engineering executives who was given responsibility for consolidating AI tools and platform groups in January.
32
Charles Lamana, who runs the Dynamics 365 line of sales and business planning software, will also be transferred from the cloud division to JAW's team.
33
It sort of sounds like Microsoft is bringing everything enterprise agents under JA while appointing a proven leader to shepherd the agentic iteration of the office suite.
34
One question that's not clear is where Mustafa Suleiman fits in all of this shuffle.
35
Suleiman was, of course, the big ticket acquisition in March of last year and appointed the CEO of Microsoft AI.
36
His work seems now primarily focused on consumer applications of AI, with Suleiman envisioning a personality-filled AI companion.
37
It's worth noting that we are dealing with wildly divergent trends with AI right now.
38
On the one hand, it is obviously incredibly potent and powerful for the enterprise, and that's where a lot of our attention certainly is.
39
But consumers are using these tools in totally different ways.
40
Life coaching, relationship support, lightweight therapy.
41
These use cases are growing as fast as anything in the enterprise.
42
which can be kind of headspinning for a company that's trying to deal with all of that at once.
43
Moving over into the hardware side of the business, AMD has NVIDIA in its sites with a new acquisition.
44
The chipmaker has acquired an AI software optimization startup called Briam for an undisclosed amount.
45
The company was acquired while it was still in stealth mode, but according to their bare bones website, they're working on, quote, enabling ML applications on a diverse set of architectures and unlocking the hardware capabilities through engineering choices made at every level of the stack, from model inference systems through runtime systems and ML frameworks to compilers.
46
If your brain melted with all of that jargon, they appear to be creating software that allows AI models to run on a variety of different hardware.
47
In a press release, AMD said that the acquisition will help fulfill its commitment to, quote, building a high-performance open AI software ecosystem that empowers developers and drive innovation.
48
Open is certainly the key word for the second-ranked AI chip manufacturer.
49
One of the biggest roadblocks for AMD hasn't just been about matching the performance of NVIDIA's chips, but rather overcoming compatibility issues.
50
Most of the world's LLMs are built on NVIDIA's CUDA platform and optimized to run on their hardware and software.
51
In that regard, Briam feels like a natural fit to solve AMD's problem.
52
In that sole blog post from their website published back in November, they specifically referenced the chipmaker writing, In recent years, the hardware industry has made strides towards providing viable alternatives to NVIDIA hardware for server-side inference.
53
Solutions such as AMD's Instinct GPUs offer strong performance characteristics, but it remains a challenge to harness that performance in practice as workloads are typically tuned extensively with NVIDIA GPUs in mind.
54
The issue is so prominent for AMD that CEO Lisa Su drilled the point home during a recent hearing in Congress.
55
She said that for the US to remain a leader in AI, there needs to be a commitment to open ecosystems that allow, quote, hardware, software, and models from different vendors to work together.
56
This accelerates innovation, reduces barriers to entry, strengthens security through transparency, and creates healthier, more competitive markets.
57
So, will this acquisition make a difference?
58
Only time will tell, but for now, that is going to do it for today's AI Daily Brief Headlines Edition.
59
Next up, the main episode.
60
Today's episode is brought to you by KPMG.
61
In today's fiercely competitive market, unlocking AI's potential could help give you a competitive edge, foster growth, and drive new value.
62
But here's the key: you don't need an AI strategy.
63
You need to embed AI into your overall business strategy to truly power it up.
64
KPMG can show you how to integrate AI and AI agents into your business strategy in a way that truly works and is built on trusted AI principles and platforms.
65
Check out Real Stories from KPMG to hear how AI is driving success with its clients at www.kpmg.us/slash AI.
66
Again, that's www.kpmg.us/slash AI.
67
This episode is brought to you by Blitzy.
68
Now, I talk to a lot of technical and business leaders who are eager to implement cutting-edge AI, but instead of building competitive moats, their best engineers are stuck modernizing ancient code bases or updating frameworks just to keep the lights on.
69
These projects, like migrating Java 17 to Java 21, often means staffing a team for a year or more.
70
And sure, co-pilots help, but we all know they hit context limits fast, especially on large legacy systems.
71
Blitzy flips the script.
72
Instead of engineers doing 80% of the work, Blitzy's autonomous platform handles the heavy lifting, processing millions of lines of code and making 80% of the required changes automatically.
73
One major financial firm used Blitzy to modernize a 20 million line Java code base in just three and a half months, cutting 30,000 engineering hours and accelerating their entire roadmap.
74
Email jack at blitzy.com with modernize in the subject line for prioritized onboarding.
75
Visit blitzy.com today before your competitors do.
76
Today's episode is brought to you by Vanta.
77
In today's business landscape, businesses can't just claim security, they have to prove it.
78
Achieving compliance with a framework like SOC2, ISO 27001, HIPAA, GDPR, and more is how businesses can demonstrate strong security practices.
79
The problem is that navigating security and compliance is time-consuming and complicated.
80
It can take months of work and use up valuable time and resources.
81
Vanta makes it easy and faster by automating compliance across 35 plus frameworks.
82
It gets you audit ready in weeks instead of months and saves you up to 85% of associated costs.
83
In fact, a recent IDC white paper found that Vanta customers achieve $535,000 per year in benefits, and the platform pays for itself in just three months.
84
The proof is in the numbers.
85
More than 10,000 global companies trust Vanta.
86
For a limited time, listeners get $1,000 off at Vanta.com/slash NLW.
87
That's vanta.com/slash NLW for $1,000 off.
88
Today's episode is brought to you by Super Intelligence, specifically agent readiness audits.
89
Everyone is trying to figure out what agent use cases are going to be most impactful for their business, and the agent readiness audit is the fastest and best way to do that.
90
We use voice agents to interview your leadership and team and process all of that information to provide an agent readiness score, a set of insights around that score, and a set of highly actionable recommendations on both organizational gaps and high-value agent use cases that you should pursue.
91
Once you've figured out the right use cases, you can use our marketplace to find the right vendors and partners.
92
And what it all adds up to is a faster, better agent strategy.
93
Check it out at bsuper.ai or email agents at bsuper.ai to learn more.
94
Welcome back to the AI Daily Brief.
95
One of the more persistent memes throughout the recent history of Gen AI, basically the post-ChatGPT period, has been this idea of OpenAI killing all startups.
96
This was even the subject of a Y Combinator podcast episode back in 2023 called Will OpenAI Kill All Startups?
97
Now, initially, the context was that in the wake of ChatGPT being released, there were a ton of companies that were either A, very, very thin wrappers on top of ChatGPT, or B, trying to fill in very specific gaps in the ChatGPT product.
98
One really notable example of this was the talk with your docs type apps, of which there were a bajillion before ChatGPT could interact with PDFs.
99
Now, obviously, that was going to be a feature that was somewhere on the roadmap.
100
And that even ultimately led to these statements from Sam Altman.
101
Fundamentally, there are two strategies to build on AI right now.
102
There's one strategy, which is assume the model is not going to get better.
103
And then you kind of like build all these little things on top of it.
104
There's another strategy, which is build assuming that OpenAI is going to stay on the same rate of trajectory and the models are going to keep getting better at the same pace.
105
It would seem to me that 95% of the world should be betting on the latter category, but a lot of the startups have been built in the former category.
106
And then, when we just do our fundamental job, which is make the model and its tooling better with every crank, then you get the OpenAI killed my startup meme.
107
Now, this meme came up big time again in the context of yesterday's product announcements.
108
This is what I had featured in the headline section of the show, but the announcement had only just happened, so I hadn't had much of a chance to digest.
109
And as people did dig a little bit deeper into this, this meme of OpenAI killing startups came back.
110
Sudhi Chilapagari from Battery Ventures writes: Great set of product announcements from OpenAI today: Enterprise Search, Glean, Meeting Note Taker, Granola, IDE, WinServe.
111
What's next?
112
Calendar, spreadsheet, email.
113
This validates that LLM is a commodity and the real money and moat lies in the application layer.
114
So, let's talk briefly about a couple of the features that were announced yesterday and the startups that people pointed to as potentially threatened because of this.
115
The new connectors feature allows ChatGPT to interact with other data sources.
116
This is only available inside business accounts first, and this basically gives that sort of chat with your docs experience that people have been interested going all the way back to those wrapper companies.
117
More recently, though, the idea of enterprise search as a use case for AI has been a huge priority for a lot of enterprise AI-focused companies, notably Glean, who was mentioned in that tweet.
118
ChatGPT building that sort of functionality natively into their core enterprise experience does bring up the question of whether you're going to want or need an additional search experience outside that.
119
Professor Ethan Malik wrote: So, OpenAI Deep Research can connect directly to Dropbox, SharePoint, etc.
120
In my experiments, it feels like what every Talk to Our Documents rag system have been aiming for, but with O3 smarts and easy use.
121
I haven't done robust testing yet, but impressive so far.
122
When it quotes a document, that link actually takes me to the document.
123
I think it's going to be a shock to the market, since Talk to Our Documents is one of the most popular implementations of AI in large organizations, and this version seems to work quite well and costs very little.
124
Now, of course, Glean is not just a talk to your documents company.
125
It is an all-in-one work AI platform that ranges from an assistant to agents and more.
126
But it is certainly the case that the more the core products like ChatGPT start to nibble at the edges of these offerings, the more confusing it's going to be for some percentage of enterprise buyers who think to themselves, well, let's just stick with the company that's offering it alongside the core models.
127
If anything, the note-taker announcement seemed to get a lot more chatter.
128
This is, I think, because people absolutely love Granola.
129
Granola advertises itself as the AI notepad for teams and back-to-back meetings.
130
And even in a world of a million native meeting recorders with things like Otter and Fireflies and Fathom, Granola has started to carve itself out a nice little niche.
131
If you go search around Twitter slash X, you can find lots of people talking about what they love about Granola.
132
One of the benefits is that it doesn't place a bot inside your calls.
133
It just captures audio directly.
134
And so yesterday, people definitely took note when OpenAI announced ChatGPT record mode.
135
Remember, the tweet was, we're rolling out ChatGPT record mode to team users on Mac OS.
136
Capture any meeting, brainstorm, or voice note.
137
ChatGPT will transcribe it, pull out the key points, and turn it into follow-ups, plans, or even code.
138
Roblo writes, in other news, OpenAI is trying to kill Granola and every other AI meeting notes app.
139
Zach Kukoff writes, Granola getting sherlocked by OpenAI.
140
At some point, model providers are going to need to decide if they want to be stable platforms or compete for every vertical.
141
Platform risk has never been higher.
142
Now, Zach also mentioned another thing in this same domain which has been going on lately.
143
He says, on the heels of Anthropic throttling WinSurf's access to Cloud4.
144
A couple of days ago, Varun Mohan, the CEO of WinSurf, tweeted, With less than five days of notice, Anthropic decided to cut off nearly all of our first-party capacity to all Cloud 3.x models.
145
Given the short notice, we may see some short-term Cloud 3.x model availability issues, as we have very quickly ramped up capacity on other inference providers, but we believe we have now secured sufficient near-term capacity.
146
We've been very clear to Anthropic that this is not our desire.
147
We wanted to pay them for the full capacity.
148
We were disappointed by this decision and short notice.
149
A day later, WinSurf's head of product engineering, Kevin Howe, writes, Yes, Anthropic completely cut our Cloud 3.x and Cloud 4 capacity.
150
By way of backstory, he writes, we had less than five days' notice and no choice in the matter.
151
We strongly expressed our disappointment and our desire to continue supporting and promoting Cloud 3.x and 4 via their first-party API.
152
Our goal has and always will be to provide the best product, period.
153
As part of that, we've always prided ourselves on providing access to all models.
154
Kevin goes on to say that they're working with other third-party providers to try to bring the Cloud models to their paying users.
155
Kevin also writes, quote, We have significantly improved our agentic harness around Gemini 2.5 Pro and GPT 4.1.
156
By the way, Google AI Studio lead Logan Kilpatrick had responded to the CEO's post with a Gemini handshake emoji WinSurf response.
157
Kevin concludes, ultimately, as any user can attest, the magic of Windsurf has always been in the product.
158
It's important to power our product with great models, but the real magic is in the deep contextual understanding of existing knowledge, thoughtful UX, tool integrations like previews and deploys, customizations like workflows and memories, enterprise readiness, jet brains, and the list goes on and on.
159
And this is exactly the question.
160
In the new world that we operate in, what are the moats?
161
Going back to Zach Kukoff's tweet again, remember he wrote, At some point, model providers are going to need to decide if they want to be stable platforms or compete for every vertical.
162
Battery Venture Sudhi writes, this validates that LLM is a commodity and the real money in Moat lies in the application layer.
163
This certainly seems to be the pattern that the Frontier Labs, at least the startup versions, Anthropic and OpenAI, are embracing.
164
Yes, obviously they continue to compete for model dominance.
165
Anthropic, for example, has really leaned into the fact that it has the preferred coding model, but these companies are also releasing actual applications.
166
They are not just playing the role of platforms.
167
OpenAI has slowly but surely been releasing a set of what are effectively consumer applications that live inside ChatGPT.
168
One might consider image generation a version of this, but certainly deep research, operator, now codecs.
169
These are OpenAI's first forays into owning the application layer, not just the model layer.
170
Similarly, Anthropic is not just interested in being the model provider.
171
With Cloud Code, they are directly competing with some combination of the latter-day IDEs and the Vibe coding platforms.
172
Again, it's pretty clear that they value owning some part of the application layer and the relationship with customers.
173
There are really big implications for what the Frontier Labs decide to do vis-a-vis agents.
174
The single most dominant theme in venture investing right now is vertical AI agents, verticalized based on specific sector or specific function.
175
The question is, how many of those are the Frontier Labs and hyperscalers going to go after?
176
And what, if anything, can actually differentiate and allow those companies to become integrated in a way that they're not just eventually punched out by those bigger players.
177
There was an interesting discussion from about a year and a half ago on Hacker News around what is a 2024 to 2030 moat for AI.
178
One of the most popular answers said the moats are network effects, switching costs, economies of scale, low-cost producer, and brand.
179
And what you'll notice is not here, and this has become kind of conventional wisdom at this point, is unique or differentiated technology.
180
Basically, there is a sense that technology itself is getting commoditized.
181
And so it will be other things that allow companies to compete.
182
I also saw this post from enterprise VC Ashu Garg, who writes, I had lunch with a founder last week who pitched me on their AI for operations platform.
183
I stopped them three slides in.
184
General purpose AI isn't cutting it anymore.
185
DeepSeek's January breakthrough told us something important.
186
Efficiency and performance can coexist a lot earlier than most people thought.
187
Startups are now excelling not by scale but by focus.
188
They're building vertical AI that deeply understands the messy high-stakes workflows in sectors like healthcare, finance, and defense.
189
Specialization is the new competitive advantage.
190
Three patterns I'm tracking across successful vertical AI startups.
191
First, they pick massive but high-friction and high-value workflows.
192
AI for sales or AI for operations is too broad.
193
What's effective is focusing on urgent complex processes.
194
Second, they build more than model wrappers.
195
They create proprietary feedback loops and data assets that compound over time.
196
This instrumentation is what turns a one-off tool into a durable, defensible product.
197
Third, they expand from beachheads of earned trust.
198
They wedge into multi-billion dollar industries by solving problems in the hardest, least glamorous corners.
199
From there, they earn the right to expand and unlock bigger TAM over time.
200
I don't know if that's the exact answer or the only answer, but I do know that whatever the answer is to this, it's going to shape how the industry evolves over the next several years.
201
Browser company CEO Josh Miller writes: Weird convergence in tech.
202
Notion adds AI research, meeting notes, enterprise search.
203
So do Atlassian, Grammarly, Coda, Glean, and Granola.
204
OpenAI buys Windsurf and Codex, GitHub, and Google follow.
205
Browsers are next.
206
Is the future this obvious?
207
Everyone's converging.
208
He continued in another tweet: It feels like everyone is bundling into a handful of AI super apps of sorts.
209
Coding, IDE, agent, et cetera, work, docs, enterprise search, meeting notes, assistant, AI chat, search browser, etc.
210
The point is, things are going to get more and less messy.
211
Companies are going to find themselves in competition in ways that they didn't anticipate.
212
And we are just now figuring out what the post-technology moat world looks like.
213
If there is any good news for startups, it's that these moments of chaos and transition tend to benefit the nimble more than the big and lumbering.
214
And so who knows?
215
The changes in moats may be exactly to some of these new startups' tastes, if they can just figure out what the new moats are going to be.
216
I think it's too early to say that OpenAI is going to kill all the startups, even that they are now competing with by virtue of the announcements yesterday, but things certainly just got even more interesting.
217
For now, that is going to do it for today's AI Daily Brief.
218
Thanks for listening or watching, as always.
219
And until next time, peace.
220
Yeah.