--- METADATA START ---
Show: N/A
Episode: Microsoft CPO: If you aren’t p… - Lenny's Podcast: Product | Growth | Career
Host: Lenny Rachitsky
GUESTS: Aparna Chennapragada 
Guests: Aparna Chennapragada
Source URL: https://podcasts.apple.com/us/podcast/microsoft-cpo-if-you-arent-prototyping-with-ai-youre/id1627920305?i=1000708881684
--- METADATA END ---

I have a cheesy Chrome extension. Literally, whenever I open a new tab, it just says, How can you use AI to do what you're going to do right now? How do you see the future of product development being different? If you're not prototyping and building to see what you want to build, I think you're doing it wrong. It becomes even more important to have that editorial and tastemaking at the heart of it, because otherwise, you just have Frankenstein products. There's this acronym that you taught me, NLX. What is that? Natural language interface. NLX is the new UX. Often I hear product builders say, oh, yeah, with AI, like the model leads the products. That doesn't mean it's not designed. You and I are having a conversation. It's a podcast. I'll have another conversation at Microsoft, and that's a meeting. Conversations also have grammars, they have structures, they have UI elements. They're invisible. What are the new principles, new constructs in natural language as an interface? I just saw that Cursor hit 300 million ARR in two years. Interestingly, you guys were very well positioned to do really well in this AI coding tool space, you guys said. Copilot, the first tool in the world at this stuff. So ahead of everyone, what happened? I would say. Today, my guest is Aparna Shinapragada. Aparna is chief product officer at Microsoft, where she oversees AI product strategy for their productivity tools and their work on agents. Previously, she was chief product officer at Robinhood, vice president at Google, where she worked on Google Lens, search, shopping, augmented reality, AI assistant, and a lot more. She was also a longtime engineering leader at Akamai and on the board of eBay and Capital One. In our conversation, we chat about how working in B2B is like being Jean-Claude Van Damme doing the splits across two moving trucks, how she's operationalizing her team living in the future so that they're building towards where things are going, why people still need to learn to code, why the PMRAL isn't going anywhere, why NLX is the new UX, and so much more. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. Also, if you become an annual subscriber of my newsletter, you get a year free of products, including linear, superhuman, notion, perplexity, and granola. Check it out at lennysnewsletter.com and click bundle. With that, I bring you a parta shadapregada. This episode is brought to you by EPPO. Eppo is a next-generation A-B testing and feature management platform built by alums of Airbnb and Snowflake for modern growth teams. Companies like Twitch, Miro, ClickUp, and DraftKings rely on Eppo to power their experiments. Experimentation is increasingly essential for driving growth and for understanding the performance of new features. And Eppo helps you increase experimentation velocity while unlocking rigorous deep analysis in a way that no other commercial tool does. When I was at Airbnb, one of the things that I loved most was our experimentation platform, where I could set up experiments easily, troubleshoot issues, and analyze performance all on my own. Eppo does all that and more with advanced statistical methods that can help you shave weeks off experiment time, an accessible UI for diving deeper into performance, and out-of-the-box reporting that helps you avoid annoying, prolonged analytic cycles. Eppo also makes it easy for you to share experiment insights with your team, sparking new ideas for the A-B testing flywheel. Eppo powers experimentation across every use case, including product, growth, machine learning, monetization, and email marketing. Check out EPO at getepo.com slash Lenny and 10x your experiment velocity. That's get eppo.com/slash lenny. This episode is brought to you by Pragmatic Institute, the trusted leader in product expertise. Pragmatic Institute helps product professionals turn ideas into impact through proven courses, workshops, and certifications designed for real-world success. For over 30 years, equipping them with practical strategies to build and scale market-winning products. Pragmatic's full-time instructors each bring over 25 years of hands-on leadership experience, teaching strategies proven to deliver real-world results. And it's not just about what you learn, it's also about who you learn it with. Completing a course connects you to an active community of over 40,000 product professionals. You'll engage in meaningful conversations, collaborate with peers and mentors, and gain direct instructor access to refine your strategies and stay ahead of trends. Get 20% off with code Lenny20 at pragmaticinstitute.com/slash Lenny. Aperna, thank you so much for being here and welcome to the podcast. Thank you, Lenny. Thanks for having me. When I asked a lot of people that work with you what I should ask you about and what I should know about you, something that came up again and again is something that I think most people don't know about you, which is that you're big into stand-up comedy and you take it semi-seriously. Just how serious are you about this? How much of your life is this? And most importantly, how does this help you build better products? It's hard to say I'm serious about a funny business, but I do watch and do stand-up comedy. I do Open Mics. I've done a few shows. I have one set brewing that is around AI, unsurprisingly, AI and tech and Silicon Valley. You know, it's really interesting for me. This was an accidental discovery. Like, I'd always been an SNL fan and like just a comedy fan, but I went to an open mic because, you know, my son sings and he went to the open mic for a try. And I found that I enjoyed it and was good at it. To your question, though, about building better products, I'd say both have PMF. I mean, product market fit, punchline market fit. But actually, there are a couple of things that I do find really powerful and useful because, you know, in open mics, or even when you're testing these things, it's a very tight cycle of iteration. And you get live, like open mics are the real-life experiments, right? You put something out there, you get very clear microfeedback from users, and then you get tough feedback sometimes. And I think, as product builders, that's actually one of the great skills to have, which is, yeah, you sometimes launch stuff that you know have a fantastic vision, but the first version is not quite there, right? And Reid Hoffman says this: hey, if you don't launch the first version and are not embarrassed, you're doing it too slow. Just that gap and closing that, it's good resilience. Yeah, I never saw these corollaries between these two things. I didn't realize you actually did like shows and you're working on a set. I wasn't going to ask you for a joke, but if you're working on a whole thing about AI, is there something that you can share from that set? One joke I'd maybe share is people think about these AI chat products as women because you don't know what's going on, it's a black box, and you don't know what they're thinking. There's like an entire set around that. But obviously, on the flip side, too, that they're probably more like men in the sense that they hallucinate a lot, they kind of are not yet reliable. I'm gonna laugh at this a little bit. This is great. This is good. Where are we going to be seeing this show, by the way? TV2. This is great. Okay. Let's get serious again. So, you worked most of your career at a lot of consumer internet companies. You worked at Google, Robinhood. You're on the board of eBay, you're on the board of Capital One. Now you're at Microsoft. I'm curious, just what is most different about working at a company like Microsoft and building product at a company like Microsoft? I think intellectually, I knew that, hey, enterprise, particularly the area that I look at most at Microsoft, is focused on enterprise and productivity and transforming companies to AI. And to me, I think two things really strike as very different. One, in fact, I just posted about this the other day saying in consumer, you're kind of like, oh, you have a playbook for make the product work or make the feature work and make it delightful. But I think in the enterprise, you almost have, every time you think you have one use case, you have really two, which is how do you make sure that the feature works well and there's governance of the feature, right? If you think about like even something as simple as sharing a link to a document, you want it to be easy, frictionless, but at the same time, you want that to be secure and kind of safe and being able to have auditability and all of those things. And often I find that when you go from consumer to enterprise, you fall into a trap of either disregarding that and say, oh, you know, we'll just focus on one side of the house, or kind of overly crippling the user experience, right, and kind of leaning on the other side. So I think there's an art and science and nuance and playbook there too. The other learning, and especially in the AI era for me, has been about this, you know, I think there's a famous trailer from the 2000s on Van Dam on these like two trailer, two buses, yeah, doing the splits, exactly. And I feel like a lot of the companies, including the tech companies, but certainly the enterprises that I talk to, are in these two modes. Where one hand, this is the most compressed tech cycle that we've ever experienced, right? It's in the order of weeks and months versus years and decades. If you think about like mobile and cloud and internet, and there's just like so much happening, the intelligence overhang. On the other hand, there's also like humans and habits that productively have its change. It's hard to change. And change management through the company is also hard, right? You don't want to kind of be rash on that. So it's like, you know, the future is unevenly distributed, but even within the companies. On the second bucket of this other, the bus that Van Dam's writing on of governance and adoption and changing behavior and stuff, is there something you've learned about how to get past that, help that along more? The thing not to do is hold back folks who are early adopters, right? I think that's the other one learning. In fact, I think that's one of the reasons why recently I've been working with folks to say, can we have both, which is the longer-term change management, being able to do it in a trusted way, at the same time, do this program we're calling Frontier Program and roll out cutting-edge experimental features. We just built this world's first agent, deep research agent, made. But if there are early adopters in an enterprise or outside, how can we kind of put that in the hands of those folks without kind of insisting that all of the company be completely developing different muscles? This program, Franziri, you're talking about, I wanted to spend a little time on it. So, what is the idea? The idea here is like people are working in this futuristic environment. How does that actually work? Yeah, I think the idea is exactly this, which is like, I want to kind of institutionalize and operationalize my personal motto of living one year in the future and say, what does this, imagine a company or a setup like Frontier Consulting Group or Frontier Inc., right? And if you did, lived in that environment where you had all the AI tools and really advanced deep research intelligence on tapp, what are the kinds of questions you'd be asking? What's the kind of work you'd be doing? How would you change how you're going about your workday? So that's the premise. And you'd say, hey, how does it change an individual? But also down the lane, we want to think about what does a frontier team look like. We talk a lot about frontier labs and models. I think models layer is amazing. And obviously, that's what empowers all these product building to happen. But I want to push us to think about what does a frontier product look like? And more importantly, how does a frontier way of working, right? Like what does a team with three people and tons of compute and AI tools look like? So how exactly does this work? There's like a team within Microsoft that's like, your job is to use all of our latest tools and build product using that? Yeah, that is the setup. But meanwhile, what we've done is we've actually set up an external, like a fake company and said, hey, if you are somebody who wants to come play with some of the cutting-edge science projects and deep research agents and agents at work, come party here. Wow. Okay. And it's only a few weeks in. Okay, so TBD, how it all goes. Yeah, yeah. And again, like, these are micro. That's the meta point here, right? Also, is that in the traditional way, we've kind of always thought about across the companies, across industries, really thinking about rollouts in these macro ways, right? You build something and you kind of like roll it out, you have a general availability, and then you take the time. And that's really important too, because again, we're talking about former companies, legal companies relying on this. So we do want to have that. But at the same time, given the compressed cycles of AI, how do we start to have people experience what's the one year in the future? Let's follow this thread in a few different directions. There's how product change development changes, there's how engineering changes. There's also just agents. I know you're spending a lot of time in agents. It feels like you're not an AI company these days if you're not working on agents or building an agent. Lanny, you're doing this wrong. You didn't use the word agents so far into the conversation. I try hard to push it out as far as I can. It's like every conversation in San Francisco, it's just like, how long until I start talking about AI? It's like three minutes, average. Oh, man. Okay, so with agents, I know that you're leading a lot of this work at Microsoft, and a lot of people are wondering what the hell, what the hell does this mean? What is going to change? Give us just a glimpse into how you see the world being different. There's a lot of hyperventilated, excited talk about kind of the eventual future and all of that. I take a much more practical product building lens on this, right? And I think about these. At the end of the day, they're tools. Yes, underneath it, there's stochastic models versus very deterministic programming models. You can tell I'm a computer scientist, like the way that that word definitely shapes how I think about this. To me, the short term is, there's an evolution. We had apps, right? And now I think we are firmly in the assistance era, where there's like human driving the, you know, that's what we think of as co-pilot. I think the human driving kind of the, in the driver's seat, but having a lot of assistance from AI. So I think of this as then you look at the dimension of almost like autonomy and delegation and intelligence. As the intelligence, for example, when deep reasoning unlock happened, of course, then you could say you can delegate more to the agent. So I think to me, I think there's one dimension where you say, hey, agents are somewhat independent software processes that can kind of like run tasks. And you're not just thinking about hand-holding and fine-modern stuff. You're saying, hey, here's my goal. Go make this happen. I'll give you an example. So we're working on this researcher agent for work. And last night I said, hey, I have an important meeting coming up with the leadership team. I really want to present these frameworks here. And this is the roadmap here. Go back and look at all the people that are in the meeting. What are their views on this topic? And kind of come up with how I should be thinking about the right persuasion pitch here. And what's magical about this is not just that it's saving time. Typically, we think about the so far AI as summarizing the document or saving time. This is like firing synapses that I didn't quite have, and actually giving me new insights and giving me, dare I say, superpowers. So that's a natural evolution of AI, I would say. So when I think about agents, I think about three things. One is an increasing level of autonomy and kind of independence that you can delegate higher and higher order tasks. Second thing I think of it is complexity, right? So it's not just a one-shot, hey, create this image or do this thing or summarize the document. It's, you know, build me this prototype that expresses my idea of an augmented reality app. It's a complex task. And then the third thing I would say is asynchronous. It works when you're not working. I think that's the other big thing about these things, that you don't have to sit in front of it. This answers the question of what is an agent, essentially, these three ballpoints. So it's what are the three again? When I think about agents, I think about these three things. So one, it's autonomy, like being, and it's a spectrum. It's not a 0-1. It's how do I actually delegate things that it can do. Second, I think of as complexity, right? It's not a one-shot, hey, summarize this document, generate this image, but it's, you know, build me this prototype or help me knock this meeting out of the park, right? And then the third one I think of is it's a much more natural interaction. That doesn't just mean chat, but it may be actually jumping on a meeting with the agent and being able to talk. So I think all three things, the autonomy, the complexity, and the natural interaction, are at least product principles that will shape really good ones, good agents. That is really helpful. Along this line of agents, there's this acronym that you taught me as we were chatting ahead of this podcast, NLX. What is that, and how does that relate to agents? And why are people not thinking about this enough? Oh, that's one of my Roman Empires these days, the natural language interface. NLX is the new UX. So I think here's the deal. To me, I think traditionally we've thought very consciously about GUI because the graphical interfaces are not something natural and so they have had to be explicitly designed, but they're rigid interfaces. What we have with conversational interface and natural language is it's a much more elastic. That doesn't mean it's not designed. So people had, often I hear product builders say, oh, yeah, with AI, the model leads the product. So it's just, you chat with it. You and I are having a conversation, it's a podcast. I'll have another conversation at Microsoft, and that's a meeting. So conversations also have grammars, they have structures, they have UI elements. They're invisible. And so one of the things that I see and I'm really excited about is what are the new principles, new constructs in natural language as an interface. I'll give you a few examples, right? And actually, like a lot of startups as well as big companies are really experimenting with this stuff. One is if you think about it, prompt itself is a new construct. And that's a new way, that's a new UI element, just like a drop-down was. So when you give a high-level goal, what we are seeing is that when the agent comes back with a plan, preferably an editable plan, that's a new construct. The other one that I think about a lot is showing the work, right? Progress. You see this with different products, right? You see with the Copilot, you see with ChatGPT, DeepSeek, this idea of thinking aloud. And it's kind of showing the work. But how much do you do it? If it's too verbose, it feels like I'm running some cranjab and scripts. But if it's two terse, then I don't know if it's going the right path and I don't have the confidence yet. So there are all these new elements. So if you're a product builder, this is a fun new space to be digging in for product design. This is really interesting because I think people chat with all these chatbots and it just feels like this is just the way it is. But you actually are designing every element of the interaction, like how much to share, but how much you're thinking. Here's my plan. What do you think? So I think this would surprise a lot of people just realizing there's so much that goes into just designing even these what seemingly are simple conversations. Yeah, another good example is follow-ups, right? You could say, look, you asked me a question, and then I could ask a follow-up set of things. And that explicitly should be designed for success, right? So for example, if I said, hey, create an image, and it created a black and white, you know, I don't know, like a clip art version of something, what are the next obvious follow-ups that it should be suggesting proactively? Now, too much, and you're kind of annoying me, right? But too little, and in some sense, you've lost an opportunity to direct me or guide me into a happy path here. This resonates a lot with when we have Kevin Wheel on the podcast, he talked about this question of just how much to show about what you're saying. And it's interesting that DeepSeek went the extreme of just showing everything, and people liked it too. I think that was interesting. Yeah, and I think it's a point in time to Lenny, because in some sense, right now, these things are such black boxes, they're almost like peeking under the hood for anything, even if it's verbose, feels like, oh, I know what's happening, especially because the compute inference time, it's taking long to think. So, it just feels like if you just went silent, I'd be very uncomfortable, I think. Exactly. So, I do feel like there's that point in time. But over time, I also feel like this is an area ripe for personalization. For example, right, like again, in human, like my API would be very different from somewhere. My interface is probably different from others, and I might just want the direct, hey, give me the TLDR versus the, oh, so I went here and then I went there. And it's like. Pulling this third a little bit, we're talking about just how the future is going to be different. There's like designing for these chat experiences, there's agents. Kind of zooming out to just product development in general, it feels like you're at the forefront of a lot of the tools that are going to change the way we build products, and also your teams are working with a lot of these tools that no one else has access to. So, let me just ask: how do you see the future of product development being different from today most? And what do you think product builders should be preparing for doing to kind of succeed in that future? I'll start with one stark statement that I say internally and externally, and I'm trying to live it: is that in this day and age, if you're not prototyping and building to see what you want to build, I think you're doing it wrong. I call it the prompt sets or the new PRDs. Like, I really insist on folks saying if you're building new projects, new features, of course, come with prototypes and prompt sets. And I think the notion is not to say, hey, now everybody is just a bigger version of a software engineer. It is to say, you know, you have the fastest path to kind of seeing and experiencing what's in your mind to be able to communicate. It's a much more high-bandwidth way of communication. I think about that as really a loop accelerator in terms of product building. That's number one. When in doubt, as someone put it, demos before memos. I think that's really number one. I would say, number two, this one is a little bit tricky, I'd say, is that what I'm seeing is that the time to first demo is much shorter, right? But the time to a full deployment is going to take longer. So I think that there's going to be an uneven cadence. So typically, I think there was much more of a, hey, you build this thing, you take a few weeks, and then you kind of iterate, and so on. Now, but that inner loop of like prototyping and iterating and getting even user research through AI conversations, all of that gets shortened. But I think the bar for scale therefore becomes much high, if you look at it, there's going to be a supply of ideas, a massive increase in supply of ideas in prototypes, right? And so, which is great, it raises the floor, but it raises the ceiling as well. In some sense, how do you break out in these times that you have to kind of make sure that this is something that rises above the noise? So, I would say that it's simultaneously thinking about not chasing after every idea, I think, is the second one. I'd say the third thing is, you know, there's a lot of conversation around full-stack builders, right? What does the team of the future look like, a product-building team? What I think about is, I think that is inevitable in terms of like there will be a few folks that are, especially at the prototyping, early idea discovery stage, that the lines are blurred, right? There will be a few tastemakers at the same time. I think you can still have a lot of people experimenting. It becomes even more important to have that editorial and taste-making kind of ottier, one or few at the heart of it, because otherwise you just have a Frankenstein product, right? That definitely doesn't change. I have one other additional bonus thing, which is a lot of folks think about, oh, you know, don't bother studying computer science or the coding is dead. And I just fundamentally disagree. If anything, I think we've always had higher and higher layers of abstraction in programming. We don't program in assembly anymore. Like, most of us don't even program in C, and then you're kind of higher and higher layers of abstraction. So, to me, they will be. It'll just be at a much higher level of abstraction, which is great. It democratizes. There'll be an order of magnitude more software operators. Instead of Swedes, maybe we'll have souls. But that doesn't mean you don't understand computer science and it's a way of thinking and it's a mental model. So I strongly disagree with the whole coding is dead. That's awesome. I love that. And so is a software operator. Is that what that stands for? Yeah. I just mean that we, yes. Okay, cool. This idea of prototyping is being kind of core to building these days. Is there anything you do within Microsoft to operationalize that and make that just like a thing everyone has to do? Is it just like culturally do it, or is it like you must show me a prototype before you show me a... You know, I think it's, again, like the future is here unevenly distributed, even in Microsoft, I would say. But there is certainly a strong cultural momentum and shift and desire to say, hey, let's actually look at live demos, live prototypes, and to even communicate the ideas. And to me, I mean, it's not always possible because obviously there are things that are deeply, like if you're trying to change something in the vowels of Excel, you probably don't. There's even enough depth in the product that you know what you need to do and you don't need to prototype that. But if you're especially thinking about new things, new products, new features, absolutely. Okay. Let's talk about product management. There's this fear that emerged as soon as all these AI coding tools came out of just like PMs are dead. We don't need PMs. We could just build things ourselves. What are these people hanging around for? And what I found is it's actually the opposite: that now that coding is easy, now the question is more and more: what should we be building? Why should we be building it? Is this right? Is this the right solution? Then getting adoption for it, which is what PMs are really good at. And so I feel like it's the opposite. Like, PMs are the most important role, and it'll change too. But let me get your take. Just what do you think the future of product management looks like? Do you think it's dead? Do you think it's going to thrive? Do you think it's going to change? Yes. Meaning, look, I mean, if you're a TPS report, mostly process person, and like a lot of companies do get confused about product management and process and project management, I think then you do have a question of like, hey, what is the value add here, right? Especially if AI can read and write 50,000 meeting notes and track things and send emails and so on. But I think what I do think on the flip side is the taste-making and kind of the editing function becomes really, really important. In a world where the supply of ideas, supply of prototypes becomes even more, like an order of magnitude higher, you'd have to think about what is the editing function here. So that does mean that the bar is higher for product folks. But I think there's an interesting side effect I am observing in startups that I'm advising, companies, and even within the companies, that there used to be more gatekeeping, I would say, in terms of, oh, this is, we should ask the product leader what they think. And again, like, there is a role for that editing function, but you have to earn it now. But there's also just like an unlock of latent, really good ideas from smart engineers, smart user researchers, smart designers who now have this expert in their pocket, right, to kind of round out all the other things that they're not typically skilled at to bring forth their ideas. And that's amazing, I think. And I think that expert, it's interesting, I'm working with that engineer and some stuff, and he uses ChatGPT to even communicate to me in a more effective way. Like turn this pitch into something that will convince Lenny this is a good idea. By the way, that is actually one of my common use cases, which is the WWXD, I call it what would X do. Like I use it to say, hey, what would Satya think about this particular set of conversations or ideas that we're pitching and so on? This is the power of, I think, deep reasoning plus relevant context. This engineer you're talking about has that context about you. And so it's kind of very interesting. If only everyone was as famous as Satya and had so much information out there. But I guess you can import all their emails or whatever tools exist to just understand from the conversations you've had with that person. Yeah. And I think this goes back to actually what you were saying too, which is, I think this idea of what is the, there's like a coil spring, there's an intelligence overhang that I just see across the board. And I think the part of product development has to almost rewire ourselves to, I think Toby from Shopify calls it the reflexive AI usage. And that's not as easy. And I've been thinking about why. Like I basically, I mean, I have a cheesy Chrome extension, literally, whenever I. But it kind of helps to pause and think, oh, what am I trying to do here? But the reason I find it hard, and when I talk to even people who are living and breathing in this space, they find it hard is that the updating of the priors is really hard. Like the models couldn't do some things one year ago. Like, I mean, image generation was full of spellings or like reasoning. You just couldn't have deeper and smarter answers. You couldn't do data analysis. So my impression of it from trying it a few months ago, that prior needs to be updated. And it's hard to do that, right? And you have to kind of do something almost counterintuitive and against the grain to say, no, no, ignore what you learned about what this can or cannot do. The baby just grew up to be a 15-year-old in a month. I think that last point is so important that we've tried these tools over the years and so far it hasn't been amazing. And then all of a sudden it is. And you kind of don't know that. And you've given up almost and things change. I think that's actually, if you're a product builder listening to it, that's a really interesting arbitrage thing for you. Like if you can kind of cut against the grain and say, nope, I won't have that scar tissue around like, you know, this didn't work a few months ago and keep setting high expectations and like demand more of the AI today, I think you can unlock more. There's a lot of alpha in doing that. That's right. Today's episode is brought to you by Coda. I personally use Coda every single day to manage my podcast and also to manage my community. It's where I put the questions that I plan to ask every guest. Imagine starting a project at work and your vision is clear. You know exactly who's doing what and where to find the data that you need to do your part. In fact, you don't have to waste time searching for anything because everything your team needs from project trackers and OKRs to documents and spreadsheets lives in one tab, all in Coda. With Coda's collaborative all-in-one workspace, you get the flexibility of docs, the structure of spreadsheets, the power of applications, and the intelligence of AI, all in one easy-to-organize tab. Like I mentioned earlier, I use Coda every single day, and more than 50,000 teams trust Coda to keep them more aligned and focused. If you're a startup team looking to increase alignment and agility, Coda can help you move from planning to execution in record time. To try it for yourself, go to coda.io/slash lenny today and get six months free of the team plan for startups. That's coda.io slash lenny to get started for free and get six months of the team plan. Coda.io/slash Lenny. I'm going to come back to this cheesy plugin. Say more about this. So, this is a plug-in that just lets you put a custom message on every new tab and it just, you have it say, how can you use AI to do this? Yeah, it's as cheesy as that. And it's interesting because it works in the last few weeks alone. I've been doing this like experiment to say, hey, how much more AI pill can I get, like both at work and in a personal life to say, you know, when I'm trying to do anything manual, like, should I be demanding the AI to do this? That's so cool. Do you know the name of this Chrome extension by any chance? Otherwise, you built a Chrome extension. Which tool did you use to do that? Some kind of Microsoft tool, I imagine. Yes. Yeah. No, actually, it was just like, I mean, I live in GitHub and GitHub Copilot, so it just was like, okay, let's go build this Chrome extension. Are you releasing this for the general public? No, I mean, that's the amazing thing. It took me like 10 minutes to do this. Okay. Let's link to it. Let's get it out there. Open source, this thing. Okay. You mentioned Satya. I have a question about this. So you're one of the very few people that have worked very closely with both Satya and Sundar at Google. Let me ask you this: how do their leadership styles differ? And is there just like a fun story you could share about each of them? Yeah, I do feel lucky to have, you know, kind of have a window into these two amazing leaders of this generation. I would say, I mean, again, no surprise, as you'd expect from CEOs of multi-trillion dollar market cap tech companies, they are 99.99 percentile in like almost every dimension you'd think of, right? Intellect, empathy, leadership, you know, product strategy. There are, of course, flavors of differences. I was the technical advisor for Sundar with the first at Google and set up kind of the office of the CEO there. And they are, again, a matter of like time and context because there's a lot more consumer-oriented focus there. So, what I did find Sundar great at it is being really calm and measured and thoughtful in terms of making sure that things have dealing with the complex ecosystems. If you think about the phone ecosystem or even like. And I think on Satya, I find it amazing the appetite he has for learning and fine-tuning his mental models and just like the Zoom levels that he can operate at, the macro, the strategy, what's the game, but also the micro. Hey, why are we not? Like, here's like a specific insight that I saw on Twitter. And like, you can count on the fact that he's ahead of pretty much everybody else in terms of spotting those early things too. So, it's just been like learning from the fire holes, as they put it. What a cool opportunity to work with two incredible folks. Okay, let's go in a whole different direction. Let me just ask you this question that I've been asking people more and more. What's the most counterintuitive lesson that you've learned about building products that goes against common startup wisdom, common product-building wisdom? I don't know if it's as common as it should be, and it's like a counter-intuitive thing, but I've repeatedly learned that when you're doing something new, zero-to-one, the temptation is to kind of think about, you know, it's like that Salt Park episode. Step one, think about the problem. Step two, separately, underpants, step one. Underpants, exactly. So, I do feel like there's a temptation to rush and say, to go to scale before solve. So, I've always said to my teams, solve before scale. So, what that does mean is there's a different posture and different mode when you're trying to solve a problem versus scaling something that's either post-product market fit or even at least like in. So, to give you a couple of examples, I think when you look at the solve stage, there are wide lurches. You got to be very comfortable with the fact that you're day one thinking about, hey, a plant detection tool. And then day 15, you're like, oh, actually, the tech is really good for translating in a foreign language. By the way, this is not hypothetical. This is what we kind of like looked at in Google Lens back then and said, okay, what is the intersection? And so on. So from the outside, it looks like chaos. But actually, and you should be very comfortable, not only tolerant, I think you should be like, should have an appetite for that. Because the last thing you want is prematurely fix on one local hill and then you're climbing that. And startups and entire product areas and companies, big companies make that mistake. And three years later, you're like, oh, how do I get off this hill? So I'd say that's one big competitive thing. Like when you're trying to think about what mode you're in, are you in the solve mode? Are you in the scale mode? One example is kind of making sure that you're comfortable with the chaos. I think the other lesson I've learned is the danger of metrics. And I think, again, if you have worked on Google search or if you worked on office products, you really have a very fine-grained sense of what are the metrics for this product. You have the input metrics out. You have the whole shebang. But when you're looking at something zero to one, if you decide on a metric too prematurely, that's false precision, first of all. I mean, CTR, when you have thousand people, it doesn't mean anything. Retention also may not. So really being very wary of like this big guy, big girl of grown-up metrics, as I call it. You are looking for more qualitative, the sound of click. And what is your, as the other anecdote, you know, kind of the handler uses, what is your set timer and play music? So if you look at like Alexa and like Siri and Google Assistant and all these things, they had a very promising broad interface. You could say anything, but I think there was one or two things that it was really good at, right? Like you could set a timer, you could play music, and you could play trivia. And so you've got to nail those things before you say, oh, yeah, here, you can do anything with it, which is not a good recipe. That's exactly what I use my Google Home for. So basic. I don't do the trivia thing though. Maybe I've got to give a shot. There's something along these lines that I've also seen you talk about, which is how to go zero to one with something. Just kind of a little framework for helping you know if this is the right time for this idea. How do you think about that? Yeah, and when you think about the solve mode, and this is again, like sticking with my whole, you know, living in one year in the future, I gravitate towards the zero to one and solve mode products completely thinking about new category of products. And what I've found, both the hard way, I would say, is that you do want to look for at least two out of these three factors, inflection points here, if you want to make a really good product. Number one, is there a shift? Is a step function in the tech? That's somewhat obvious, I would say. Like, you know, deep learning was one for Google Lens. Back then, speech recognition was a step function for conversational search. I would say for Robinhood, the generational shift was very clearly, and the fact that phones were a primary means for, you could actually have an app, mobile app for finance that you could use. So look for that inflection. What is the tech inflection? And right now, of course, LLMs and reasoning models are that step function. But that's not enough. I would say the second factor that we should look for is what is the consumer behavior shift. So to give you an example, when we started working on Google Lens, what we said is, look, people were taking mostly pictures for sharing, selfies and sunsets and so on. And suddenly when storage became free and mostly free and everybody had phones everywhere all the time, you took pictures of everything. And then you had like enough of pictures or you use the camera as the keyboard for your world, right, for the real world. And so how do you kind of then say, oh, this consumer shift is big. And so therefore, kind of like as it, as you go order of magnitude more photos, then you want more to come out of them and you can apply AI to that. And I'd say the third inflection point, particularly I would say in enterprise, but also in consumer, is the business model shift. How do you, is there an inflection point, natural inflection point in the business model? So any great products, if you think about like, you know, all the way from search, again, like the second price auction and the fact that you had like, you know, CPCs, same thing with SaaS and the fact that you could actually charge or monetize enterprise products in a different way. And with AI, of course, like the monetization is a whole different, like, I mean, we've just barely scratched the surface of whether you do seat monetization, usage, like on-tap, and then, of course, outcome-based stuff, outcome-based monetization. Hey, have you solved the problem for me? And then I will pay you some fees. So, all three, like to me, are you know kind of like great, but at least two out of three for a good product. So, this essentially, when investors look at startups, they're always asking why now? Why is this the time to start this thing? And so, your advice here is you should, there's three ways to look at it, and you should, two of these three should be true. There should be a shift in technology, some new technology that has enabled this now recently. There's a shift in consumer behavior, and then there's maybe a new sort of, or you've invented a new business model, like any way to monetize something that it gives you an advantage over folks trying to do it together. Awesome. You didn't mention Robin Hood, I think, in that example. That was another good example of phone. Yeah, I mean, talk about the business model of kind of, again, like not having a zero, you know, zero fees, right? And again, like, that combination of all of these things is what can unlock it. You can't just say, oh, we'll just have a much, much more better intuitive interface and hope that people will switch to it. Okay, so speaking of zero-to-one products, I'm going to take us to an occasional segment on this podcast that I call Hot Seat Corner. And I have a question for you that is on my mind, and it's come up in a couple recent podcasts, actually. So, there's these companies like Cursor, vZero, Lovable, Bolt, Replit, that are like the fastest-growing company's history. I just saw that Cursor hit 300 million ARR in two years. Interestingly, you guys were very well positioned to do really well in this space. You built VS Code, which is what all these companies are forking to build on. You have incredible AI infrastructure, incredible AI talent. So this could have been your market. What happened? What happened to Partner? You know, it's interesting, the framing. So I'm a data user of GitHub Copilot. And I would say, look, if you unpack, I think the thing, the beauty of this is that code generation has become an amazing tool that NLMs have unlocked. So it is not so, it is actually really good excitement and action that now code generation has just opened up all of these things that we've talked about the whole idea of like prototyping, go from idea to marks an idea to kind of a clickable prototype in like in a few minutes. Those are the kinds of things that of course we should expect code generation to enable. The way I think about how we are positioned and what we do with GitHub is so it's a system, not just a product or a set of features. If I think about GitHub, it's for folks who have the repo there, right? And you have kind of, of course, you have the assistance in terms of auto-complete and you can chat. But now we have the agent board. It's one of the fastest kind of loops that we are seeing. Really strong positive feedback. So in some sense, when you have a system, what you are looking for in terms of building and designing it is not just a single product that can go grow, but it's the what is the repository, what is your context, what are the set of features that grow from your expertise, right? If you're a really expert coder, you want kind of like the assistance, this product needs to scale for that. If you're a wide coder, you should still be able to do that, and so on. So, that I think is the way that GitHub is positioned to build on and like growing, honestly, really well. That's so interesting. So, the core of this is everyone ends up in GitHub anyway, no matter what tool they use. And that's kind of the. Yeah, and I think the idea again is that code generation as a tool will unlock a lot more products. I mean, they're not all competitors to the fact of they're not all kind of doing the same job. I think when you're, at the end of the day, like you're building code for companies to run on, you need to have a system, you need to have kind of the ability, an entire Swiss Army toolkit, right? Not just the autocomplete, not just a chat, not just like a software agent that runs and you kind of like hand-hold. You need all of this to work together. And that's what the GitHub product is going after. All roads lead to GitHub. On the flip side of this question, there have been probably 5,000 startups that have tried to disrupt Excel, and you guys just keep winning. So, something there is working really well. That is so interesting you say that. So, when I came to Microsoft and I'm an Excel fan, so I actually had a conversation with one of the OG Excel product folks. I was like, man, what is it about this product? And he said a couple things that were really interesting for me that just stuck with me. One is, you know, he said, hey, you know, Excel is a proof that non-coders also have to program. Programming is really powerful, and it's the tool that gives all of the non-coders. And then the second thing that I found out is super cool, I don't know if you know this, but I didn't know at least before two years ago that there are these amazing Excel championships, like World Excel championships, where you see folks who can do just magic. And to me, I think the insight here is also that some tools are harder to learn, perhaps, in the beginning. There's friction in terms of learning, but great to use, right? So it's a very good case of: hey, the learning curve initially, the one-time learning curve might be tricky, but it is because there's so much power and depth in the tool. That's so interesting. I never thought of Excel as a programming language, but it makes sense. And I feel like once you get used to it, and this is just the way things work, you're kind of stuck there, and everything else has to basically copy that model, which is hard to be as good. Yeah, and I think the depth and the attention that the team is given, and again, that's the compounding effect over decades of working on like deep, deep signal from people who live, who depend on it day in and day out. Okay, to kind of start to close out our conversation, I want to ask this question around your career. I find that most people have one moment in their career that changes the trajectory of their career. It could be like a manager they had, it could be a project they worked on, could be just a job they landed. What would you say is the most pivotal moment in your career that eventually led you to becoming chief product officer at Microsoft? Actually, there is one moment where it was a turning point for me. I was in Google. I said, hey, these phones are becoming a thing. Personalization has to be important. So I probably banged my head against the wall for a year or so trying to make personalization work. And it turns out when you have a query that you put into Google search, the personalization didn't matter as much. And so we disbanded the team. But then I think I started working on this product called Google Now, which was a twist on that, which said, hey, actually, on the phone, we should be able to push content. It's not about searching with personalization. For example, if you have a flight coming up, we should be able to say, hey, connect the dots and say you should leave now for the, you know, given the traffic and where you need to go and so on. Or if you're deeply interested in stand-up comedy with deadpan artists, you should check out Mitch Hetberg. These are kind of like these really moments that the smartphone should be smarter. So I led the product through the kind of the initial zero-to-one phase. And that was a pivotal moment. It made me realize two things. One, I really love seeing around the corner and kind of seeing where things go and building the product to rise to the occasion way more than the scaling and sustaining products. Second, it's harsh, but being early is the same as being wrong. You know, this is pre-LLMs, pre-deep learning. A lot of the really amazing ideas in terms of next token predictor, et cetera, we've been thinking of it, but didn't have the horsepower to go. The interface was great, the intelligence. And I'd say the third thing that stuck with me is I got to work with some really smart, like they talk about talent density now, right? And I think really smart people who have gone on to do like amazing things. And so kind of like, it gave me a taste of what a small group of people can do. It's such a great story because, because it didn't work out right in the end, like Google now kind of went away, right? And by the way, I super remember that product. It was very cool. I remember looking at it. It was very delightful and happy. And so I also have this segment on the podcast called Failure Coordinator, where people share a story of failure and how that helped them. And I love this as a combination of those two. Yeah, I mean, I'm not going to lie, I think it's painful when you do that because you see the vision of what can be and what is. And sometimes it's hard limitations. Sometimes it takes like, you know, in this case, it takes five years or ten years to kind of like really unlock the intelligence. But sometimes it's one or two key click stops away from the product being great. And part of figuring out is knowing when you're in what situation. How long was that period from starting out until just like moving on? And it's not really. Yeah, I would say in that case, one of the good things is, again, it led the foundation of, it was one of the foundations of the Google Assistant. And of course, as the LLM's step function happened, now with Gemini, it kind of like works out. And I think it's the same thing across the board, which is sometimes you want to kind of figure out the invariants that do work, right? That can then go on to the next version of the product. And other times you just have to start over. Is Google now the first agent before agents, sort of feels like? That was certainly the idea. Like, whether you think about all the voice assistants, right, the interface is like we overshot and the intelligence wasn't there. Today, I feel like there's an opposite problem. I think these things have amazing intelligence, and the interface we have largely is like the AOL dial-up modem chat bot. We've covered a lot of ground. Is there anything that you wanted to chat about or leave listeners with maybe a last nugget of wisdom before we get to a very exciting lightning round? I think I would say one thing that I'm really excited about is this idea of figuring out how we, as people and agents, collaborate together. I think there's like some great set of products and experiences to be reimagined. That's my other Roman Empire, which is how do we actually have this co-working space where you have kind of like the humans and agents, and how do you actually kind of have an output that's much, much more significant than what any one of us or any few of us can produce. Well, I need to hear more about this. When you imagine a coworking space of humans and agents, what does this look like? Is this like Microsoft Teams, or is this like a physical place with little robots? Oh, I had a thought of the physical place, but I am thinking a lot about kind of, you know, right now, all of these experiences are very single-player, right? And I do think there's an opportunity to think about how do we, again, I'm living one year in the future, how do we actually have, like, you know, collaborate with each other, but with also with agents and really figure out, for example, what tasks can be delegate? What can we kind of like inspect? How do we actually have information that flows between people that agents can mediate and so on? All right. I'm curious to see what you guys got cooking. With that, we've reached our very exciting lightning round. Are you ready? Let's do it. Let's do it. First question: what are two or three books that you find yourself recommending most to other people? Oh, I have recency bias, but I've been reading this book called The Brief History of Intelligence. Phenomenal book, and lots of underlining for me. And I think it kind of, the premise is to, it looks at the evolution of intelligence, like human intelligence and kind of the brain development, and connects that to what we're seeing with AI. Do you have a favorite recent movie or TV show that you've really enjoyed? Hacks. I've been watching this. It's about a woman who's a great stand-up comedian. I think it's set in kind of like the fact that she grew up, I think, in the 70s and 80s and kind of like really tried to break through in an industry that hasn't traditionally been very friendly to women. So really fun and quirky. Do you have a favorite product that you've recently discovered that you really love? Could be an app, could be some physical. I do use a lot of Microsoft products, GitHub Copilot being one of them. But I think the one that I maybe I'll pick is Granola, I think is the name of the app. I found it really useful. I just gave it a spin the other day and I'm like, oh, this is really useful in terms of being able to, you know, again, like without being intrusive, just capture the. It felt like one of those things where you have the confidence of a few things like we were talking about, right? Like the transcription, real-time transcription tech has gotten really good, voice recognition is great, and then enough of the LLM magic on top of it to kind of make it structured and contextual. I am a huge fan of granola. I'll give a quick pitch here. If you become an annual subscriber of my newsletter, you get a year free of granola for your entire company. Did not know that. There we go. So, and then just check that out, Lenny'snewsletter.com and you can click the word bundle and you'll see how to do that. Very cool. Two more questions. Do you have a favorite life motto that you often come back to when you're dealing with something maybe you share with folks they find useful as well in work or in life? I have one. In fact, actually, this is my email signature for, I don't know, for the last 20 years or so. It says the best way to predict the future is to invent it. I think it's a quote by Alan Kaye. I find it useful for two things. One is, you know, no one knows anything. Like, when you think about all the folks who are, you know, kind of think about, hey, this is exactly how everything is going to look and this is exactly the sequence and so on. I think there's no substitute to experientially building it. And I think the second part is, you know, like if you think there's something that should exist, go build it. I love that. Final question. We've talked about stand-up comedy a bit. Is there like a favorite under-the-radar stand-up comedian that you think people should go check out? Oh, there's a couple of them. So one, I think there's an Indian American or I think I think a British Indian stand-up comedian. Her name is Cindu V. And I think the other one that he, this is definitely not under the radar, but like, I've just like love his take is Nate Berghadzi. He's just so good. Aperna, this was amazing. Two final questions. Where can folks find you online if they want to reach out maybe and follow up on anything you shared? And how can listeners be useful to you? You can find me on LinkedIn and Twitter. Aperna CD is the handle. I do post stuff a lot more on LinkedIn these days. So, you know, I would love to hear thoughts, comments, conversations there. I'd say one thing that would be super interesting is if any of this stuff sparked conversations, particularly around what can a small team with a lot of AI tools do or new products that folks are really excited about, saying that they should exist, hit me up. Amazing. Aparna, thank you so much for being here. Thank you. Bye, everyone. Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast. You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.