--- METADATA START ---
Show: All-In with Chamath, Jason, Sacks & Friedberg
Episode: AI Doom vs Boom, EA Cult Returâ€¦
Host: Jason Calacanis, Chamath Palihapitiya, David Sacks, David Friedberg
GUESTS: None 
Guests: None
Source URL: https://podcasts.apple.com/us/podcast/ai-doom-vs-boom-ea-cult-returns-bbb-upside-us-steel/id1502871393?i=1000710690232
--- METADATA END ---

1
All right, everybody, welcome back to the all-in podcast, the number one podcast in the world.
2
You got what you wanted, folks.
3
The original quartet is here live from D.C.
4
with a great shirt.
5
Is your haberdasher making that shirt, or is that a Tom Ford?
6
That white shirt is so crisp, so perfect.
7
David Sachs, you're...
8
What's your czar?
9
Your czar.
10
I'll tell you exactly what it is.
11
I'll tell you what it is.
12
You can tell me if it's right.
13
Brioni.
14
Yes, of course, it's Brioni.
15
Brioni spread collar.
16
Look at that.
17
How many years have I spent being rich?
18
When a man turns 50, the only thing he should wear is Brioni.
19
The stitchings.
20
It looks very luxurious.
21
That's how Jamoth knew, right, Jamoth?
22
How did you figure it out?
23
The stitching?
24
It's just how it lays with the collar.
25
To be honest with you, it's the button catch.
26
The Brioni is a very specific style of button catches.
27
If you don't know what that means, it's because you're a fucking ignorant malcontent.
28
I'm looking it up right now.
29
Yeah, he's back now.
30
I just asked you to check your junior.
31
Let your winners ride.
32
Brain Man, David Sachs.
33
We open source it to the fans.
34
And they've just called Marie's Myth.
35
Love U.S.
36
Queen of Cambodia.
37
All right, everybody.
38
The All-In Summit is going into its fourth year, September 7th through 9th.
39
And the goal is, of course, to have the world's most important conversations.
40
Go to allin.com/slash yada yada yada to join us at the summit.
41
All right.
42
It's a lot in the docket, but there's kind of a very unique thing going on in the world, David.
43
Everybody knows about AI doomerism.
44
Basically, people who are concerned, rightfully so, that AI could have some significant impacts on the world.
45
Dario Amode said he could see employment spike to 10 to 20% in the next couple of years, the 4% now, as we've always talked about here.
46
He told Activists that AI companies and government needs to stop sugarcoating what's coming.
47
He expects a mass elimination of jobs across tech, finance, legal, and consulting.
48
Okay, that's a debate we've had here.
49
And entry-level.
50
Polymarket thinks regulatory capture via this AI safety bill is very unlikely.
51
U.S.
52
enacts AI safety bill in 2025 currently stands at a 13% chance.
53
But, Sachs, you wanted to discuss this because it seems like there is more at work than just a couple of technologists with, I think we'd all agree, there are legitimate concerns about job destruction or job and employment displacement that could occur with AI.
54
We all agree on that.
55
We're seeing robo-taxis start to hit the streets, and I don't think anybody believes that being a cab driver is going to exist as a job 10 years from now.
56
So there seems to be something here about AI doomerism, but it's being taken to a different level by a group of people maybe with a different agenda, yeah?
57
Well, first of all, let's just acknowledge that there are concerns and risks associated with AI.
58
It is a profound and transformative technology.
59
And there are legitimate concerns about where it might lead.
60
I mean, the future is unknown, and that can be kind of scary.
61
Now, that being said, I think that when somebody makes a pronouncement that says something like 50% of white-collar jobs are going to be lost within two years, that's a level of specificity that I think is just unknowable and is more associated with an attempt to grab headlines.
62
And to be frank, if you go back and look at Anthropic's announcement or Dario's announcement, there is a pattern of trying to grab headlines by making the most sensationalist version of what could be a legitimate concern.
63
If you go back three years ago, they created this concern.
64
And they showed what was supposedly a sample, I think, of Claude generating an output that could be used by a bioterrorist or something like that.
65
And on the basis of that, it actually got a lot of play.
66
And in the UK, Rishi Sunak got very interested in this cause, and that led to the first AI safety summit at Bletchley Park.
67
So that sort of concern really drove some of the initial AI safety concerns.
68
But it turns out that that particular output was discredited.
69
It wasn't true.
70
I'm not saying that AI couldn't be used or misused to maybe create a bioweapon one day, but it was not an imminent threat in the way that it was portrayed.
71
There have been other examples of this.
72
You know, obviously, people are concerned about could the AI develop into a superintelligence that grows beyond our control?
73
Could it lead to widespread job loss?
74
I mean, these are legitimate things to worry about.
75
But I think these concerns are being hyped up to a level that there's simply no evidence for.
76
And the question is why?
77
And I think that there is an agenda here that people should be concerned about.
78
So let's start with maybe Freeberg.
79
Things that we all agree on here.
80
There are millions of people who drive trucks and Ubers and Lyfts and DoorDashes.
81
You would, I think, agree the majority of that work in about five to ten years, just to put a number on it, will be done by self-driving robots, cars, et cetera, trucks.
82
Yeah, Dave?
83
I think that might be the wrong way to look at it, or I wouldn't look at it that way.
84
And maybe I'll just frame it a different way.
85
If I'm deploying capital, let's say I'm a CEO of a company, and I can now have software that's written by AI.
86
Does that mean that I'm going to fire 80% of my software engineers?
87
Basically, it means one software engineer can output, call it 20, 50 times as much software as they previously could by using that software generation tool.
88
So the return on the invested capital, the money I'm spending to pay the salary of that software engineer, is now much, much higher.
89
I'm getting much more out of that person because of the unlocking of the productivity because of the AI tool than I previously could.
90
So when you have a higher ROI on deployed capital, do you deploy more capital or less capital?
91
Suddenly you have this opportunity to make 20 times on your money versus two times on your money.
92
If you have a chance to make 20 times on your money, you're going to deploy a lot more capital.
93
And this is the story of technology going back to the first invention of the first technology of the caveman.
94
When we have this ability to create leverage, humans have a tendency to do more and invest more, not less.
95
And I think that's what's about to happen.
96
I think we see this across the spectrum.
97
People assumed, oh my gosh, software can now be written with one person.
98
You can create a whole startup.
99
You don't need to have venture capital anymore.
100
In fact, what I think we're going to see is much more venture capital flowing into new tech startups, much more capital being deployed because the return on the invested capital is so, so, so much higher because of AI.
101
So generally speaking, I think that the premise that AI destroys jobs is wrong because it doesn't take into account the significantly higher return on invested capital, which means more capital is going to be deployed, which means actually far more jobs are going to be created, far more work is going to get done.
102
And so, I think that the counterbalancing effect is really hard to see without taking that zoomed-out perspective.
103
To respond to Sachs's point, I do think anytime you see a major change socially, societally, there's a vacuum.
104
How's the system going to operate in the future?
105
And anytime there's a vacuum in the system, a bunch of people will rush in and say, I know how to fill that vacuum.
106
I know what to do because I am smarter, more educated, more experienced, more knowledgeable, more moral.
107
I have some superiority over everyone else, and therefore I should be in a position to define how the new system should operate.
108
And so, there's a natural kind of power vacuum that emerges anytime there's a major transition like this, and there will be a scrambling and a fighting and a whole bunch of different representation.
109
Typically, fear is a great way of getting into power, and people are going to try and create new control systems because of the transition that's underway.
110
Okay, you're going to see this around the world.
111
Yeah, I mean, so, Trimoff, it's pretty clear.
112
You know, Freeberg didn't answer this question specifically, so I'm going to give it to you again.
113
You would agree jobs like driving things are going to go away if we had to pick a number.
114
Somewhere between five and 10 years, the majority of those would go away.
115
He's positioning, hey, a lot more jobs will be created because there'll be all these extra venture capital and opportunities, et cetera.
116
But job displacement will be very real.
117
And we're seeing, I think, job displacement.
118
Now, you had a tweet recently, you know, you were talking about entry-level jobs and how that seems to be going away in the white-collar space.
119
So, where do you land on job displacement?
120
Freeberg's already kind of given the big picture here, but let's step back to for people who are listening who have relatives who drive Uber or a truck or are graduating from college and want to go work at a, you know, I don't know, the Magnificent Seven or in tech, and they're not hiring.
121
And we know the reason they're not hiring because they're leaning into AI.
122
So, let's talk about the job displacement in the medium term.
123
I'm going to ignore your question.
124
Great, I'm going to answer that.
125
So, why should you be any different than the other contents on this podcast?
126
There's two people not wanting to answer the question about job displacement.
127
Interesting trend.
128
No, no, no, we'll go back to that.
129
Let me start by just saying that it seems that these safety warnings tend to be pretty coincidental with key fundraising moments in Anthropic's journey.
130
So, let's just start with that.
131
And if you put that into an LLM and try to figure out if what I just said is true, it's interesting, but you find it's relatively accurate.
132
I think that there is a very smart business strategy here.
133
And I've said a version of this about the other companies at the foundational model layer that aren't Meta and Google, because Meta and Google, frankly, sit on these money gushers where they just generate so much capital that they can fund these things to infinity.
134
But if you're not them, so if you're OpenAI or if you're Anthropic, you have to find an angle.
135
And I think the angles are slightly different for both.
136
But I think what this suggests is that there's a pattern that exists.
137
And I think that that explains some of the framing of what we see in the press, Jason, and why we get these exaggerated claims.
138
Perfect.
139
So there are people who are doing this for nefarious reasons, is, I guess, where you're sort of getting at here.
140
It's a way to.
141
Well, there's also an industrial complex, according to some folks, that are backing this.
142
If you've heard of effective alterism, that was like this movement of a bunch of, I don't know, I guess they consider themselves intellectual sacks.
143
And they were kind of backing a large swath of organizations that I guess we would call in the industry astroturfing, or what do they call it when you make so many of these organizations that they're not real in politics and flooding the zone, perhaps.
144
So if you were to look at this article here, Nick, I think you have the AI existential risk industrial complex graphic there.
145
It seems like a group of people, according to this article, have backed to the tune of 1.6 billion a large number of organizations to scare the begins out of everybody and make YouTube videos, TikToks, and they've made a map of it.
146
There's some key takeaways here from that article where it says here that it's an inflated ecosystem.
147
There's a great deal of redundancy, same names, acronyms, logos with only minor changes, same extreme talking points, same group of people just with different titles, same funding source.
148
There's a funding source called Open Philanthropy, which was funded by Dustin Moskowitz, who is one of the Facebook billionaires.
149
Jr., you worked with him, right?
150
I mean, he was, wasn't he like Zuck's roommate at Harvard or something, and one of the first engineers, made a lot of money.
151
So he funded this.
152
He's an EA, and he funded this group called Open Philanthropy, which then has become the feeder for essentially all these other organizations.
153
And what's interesting is that the guy who set this up for Dustin, Holden Karnofsky, who is a major effective altruist and was doling out all the money, he's married to Dario's sister.
154
And she's, I guess, associated with the EA, and she was one of the co-founders of Anthropic.
155
So, these are not coincidences.
156
I mean, the reality is there's a very specific ideological and political agenda here.
157
Now, what is that agenda?
158
It's basically global AI governance, if you will.
159
They want AI to be highly regulated, but not just at the level of the nation state, but I'd say internationally, supranationally.
160
Well, if you just do a quick search on global compute governance, it'll tell you what the key aspects are.
161
So, number one, they want regulation of computational resources.
162
This includes access to GPUs.
163
They want AI safety and security regulation.
164
They want international, you call them globalist agreements, and they want ethical and societal considerations or policy built into this.
165
Now, what does that sound like?
166
That sounds a lot to me like what the Biden administration was pursuing.
167
Specifically, we had that Biden executive order on AI, which was 100 pages of burnsome regulation that was designed to promote AI safety, but had all these DEI requirements.
168
So, you know, it led to woke AI.
169
You remember when Google launched Black George Washington and so forth?
170
They had the Biden diffusion rule, which created this global licensing framework to sell GPUs all over the world.
171
So, extreme restrictions on proliferation of.
172
They created what's called the AI Safety Institute, and they, again, fostered these international AI summits.
173
So if you actually look at what the Biden administration was tangibly doing in terms of policy and you look at what EA's agenda is with respect to global compute governance, they were pushing hard on these fronts.
174
And now, if you look at the level of personnel, there were very, very powerful Biden staffers who now all work in Anthropic.
175
So probably the most powerful Biden staffer on AI over the past four years was a lawyer named Tarun Chabra.
176
And he now works at Anthropic for Dario.
177
Elizabeth Kelly, who was the founding director of the AI Safety Institute in the government, now works at Anthropic.
178
Like I mentioned, Dario's sister is married to Holdering Karnofsky, who doles out all the money to these EA organizations.
179
So if you were to do something like create a network map, you would see very quickly that there's three key nodes here.
180
There's the effective altruist movement, of which Sam Bank McFreed's the most notable member, but which I think Dustin Mosowitz is now the main funder.
181
There's the Biden administration and like the key staffers, and then you've got Anthropic.
182
And it's a very tightly wound network.
183
Now, why does this work?
184
Well, let's get started.
185
Yeah, because also the goals, I think, is.
186
Yes, well, the goal, like I said, is global compute governance.
187
It's basically establishing national and then international regulations of AI.
188
Now, but they would claim, let's just pause here for a minute.
189
They would claim the reason they're doing it.
190
And so we'll save if we believe this.
191
They're also concerned, as science fiction as it is, that the AI, when we get to like a sort of generalized superintelligence, is going to kill humanity, that this is a non-zero chance.
192
Yuan has said this before.
193
They've sort of taken it to a almost like a certainty.
194
Yes.
195
We're going to have so many of these general intelligences.
196
They only believe that when they're raising money.
197
Well, that's what I'm sort of getting at.
198
I think they believe it all the time, but maybe the press releases are time for the funny thing.
199
But yet they're building.
200
Let me answer.
201
That's a great product.
202
Yeah.
203
Yeah, look, I mean.
204
It is a great product.
205
Cloud kicks us.
206
I'm more interested in the political dimension of this.
207
I'm not bashing a specific product or company.
208
But look, I think that there is some non-zero risk of AI growing into a super intelligence that's beyond our control.
209
They have a name for that.
210
They call it X-risk or existential risk.
211
I think it's very hard to put a percentage on that.
212
I'm willing to acknowledge that is a risk.
213
You know, I think about that all the time, and I do think we should be concerned about it.
214
But there's two problems, I think, with this approach.
215
Number one is X-risk is not the only kind of risk.
216
I would say that China winning the AI race is a huge risk.
217
I don't really want to see a CCP AI running the world.
218
And if you hobble our own innovation, our own AI efforts in the name of stomping out every possibility of X-risk, then you probably end up losing the AI race to China because they're not going to abide by those same regulations.
219
So, again, you can't optimize for solving only one risk while ignoring all the others.
220
And I would say the risk of China winning the AI race is, you know, it might be like 30%.
221
Whereas I think X-risk is probably a much lower.
222
And I do think that they are single-mindedly focused on scaring people with some of these headlines around: first it was the bioweapons, then it was the super intelligence, now it's the job loss.
223
And I think it's a tried and true tactic of people who want to give more power to the government to scare the population, right?
224
Because if you can scare the population and make them fearful, then they will cry out for the government to solve the problem.
225
And that's what I see here: you've got this elaborate network of front organizations, which are all motivated by this EA ideology.
226
They're funded by a hardcore leftist.
227
And by the way, I became aware of Dustin's politics because of the Chase of Boudin recall.
228
I found out that he was a big funder of Chase of Boudin.
229
Remember this?
230
Yeah.
231
Dustin Mossimus and Carrie Tuna, his wife.
232
Also, Reed Hastings just joined the board of Anthropic.
233
Remember when he, back in 2016, tried to drive Peter Thiel off of the board of Facebook for supporting Trump.
234
So, you know, these are like committed leftists, they're Trump haters, but the point is that these are people who fundamentally believe in empowering government to the maximum extent, more government, and empowering government to the maximum extent.
235
Now, my problem with that is I actually think that probably the single greatest dystopian risk associated with AI is the risk that government uses it to control all of us.
236
To me, like you end up in some sort of Orwellian future where AI is controlled by the government.
237
And out of all the risks we've talked about, that's the only one for which I've seen.
238
So, in other words, if you go back to last year when we had the whole woke AI, there was plenty of evidence that the people who were creating these products were infusing their left-wing or woke values into the product to the point where it was lying to all of us and it was rewriting history.
239
And there was plenty of evidence that the Buying EO was trying to enshrine that idea, was basically trying to require DEI be infused into AI models.
240
And it wanted to anoint two or three winners in this AI race.
241
So I'm quite convinced that prior to Donald Trump winning the election, we were on a path of global compute governance where two or three big AI companies were going to be anointed as the winners.
242
And the quid pro quo is that they were going to infuse those AI models with woke values.
243
And there was plenty of evidence for that.
244
You look at the policies, you look at the models.
245
This was not a theoretical concern.
246
This was real.
247
And I think the only reason why we've moved off of that trajectory is because of Trump's election.
248
But we could very easily be moved back onto that trajectory.
249
If you were to look at all three opinions here and put them together, they could all be true at the same time.
250
You've got a number of people, some might call useful idiots, some might call just people with God complexes, who believe they know how the world should operate.
251
Effective altruism kind of falls into that.
252
Oh, we can make a formula, that's their kind of idea, where we can tell you where to put your money, rich people, in order to create the most good.
253
And we're these enlightened individuals with the best view of the world.
254
They might be, who knows?
255
Maybe they're the smartest kids in the room, but they're kind of delusional.
256
The second piece I'll do here is: I think you're absolutely correct, Jamat, that there are people who have economic interests who are then using the who's useful idiots and/or delusional people with God complexes.
257
And then, SAC, inherent to all of that, is they have a political ideology.
258
So, why not use these people with delusions of grandeur in order to secure the bag for their companies, for their investments, and secure their candidates into office so that they can block further people from getting H-100s?
259
Because they literally want to.
260
By the way, that's the part that's very smart about what they're doing.
261
Because, you know, it's not like they're illiquid.
262
They're full of liquidity in the sense that you're bringing in people that are very technically capable, and you're setting up these funding rounds where a large portion goes right back out the door via secondaries.
263
And so, there's all these people that are making money having this worldview.
264
And so, to your point, Jason, it's going to cement that worldview, and then they are going to propagate it even more aggressively into the world.
265
So, I think the threshold question is: should you fear government over-regulation or should you fear autocomplete?
266
And I would say you should not be so afraid of the autocomplete right now.
267
It may get so good that it's an AGI, but right now it's an exceptionally good autocomplete.
268
Yeah, and I just think that, again, it's a tried and true tactic of people who want to give immeasurably more power to the government to try and make people afraid and they stampede people into these policies.
269
Right.
270
And that gives them power.
271
Exactly.
272
Now, why do I think this is important to talk about?
273
On last week's show, I talked about the trip to the Middle East and how we started doing these AI acceleration partnerships with the Gulf states, who have a lot of resources, a lot of money, and they're intensely interested in AI.
274
And the Biden administration was pushing them away.
275
It basically said, you can't have the chips, you can't build data centers.
276
And it was pushing them into the arms of China.
277
The thing that I thought was so bizarre is that the various groups and organizations and former Biden staffers wrote this policy have been agitating in Washington, and they've been trying to portray themselves as China hawks.
278
And I'm like, wait, this doesn't make any sense because this policy, again, there's basically two camps in this new Cold War.
279
It's U.S.
280
versus China.
281
You can pull the Gulf states into our orbit and you can drive them into China's orbit.
282
So this to me just didn't make any sense.
283
And what's happened is that, frankly, you've got this EA ideology that's really motivating things, which is a desire to lock down compute, right?
284
They're afraid of proliferation.
285
They're afraid of diffusion.
286
That's really their motivation.
287
And they're trying to rebrand themselves as China hawks because they know that in the Trump administration, that idea is just not going to get much purchase, right?
288
And your position as czar is a level playing field.
289
People compete, and the good guys, you know, the West, should be supported to hit artificial general intelligence as fast as possible.
290
So the bad guys, China, don't get it first.
291
That's an open competition.
292
I don't know if I would frame it around AGI specifically, but what I would say is that, look, I think our policy should be to win the AI race because the alternative is that China wins it, and that would be very bad for our economy and our military.
293
How do you win the AI race?
294
You got to out-innovate.
295
You got to have innovation.
296
That means we can't have over-regulation and red tape.
297
We've got to build out the most AI infrastructure, data centers, energy, which includes our partners.
298
And then, third, I think it means AI diplomacy because we want to build out the biggest ecosystem.
299
We know that the biggest app store wins, biggest ecosystem wins, right?
300
And the policies under the Biden administration were doing the opposite of all those things.
301
But again, we have to go back to what was driving that.
302
And it was not driven by this Chinahawk mentality.
303
That is now a convenient rebranding.
304
It was driven by this EA ideology, this doomerism.
305
And so this is what I'm talking about: I want to expose it because I think a lot of people on the Republican side don't realize where the ideology is really coming from and who's funding it.
306
They're obviously Trump haters, and they need to be lumered, quite frankly.
307
Freeberg, let me look at it.
308
They do.
309
They need to be lumered.
310
I mean, you know.
311
Freeberg, I want to come back around again because I respect your opinion on, you know, how close we are to turning certain corners, especially in science.
312
So I understand big picture, you believe that the opportunity will be there.
313
Hey, we got people out of fields, you know, in the agricultural revolution, we put them into factories, industrial revolution, then we went to this information revolution.
314
So your position is we will have a similar transition and it'll be okay.
315
But do you not believe that the speed, because we've talked about this privately and publicly on the pod, that this speed, the velocity at which these changes are occurring, you would agree, are faster than the industrial revolution, much faster than the information revolution.
316
So let's one more time talk about job displacement.
317
And I think the real concern here for a group of people who are buying into this ideology is specifically unions, job displacement.
318
This is something the EU cares about.
319
This is something the Biden administration cares about.
320
If truck drivers lose their jobs, just like we went to bat previously for coal miners, and there were only 75,000 or 150,000 in the country at the time, but it became the national dialogue.
321
Oh my God, the coal miners.
322
Okay, coders, you think there'll be more code to write, but driving, there's not going to be more driving to be done.
323
So is this time different in terms of the velocity of the change and the job displacement in your mind, Freeberg?
324
The velocity is greater, but the benefit will be faster.
325
So the benefit of the Industrial Revolution, which ultimately drove lower-priced products and broader availability of products through manufacturing, was one of the key outputs of that revolution, meaning that we created a consumer market that largely didn't exist prior.
326
Remember, prior to the Industrial Revolution, if you wanted to buy a table or some clothes, they were handmade.
327
They were kind of artisanal.
328
Suddenly, the Industrial Revolution unlocked the ability to mass produce things in factories, and that dropped the cost and the availability and the abundance of things that everyone wanted to have access to, but they otherwise wouldn't have been able to afford.
329
So suddenly everyone could go and buy blankets and clothes and canned food and all of these incredible things that started to come out of this Industrial Revolution that happened at the time.
330
And I think that folks are underestimating and under-realizing the benefits at this stage of what's going to come out of the AI revolution and how it's ultimately going to benefit people's availability of products, cost of goods, access to things.
331
So the counterbalancing force, Jay Cal is deflationary, which is let's assume that the cost of everything comes down by half.
332
That's a huge relief on people's need to work 60 hours a week.
333
Suddenly you only need to work 30 hours a week and you can have the same lifestyle or perhaps even a better lifestyle than you have today.
334
So the counter argument to your point, but the counter argument to your point is that there's going to be this cost reduction and abundance that doesn't exist today.
335
Give an example.
336
Let's give like some examples that we could see.
337
Automation and food prep.
338
So, we're seeing a lot of restaurants install robotic systems to make food, and people are like, oh, job loss, job loss.
339
But let me just give you the counterside.
340
The counterside is that the cost of your food drops in half.
341
So, suddenly, you know, all the labor costs that's built into making the stuff you want to pick up, everyone's freaking out right now about inflation.
342
Oh, my God, it's $8 for a cup of coffee, it's $8 for a latte.
343
This is crazy, crazy, crazy.
344
What if that dropped down to two bucks?
345
You're going to be like, man, this is pretty awesome with good service and good experience, and don't make it all dystopian.
346
But suddenly, there's going to be this like incredible reduction or deflationary effect in the cost of food.
347
And we're already starting to see automation play today in the food system to bring inflation down.
348
And that's going to be very powerful for people.
349
Shout out to ETSA, Cloud Kitchens, and CafeX.
350
We all took swings at the bat at that exact concept: it could be done better, cheaper, faster.
351
One of the amazing things of these vision action models that are now being employed is you can rapidly learn using vision systems and then deploy automation systems in those sorts of environments where you have a lot of kind of repetitive tasks that the system can be trained and installed in a matter of weeks.
352
And historically, that would have been a whole startup that would have taken years to figure out how to get all these things together and custom program it, custom code it.
353
So, the flip side is like when Uber hit, those people were not drivers.
354
Think about the jobs that all those people had prior to Uber coming to market.
355
And then, the reason they drove for Uber is they could make more money driving for Uber or now driving the flexibility or DoorDash and the flexibility.
356
So, their lifestyle got better.
357
They had all of this more control in their life, their incomes went up.
358
And so there's a series of things that you are correct won't make sense in the future from a kind of standard of work perspective.
359
But the right way to think about it is opportunity gets created.
360
New jobs emerge, new industry, new income, costs go down.
361
And so I keep harping on this that it's really hard today to be very prescriptive, to Sax's point, about what exactly is around the corner.
362
But it is an almost certainty that what is around the corner is more capital will be deployed.
363
That means the economy grows.
364
That means there's a faster deployment of growth of new jobs, new opportunities for people to make more money, to be happier in the work that they do.
365
And the flip side being things are going to get cheaper.
366
So we're waxing philosophical here, but I think it's really key because you can focus on the one side of the coin and miss the whole other.
367
And that's what a lot of journalists and wonder commentators and fear-mongerers do is they miss that other side.
368
Got it.
369
Well said, Freedberg.
370
Well said.
371
I think I've heard Satya turn this question around about job loss, saying, well, do you believe that GDP is going to grow by 10% a year?
372
Because what are we talking about here?
373
In order to have the kind of disruption that you're talking about, where, I don't know, 10 to 20% of knowledge workers end up losing their jobs, AI is going to be such a profound force that it's going to have to create GDP growth like we've never seen before.
374
That's right.
375
So it's easier for people to say, oh, well, 20% of people are going to lose their jobs.
376
But wait, we're talking about a world where the economy is growing 10% every year.
377
Like, do you actually believe that?
378
That's more income.
379
That's more income for everyone.
380
That's new jobs being created.
381
It's an inevitability.
382
We've seen this in every revolution.
383
You know, prior to the Industrial Revolution, 60% of Americans worked in agriculture.
384
And when the tractor came around and factories came around, those folks got to get out of doing manual work.
385
And they got to go work in a factory where they didn't have to do manual labor to move things.
386
Yeah, they did things in the factory with their hands, but it wasn't about grunt work in the field all day in the sun.
387
And it became a better standard of living.
388
It became new jobs.
389
And today became a five-day work week.
390
It went from a seven-day work a day.
391
And it's from a seven to eight days work week to 100 hours a week to 45, 50 hours a week.
392
And now I think the next phase is we're going to end up in less than 30 hours a week with people making more money and having more abundance for every dollar that they earn with respect to what they can purchase and the lives they can live.
393
That means more time with your family, more time with your friends, more time to explore interesting opportunities.
394
So, you know, we've been through this conversation a number of times.
395
I know I'm not, no, I'd say we can straight up, I think, and really unpack it because the fear is peaking now, Sachs.
396
People are using this moment in time to scare people that, hey, the jobs are going to go away and they won't come back.
397
But what we're seeing on the ground, Sachs, is I'm seeing many more startups getting created and able to accomplish more tasks and hit a higher revenue per employee than they did in the last two cycles.
398
So it used to be, you know, you try to get to a quarter million in revenue per employee, then 500.
399
Now we're regularly seeing startups hit a million dollars in revenue per employee, something that was rarefied air previously, which then speaks to your point, Freeberg, that there'll be more abundance.
400
There'll be more capital generated, more capital deployed.
401
Because there's more capital deployed for more opportunities, but you're going to need to be more resilient, I think.
402
Yeah.
403
I think it's actually very hard to completely eliminate a human job.
404
The ones that you cited, and Jay Cow, you keep citing the same ones because I actually don't think there's that many that fit in this category.
405
The drivers and maybe level one customer support, because those jobs are.
406
But when you think about even like what a salesperson does, right?
407
It's like, yes, they spend a lot of time with prospects, but they also spend time negotiating contracts and they spend time doing post-sale implementation and follow-up, and they spend time learning the product and giving feedback.
408
I mean, it's a multifaceted job, and you can use AI to automate pieces of it, but to eliminate the whole job is actually very hard.
409
And so I just think this idea that boom, 20% of the workforce is going to be unemployed in two years, I just don't think that it's going to work that way.
410
But look, if there is widespread job disruption, then obviously the government's going to have to react and we're going to be in a very different societal order.
411
But my point is, you want the government to start reacting now before this is actually happening.
412
Yeah, we don't need to be precogs and predict it.
413
Yeah.
414
It's a total power grab.
415
It's a total power grab to give the government and these organizations more power before the risk is even manifested.
416
And let me say this as well: with respect to all these regulations that were created, the 100-page by NEO and the 200-page diffusion rule, none of these regulations solve the X-risk problem.
417
None of these things actually would prevent the most existential risks that we're talking about.
418
They don't have to sign for alignment.
419
They don't sign for the kill switch.
420
Yeah, when someone actually figures out how to solve that problem, I'm all ears.
421
You know, look, I'm not cavalier about these risks.
422
I understand that they exist, but I'm not in favor of the fear-mongering.
423
I'm not in favor of giving all this power to the government before you even know how to solve these problems.
424
Shamath, you did a tweet about entry-level jobs being toast.
425
So I think there is a nuance here, and both parties could be correct.
426
I think the job destruction is happening as we speak.
427
I'll just give one example and then drop two.
428
One job in startups that's not driving a car or super entry-level was people would hire consultants to do recruitment and to write job descriptions.
429
Now, I was at a journal last night talking to a bunch of founders here in Singapore, and I said, How many people have used AI to write a job description?
430
Everybody's hand went up.
431
I said, How many of you with that job description was that job description better than you could have written or any consultant?
432
And they all said, Yes, 100% AI is better at that job.
433
That was a job, a high-level HR recruitment job or an aspect of it, SAC.
434
So that was half the job, a third of the job, to your point.
435
The chores are being automated.
436
So I do think we're going to see entry-level jobs, Samath.
437
The ones that get people into an organization, maybe they're going away.
438
And was that your point of your tweet, which we'll pull up right here?
439
If a GPT is a glorified autocomplete, how did we used to do glorified autocomplete in the past?
440
It was with new grads.
441
Newgrads were our autocomplete.
442
And to your point, the models are good enough that it effectively allows a person to rise in their career without the need of new grad grist for the mill, so to speak.
443
So I think the reason why companies aren't hiring nearly as many new grads is that the folks that are already in a company can do more work with these tools.
444
And I think that that's a very good thing.
445
So you're generally going to see OpEx as a percentage of revenue shrink naturally, and you're going to generally see revenue per employee go up naturally.
446
But it's going to create a tough job market for new grads in the established organizations.
447
And so what should new grads do?
448
They should probably steep themselves in the tools.
449
The most important thing for whether there are jobs available for new grads or not is whether the economy is booming.
450
So, obviously, in the wake of a financial crisis, the jobs dry up because everyone's cost-cutting, and those jobs are the first ones to get cut.
451
But if the economy is booming, then there's going to be a lot more job creation.
452
And so, again, if AI is this driver and enabler of tremendous productivity, that's going to be good for economic growth.
453
And I think that that will lead to more company formation, more company expansion at the same time that you're getting more productivity.
454
Now, to give an example, one of the things I see a lot discussed online about these coding assistants is that they make junior programmers much better.
455
Because, you know, if you're already like a 10x programmer, very experienced, you already knew how to do everything.
456
And you could argue that the people who benefit the most are the entry-level coders who are willing to now embrace the new technology, and it makes them much more productive.
457
So, in other words, it's a huge leveler, and it takes an entry-level coder and makes them 5x or 10x better.
458
So, look, this is an argument I see online.
459
The point is just, I don't think we know how this cuts yet.
460
I agree.
461
And I just think there's like this doomerism is premature, and it's not a coincidence that it's being funded and motivated by this hardcore ideological element.
462
I'll tell you my hiring experience.
463
We have about 30 people at 8090, and the way that I found it to work the best is you have senior people act as mentors, and then you have an overwhelming corpus of young, very talented people who are AI native.
464
And if you don't find that mix, what you have instead are L7s from Google and Amazon and Meta who come to you with extremely high salary demands and stock demands.
465
And they just don't thrive.
466
And part of why they don't thrive is that they push back on the tools and how you use them.
467
They push back on all these things that the tools help you get to faster.
468
This is why I think it's so important for the young folks to just jump in with two feet and be AI native from the jump because you're much more hireable, frankly, to the emergent company.
469
And the bigger companies, you'll have a lot of these folks that see the writing on the wall, may not want to adapt as fast as otherwise.
470
Another way, for example, that you can measure this is if you look inside your company on the productivity lift of some of these coding assistants for people as a distribution of age, what you'll see is the younger people leverage it way more and have way more productivity than older folks.
471
And I'm not saying that as an ageist comment.
472
I'm saying that it's an actual reflection of how people are reacting to these tools.
473
What you're describing is a paradigm shift.
474
It is a big leap.
475
It is.
476
It's like when I went to college, when I took computer science, it was object-oriented programming.
477
It was like C<unk>.
478
It was compiled languages.
479
It was gnarly.
480
It was nasty work.
481
And then you have these high-level abstracted languages.
482
And I used to remember at Facebook, I would just get so annoyed because I was like, why is everybody using PHP and Python?
483
This is like not even real.
484
But I was one of these old light eyes who didn't understand that I just had to take the leaf.
485
And what it did was it grew the top of the funnel of the number of developers by 10x.
486
And as a result, what you had were all of these advancements for the internet.
487
And I think what's happening right now is akin to the same thing.
488
And if you're very rigid in how you think the job should be done technically, I think you're just going to get left behind.
489
Just a little interesting statistic there.
490
Microsoft announced 6,000 job layoffs, about 3% of their workforce, while putting up record profits while being in an incredible cash position.
491
And that's like total confirmation bias.
492
It's like now every time there's a layoff announcement, people try to tie it to AI to feed this Doomer story.
493
I don't think that's an AI story.
494
Well, actually, I think it's an AI story.
495
I think it is because the people they're eliminating are management.
496
And I think the management layer becomes less necessary in the world.
497
It was entry-level employees.
498
Now you're saying it's management.
499
This is total confirmation bias.
500
I think those are.
501
No, no.
502
I think those are two areas that specifically get eliminated.
503
Entry-level, it's too hard to give them the grunt work.
504
And then for the managers who are also there for 20 years.
505
Hold on, let me finish.
506
For those people, I think they are necessary in this new AI monitoring management.
507
What are you talking about?
508
What is the AI agent that's doing management right now in companies?
509
Oh, this theory doesn't even make sense.
510
Oh, no, it totally does.
511
There are tools now that are telling you these are the most productive people in the organization.
512
Tromak just outlined who's shipping the most, et cetera, who's using the tools.
513
And then people are saying, well, why do we have all these highly priced people who are not actually shipping code, who are L7s?
514
You're totally following for some sort of narrative here.
515
This makes no sense.
516
I don't think I am.
517
Yeah.
518
Let me be very clear what I'm saying.
519
What I am saying is AI natives are extremely productive.
520
They use these tools.
521
They're very facile with them.
522
I think it's very reductive, but what you see is the older or more established in your career you are in technical roles, what I see is that it's harder and harder for folks like that to embrace these tools in the same way.
523
Now, how does it play out in terms of jobs?
524
I think that just these tools are good enough where the net new incremental task-oriented role that would typically go to a new grad, a lot of that can be defrayed by these models.
525
That's what I'm saying very cool, specifically.
526
And I don't think that speaks to management.
527
I agree with Sachs.
528
But it has nothing to do with it.
529
Sergei said, Freeberg, when he came to our F1, that management will be the first thing to go.
530
I was talking to some entrepreneurs last night, again, here in Singapore, and they are taking all the GitHub and JIRA cards and things that have been submitted, plus all the Slack messages in their organization, and they're putting them into an LLM and having it write management reports of who is the most productive in the organization.
531
And in the new version of Windows, it's monitoring your entire desktop, Freeberg.
532
Management is going to know who in the organization is actually doing work, what work they're doing, and what the result of that work is through AI.
533
That is the future of management.
534
And you take out all bias, all loyalty, and the AI is going to do that.
535
I couldn't disagree with you more, Sachs, on that.
536
But Freeberg, you wanted to wrap us up on this one.
537
My point is that AI, managers are not losing their job because AI is replacing them.
538
I didn't say that AI wouldn't be a valuable tool for managers to use.
539
Sure, AI would be a great tool for managers, but we're not anywhere near the point where managerial jobs are being eliminated because they're getting replaced by AI agents.
540
We're still at the chatbot stage of this.
541
Literally, Sergei said he took their internal Slack, went into like a dev conversation, and said, who are the underrated people?
542
And it gave him the right answer.
543
Wait, that doesn't allow you to cut 6,000 people.
544
I think it's happening as we speak.
545
It's just not over.
546
You fell for this narrative.
547
You grasped onto this Microsoft restructure where they eliminated 6,000 roles, and you're trying to attribute that to AI now.
548
I think it has to do with AI.
549
I think management is looking at it saying, we are going to replace these positions with AI.
550
We might as well get rid of them now.
551
It is in flux.
552
We'll see who's right in the coming months.
553
Can I make another comment?
554
Freyberg, wrap us up here so we can get on to the next topic.
555
This is a great topic.
556
So I want to make one last point, which I think and Sachs, you may not appreciate this, so we can have a healthy argument about this.
557
I think in the same way that all of this jobs are going to get lost to AI fear-mongering, there's a similar narrative that I think is a false narrative around there's a race in AI that's underway between nation states.
558
And the reason I think it's false is if I asked you guys the question, who won the Industrial Revolution?
559
The Industrial Revolution benefited everyone around the world.
560
There are factories, and there's a continuous effort and continuous improvement in manufacturing processes worldwide.
561
That is a continuation of that revolution.
562
Similar, if I asked who won the internet race, there were businesses built out of the U.S., businesses built out of China, businesses built out of India and Europe that have all created value for shareholders, created value for consumers, changed the world, et cetera.
563
And I think the same is going to happen in AI.
564
I don't think that there is a finish line in AI.
565
I think AI is a new paradigm of work, a new paradigm of productivity, a new paradigm of business, of the economy, of livelihoods, of pretty much everything, every interaction humans have with ourselves and the world around us will have in its substrate AI.
566
And as a result, I think it's going to be this continuous process of improvement.
567
So I'm not sure.
568
Look, there are different models, and you can look at the performance metrics of models, but you can get yourself spun up into a tizzy over which model is ahead of the others, which one's going to, quote, get to the finish line first.
569
But I think at the end of the day, the abundance and the economic prosperity that will arise from the continuous performance improvements that come out of AI and AI development will benefit all nation states and actually could lead to a little bit more of a less resource-constrained world where we're all fighting over limited resources and there's nation-state definitions around who has access to what, and perhaps more abundance, which means more peace and less of this kind of resource-driven world.
570
Sax, your thought on the Kumbaya theory?
571
Exposed by Freeberg.
572
Yeah.
573
I'll partially agree in the sense that I don't think the AI race is a finite game.
574
It's an infinite game.
575
I agree that there's no finish line, but that doesn't mean there's not a race going on.
576
So, for example, an arms race would be a classic example of a competition between countries to see who is stronger to basically amass power.
577
And they might be neutralizing each other.
578
The balance of power may stay in equilibrium, even though both sides feel the need to constantly up-level their arms, their power.
579
And so I think that, to use the term that Mir Sheimer used at the All-In Summit, we are in an iron cage.
580
The U.S.
581
and China are the two leading countries in the world, economically, militarily, technologically.
582
They both care about their survival.
583
The best way to ensure your survival in the self-help world is by being the most powerful.
584
And so these are great powers who care a lot about the balance of power, and they will compete vigorously with each other to maintain the greatest balance of power between them.
585
And high-tech is a major dimension of that competition.
586
And within high-tech, AI is the most important field.
587
So, look, there is going to be an intense competition around AI.
588
Now, the question is: how does that end up?
589
I mean, it could end up in a tie, or in it could end up in a situation where both countries benefit, maybe open source wins, maybe neither side gains a decisive advantage, but they're absolutely going to compete because neither one can afford to take the risk that the other one will develop a decisive advantage.
590
Christener's dilemma: nuclear proliferation is a good analogy.
591
I would argue nuclear deterrence led to a more peaceful world in the 20th century.
592
I mean, is that fair to say, Sachs, that ultimately.
593
What happened with nuclear is that the actual underlying technology hit an asymptote, it plateaued, right?
594
And so, we ended up in a situation where, in the case of the United States versus the Soviet Union, where both sides had enough nukes to blow up the world many times over, and there wasn't really that much more to innovate.
595
So, you know, the underlying technological competition had ended, the dynamic was more stable, and they were able to reach an arms control framework to sort of control the arms race, right?
596
I think AI is a little different.
597
We're in a situation right now where the technology is changing very, very rapidly, and it's potentially on some sort of exponential curve.
598
And so, therefore, being a year ahead, even six months ahead, could result in a major advantage.
599
I think under those conditions, both sides are going to feel the need to compete very vigorously.
600
I don't think they can sign up.
601
But this is a system of productivity, right?
602
For an agreement to slow each other down.
603
I just think that's a good idea.
604
But nuclear was not a system of productivity.
605
It was.
606
This is a system of making more with less, which unleashes benefits to everyone in a way that perhaps should be calming down the conflict and the technology.
607
You've got to admit that there is a potential dual use here.
608
There's no question that the armies of the future are going to be drones and robots and they're going to be AI-powered.
609
And as long as that's the case, these countries are going to compete vigorously to have the best AI.
610
And they're going to want their leaders, their national champions, their startups and so forth to win the race.
611
What's the worst case, Sachs, if China wins the AI race?
612
What is the worst scenario?
613
Ask what it means first.
614
Sax, because that's literally what I'm asking.
615
Like, what would that scenario be?
616
Would they invade America and they dominate us forever?
617
And what does it mean to lead?
618
Yeah.
619
Yeah.
620
What does it mean to win?
621
To me, it would mean that they achieve a decisive advantage in AI such that we can't leapfrog them back.
622
And an example of this might be something like 5G, where Huawei somehow leapfrogged us, got to 5G first and disseminated it through the world.
623
They weren't concerned about diffusion.
624
They were interested in promulgating their technology throughout the world.
625
If the Chinese win AI, they will sell more products and services around the globe than the U.S.
626
Trevor Burrus This is where we have to change our mindset towards diffusion.
627
I would define winning as the whole world consolidates around the American tech stack.
628
They use American hardware in data centers that, again, are fundamentally powered by American technology.
629
And, you know, just look at market share.
630
Okay.
631
If we have like 80 to 90% market share, that's winning.
632
If they have 80% market share, then we're in big trouble.
633
So it's very simple.
634
It means.
635
Yeah, but if the market grows.
636
They will have a more prosperous life.
637
And as a result, it's not necessarily the framing about if we don't get there first, we're necessarily going to lose.
638
I get that there's an edge case of conflict or what have you, but I do think that there's a net benefit where the whole world suddenly is in this more prosperous state.
639
And this is a classic example of a dual-use technology where there are both economic benefits and there are military benefits.
640
Yes.
641
GPS would come to mind in this example, right?
642
Like my summary point is just that it's not all about a losing game with respect to this, quote, race with other nation states.
643
But at the end of the day, yes, there is risk.
644
But I do think that if the pace of improvement stays on track like it is right now, holy shit, I think we're in a pretty good place.
645
That's just my point.
646
Some positivity.
647
Okay.
648
Look, I hope that the AI race stays entirely positive and it's a healthy competition between nations and the competition spurs them on to develop more prosperity for their citizens.
649
But as we talked about at the AI summit, there's two ways of looking at the world.
650
There's kind of the economist way that Jeffrey Sachs was talking about, and then there's the balance of power way, a realist way, which Mirsheimer was talking about.
651
And when economic prosperity and survival or balance of power come into conflict, it's the realist view of the world that it's the balance of power that gets privileged.
652
And I just think that's the way that governments operate: prosperity is incredibly important.
653
We want economic success, but power is ultimately privileged over that.
654
And this is why we're going to compete vigorously in high-tech.
655
That's why there is going to be an AI race.
656
Okay.
657
Perfect segue.
658
I had a lunch with a bunch of family offices and capital allocators, government folks here in Singapore, and they were talking about our discussion last week about the Big Beautiful bill and the debt here in the United States.
659
It's permeating everywhere.
660
The two conversations at every stop I've made here is the Big Beautiful bill and the balance sheet of the United States, as well as tariffs.
661
So we need to maybe revisit our discussion last week.
662
Chamat, you had, and Freyberg did an impromptu call with Ron Johnson over the weekend, which then spurred him going on 20 other podcasts to talk about this.
663
Stephen Miller from the administration has been tweeting some corrections or his perceived corrections about the bill.
664
And Saxa, I think you've also started tweeting this.
665
Where do we want to start?
666
Maybe there are just a couple of facts that should be cleaned up.
667
Okay, so facts from the administration, their view of our discussion.
668
Well, even though I was defending the bill last week, on the whole, I wasn't saying it was perfect.
669
I was just saying it was better than the status quo.
670
Yeah, you were clear about that, man.
671
Yeah.
672
But even I, in doing that, was conceding some points that I think were just factually wrong.
673
And the big one was that I said I was disappointed that the Doge cuts weren't included in the Big Beautiful bill.
674
What Stephen Miller has pointed out is that reconciliation bills can only deal with what's called mandatory spending.
675
They can't deal with what's called discretionary spending.
676
And since the Doge cuts apply to discretionary spending, they just can't be dealt with in a reconciliation bill.
677
They have to be dealt with separately.
678
There can be a separate rescission bill that comes up, but it can't be dealt with in this bill.
679
I really want the Doge cuts to happen.
680
But it's just a fact that the Doge cuts cannot happen in the Big Beautiful bill.
681
It's not that kind of bill.
682
And I think it's therefore wrong to blame Big Beautiful Bill for not containing Doge cuts when the Senate rules don't allow that.
683
You know, it all goes back to the Byrd rules.
684
There are only specific things that can be dealt with through reconciliation, which is this 50-vote threshold.
685
And it has to be quote-unquote mandatory spending.
686
Discretionary cuts are dealt with in annual appropriations bills that require 60 votes.
687
Now, look, this is kind of a crazy system.
688
I don't know exactly how it evolved.
689
I guess Robert Byrd is the one who came up with all this stuff, and maybe they need to change the system.
690
But it's just wrong to blame the Big Beautiful bill for not containing the Doge cuts.
691
That's just a fact.
692
So the other thing is that the BBB does actually cut spending.
693
It's just not scored that way because when the bill removes the sunset provision from the 2017 tax cuts, the CBO ends up scoring that as effectively a spending increase.
694
But tax rates are simply continuing at their current level.
695
In other words, at this year's level.
696
So if you used the current year as your baseline, okay, and then compared it to spending next year, it would score as a cut in spending.
697
So it's just not, it's not correct to say this bill increases spending.
698
It does actually result in a mandatory spending cut, but it's not getting credit for that because we're continuing the tax rates at the current year's rates.
699
Do you believe, Sachs, that this administration, which you are part of, in four years?
700
Will it have reduced the deficit, or will the deficit continue to grow at $2 trillion a year?
701
What is your belief?
702
Because there's a lot of strategies going on here.
703
Yeah, my belief is that President Trump came into office inheriting a terrible fiscal situation.
704
I mean, basically that he created and that Biden created.
705
They both put $8 trillion on the debt.
706
That's right.
707
It's a big difference.
708
It's a big difference to add to the deficit when you're in the emergency phase of COVID.
709
And there's emergency.
710
I think it's a bigger for that.
711
Sure.
712
And it's emergency spending.
713
It was never supposed to be permanent.
714
And then somehow Biden made it permanent.
715
And he wanted a lot more.
716
Remember Build Back Better?
717
He wanted a lot more.
718
So, you know, it's tough when you come into office with a, what is, $2 trillion annual deficit.
719
So to my original question.
720
Now, look, hold on.
721
Would I like to see the deficit eliminated in one year?
722
Yeah, absolutely.
723
But there's just not the votes for that.
724
Well, I asked you before.
725
There's a one-vote margin here in the House, and the Democrats aren't cooperating in any way.
726
So I think that the administration is getting the most done that it can.
727
This is a mandatory spending cut.
728
And I think the Doge cuts will be dealt with, hopefully, through rescission in a subsequent bill.
729
I'm asking you about four years from now.
730
Will we be sitting here in four years?
731
Will Trump have cut spending by the end of this term, in another three and a half years?
732
Will we be looking at a balanced budget potentially?
733
Is that the goal of the administration?
734
Or will we be at $42, $44, $45 trillion at the end of Trump's second term, David Senator?
735
Listen, if you want that level of specificity, you're going to have to get Scott Besson on, okay?
736
This is just not my area.
737
I'm not going to pretend to have that level of detailed answers.
738
But what I believe is that the Trump administration's policy is to spur growth.
739
I think that.
740
I think let's stop being doomers about it.
741
We need that productivity boost.
742
And I think that the net result of those things will be to improve the fiscal situation.
743
Do I want more spending cuts?
744
Yeah, but look, we're getting more than was represented last week.
745
Let's put it that way.
746
Okay, fair enough, Sachs.
747
Thank you for the cleanup there.
748
Chamath, our bestie, Elon, was on the Sunday shows, and he said, hey, the bill can be big or it can be beautiful.
749
It can't be both.
750
He seems to be, I'll say, displeased or maybe not as optimistic about balancing the budget and getting spending under control.
751
But he still believes in Doge, obviously, and hopefully Doge continues.
752
You seemed a little bit concerned last week.
753
A week's past.
754
You've heard some of Stephen Miller's opinions.
755
Where do you net out seven days from our big, beautiful budget bill debate last week?
756
A week ago.
757
Well, I mean, I think Stephen's critique of how the media summarized the reaction to the bill is accurate.
758
And I think it's probably useful to double-click into one thing that Sachs didn't mention, but that Stephen did.
759
A lot of this pivots around the CBO, which is the Congressional Budget Office, and how they look at these bills.
760
And there's a lot of issues with how they do it.
761
In one specific case, which Sachs just mentioned and Stephen talked about, is that they have these arcane rules about the way that they score things.
762
And what they were assuming is that the tax rates would flip back to what they were before the first Trump tax cuts, which obviously would be higher than where they are today.
763
What that would mean in their financial model is we were going to get all that money.
764
Now, to maintain the tax cuts where we are, they now then would look at that and say, oh, hold on, that's a loss of revenue.
765
Why are all of these things important?
766
I downloaded the CBO model, went through it, and what I would say is, at best, it's Spartan, which means that I don't think a financial analyst or somebody that controls a lot of money will actually put a lot of stock in their model.
767
I think what you'll have happen is people will build their own versions bottoms up.
768
Do you trust it, the CBO's version of this, or do you largely trust it?
769
I don't think the CBO really knows what's going on, to be totally honest with you.
770
Okay.
771
I think that there are parts of what they do which they're also opaque on.
772
Nick, I sent you a tweet from Goldman Sachs.
773
So here's what Goldman put out.
774
Now, the point is, when you build a model, what you're trying to do is net out all of these bars.
775
Okay, you're trying to add the positive bars and the negative bars, and you figure out what is the total number at the end of it.
776
Now, in order to do that, when you see the bars on the far right, that's a $2034.
777
That's very different than a $2025.
778
The CBO doesn't disclose how they deal with that.
779
They don't disclose the discount rate.
780
So you can question what that is.
781
The CBO makes these assumptions that, as Stephen pointed out, are very brittle with respect to the tax plan.
782
That's not factored in here.
783
So those are the issues with the way the CBO scores it.
784
Now, Peter Navarro published an article, which I think is probably the most pivotal article about this whole topic.
785
Peter Navarro of Tariff.
786
Yeah, here I think he nails it right in the bullseye, which is the bond market needs to make a decision on one very critical assumption when they build their own model.
787
Okay, so let's ignore the CBO's kind of brittle math and the Excel that they post on their website.
788
People are going to do their own because they're talking about managing their own money.
789
But Navarro basically points to the critical thing, which is: listen, those CBO assumptions also include a fatal error, which is they assume these very low levels of GDP.
790
What you're probably going to see in Q2 is a really hot GDP print.
791
If I'm a betting man, which I am, I think the GDP print is going to come in above three, not quite four, but above three.
792
And so, what Peter is saying here is: hey, guys, like you're estimating 1.7% GDP.
793
Why don't you assume 2.2?
794
Or why don't you assume 2.7 or any number?
795
Or really, what he's saying is, why don't you build a sensitivity so that you can see the implications of that?
796
And I think that that is a very important point.
797
Okay, so where do I net out a week later, Jason?
798
It's pretty much summarized in the tweet that I posted earlier today.
799
So, over the last week, as people have digested it, I think that there are small actors in this play and big actors.
800
The biggest actor is obviously President Trump, but the second biggest actor is the long end of the bond market.
801
These are the central bankers, the long bond holders, and these macro hedge funds.
802
Why?
803
Because they will ultimately determine the United States.
804
How expensive will it be to finance our deficits, irrespective of whatever the number is?
805
It could be a dollar or it could be a trillion dollars.
806
That doesn't matter right now.
807
The point is, what is going to be our cost of capital?
808
And what's happened over the last little while is that they've steepened the curve and they've made it more expensive for us to borrow money.
809
That's just the fact.
810
So, how do we get in front of this?
811
I think the most important thing, if you think about what Peter Navarro said, is this plan and the bill can work if we get the GDP right.
812
Okay?
813
So, how do you get the GDP right?
814
And this is where I have one very narrow set of things that I think we need to improve.
815
And the specific thing that I'll go back to is today, America is at a supply-demand trade-off on the energy side.
816
What does that mean?
817
We literally consume every single bit of energy that we make.
818
We don't have slack in the system.
819
We are growing our energy demands on average about 3% a year.
820
So, I think the most critical thing we need to do is to make sure the energy markets stay robust, meaning there's a lot of investment that people are making.
821
On Tuesday, I announced a deal that I did building a one-gigawatt data center in Arizona.
822
This is a lot of money.
823
This is little old me, but there are lots of people ripping in huge, huge, huge checks, hundreds of billions of dollars.
824
I think the sole focus has to be to make sure that the energy policy of America is robust and it keeps all the electrons online.
825
If there's where things start to get a little funky.
826
So, I think where I am is I think President Trump should get what he wants.
827
I think the bill can work, narrowly address the energy provisions, and I think we live to fight another day.
828
So, Friedberg, cynical approach might be: we're working the refs here.
829
The CBO is not taking into GDP.
830
This GDP has a magical unicorn in it.
831
AI and energy is going to spur this amazing growth.
832
But the bond markets don't believe it either.
833
So, are we looking at just a GOP, a party, I'll put the administration aside, that is just as recklessly spending as the Democrats, and they want to change the formula by which they're judged in the future that there's going to be magically all this growth, and growth solves all problems.
834
And what we really need to do, to your point, I think two weeks ago, that this is just disgraceful to put up this much spending, and we have to have austerity, and we need to increase maybe the discipline in the country, and both parties have to be part of that.
835
I'm asking you, from the cynical perspective, maybe to represent or steal me on the other side here.
836
We had a conversation with Senator Ron Johnson after we recorded the pod last week, and he was very clear in a key point, which is that this bill addresses mandatory spending.
837
Just to give you a sense, 70 percent of our federal budget is mandatory spending.
838
30 percent falls into that discretionary category.
839
The mandatory spending is composed of the interest on the debt, which is now well over a trillion dollars a year on its way to a trillion five, almost a trillion a year.
840
And as Ron Johnson shared with us, over the years, more and more programs have been put into the mandatory spending category.
841
And so you can get past the filibustering in the Senate to be able to get budget adjustments done.
842
The key thing he's focused on, and Rand Paul is focused on, and I've talked about, is the spending level of our mandatory programs.
843
The Big Beautiful bill proposes a roughly $70 billion per year cut in Medicaid.
844
Okay, and that sounds awful.
845
How could you do that to people?
846
In 2019, the year before COVID, Medicaid spending was $627 billion.
847
In 2024, it was $914 billion.
848
So the $70 billion cut gets you down to $840.
849
You're still roughly, call it 40% above where you were in 2019.
850
So it's at the right level.
851
And fundamentally, the opportunity to cut those mandatory programs, which I know sounds awful to cut Social Security and cut Medicaid, but the reality is they're not just being cut from a low level.
852
They're being cut from a level that's 60 plus percent higher than they were in 2019.
853
I gave you another example, which is the SNAP program, the food stamp program.
854
Again, $15 billion of the $120 a year that we spend on food stamps is being used to buy soda.
855
And a whole nother $120 is being used to buy other junk food.
856
So they have proposed in this bill to cut SNAP down to 90.
857
And it was 60 in 2019.
858
So it's still 50% above where it was in 2019.
859
So the key point that's being made by Ron Johnson and others is that the spending on these mandatory programs, which account for nearly three-quarters of our federal budget, are still very elevated relative to where we were in 2019.
860
And we are not going to get out of our deficit, barring a massive increase in GDP, without changes to the spending level.
861
Now, I don't put the blame on the White House.
862
This bill passed with one vote in the House, one vote.
863
And so a key point to note, and I've said this from day one, and every time I've gone to DC and every time we've talked about Doge, I've said there's no way any of this stuff's going to change without legislative action from the Congress.
864
And here we are seeing Congress, for whatever reason, you can listen to Ron Johnson, you can listen to Rand Paul, you can listen to others say, you know what, we can't cut that deep.
865
It is going to be too harmful to our constituents.
866
We need to keep the programs at their current levels or make no changes at all or only modest changes.
867
And that's where we are.
868
That's the reality.
869
Now, I do think that Navarro did an excellent job in his op-ed for whatever criticism we may want to lay on Navarro for many other things.
870
He pointed out that the CBO projections in 2017 for the next year's GDP growth numbers was 1.8 to 2%.
871
And it actually came in at 2.9%, a full one point higher because of the Tax and Jobs Act that was passed by the Trump administration in 2017.
872
So the additional money that goes into investments because lower taxes are being paid fueled GDP growth.
873
This is what some people call trickle-down economics.
874
People ridicule it.
875
They say it doesn't work.
876
It's not real.
877
But in this particular instance, they cut taxes and the GDP grew much faster than was projected or estimated by the economists at the CBO.
878
So the argument that's being made is that we are not capturing many of the upsides in the GDP numbers that are being projected.
879
We don't know the economic benefit and effects of AI.
880
We don't know the economic benefits and effects of the work that's being done to deregulate.
881
Another key point, which is not talked about by Navarro or anywhere else, there's a broad effort to deregulate standing up new energy systems, deregulate industry and pharma, deregulate banking.
882
Besson talked about this in our interview with him.
883
All of those deregulatory actions, theoretically, should drive more investment dollars.
884
Because if you can get a biotech drug to market in five years instead of 10, you'll invest more in developing new biotech drugs.
885
If you can stand up a new nuclear reactor in seven years instead of 30, you'll build more nuclear reactors.
886
Money will flow.
887
If you can get a new factory working because it's a lot easier and faster to build the factory and cheaper, you'll build more factories and production will go up.
888
People were really taken, by the way, by your comment that you would shut up about the deficit if we had like a really great energy policy and we were dumping a lot on top of it.
889
I want to build on the point that both Jamatha and Freberg made about growth rates.
890
So there's a very important chart here from Fred.
891
This is the Federal Reserve of St.
892
Louis.
893
This is federal receipts.
894
So basically, it's federal tax revenue as a percent of GDP.
895
And this goes all the way back to, you know, the 1930s, 1940s.
896
So if you look in the post-World War II period, you can see, just eyeballing it, that there's a lot of variation around this.
897
But the line is around 17.5%, plus or minus 2%.
898
And the interesting thing is that this chart reflects radically.
899
So, for example, during some of these periods, we've had 90% top marginal tax rates.
900
We've had 70% top marginal tax rates.
901
So, yeah, under Jimmy Carter, the top marginal tax rate was, I think, 70%.
902
We've had tax rates, you know, under Reagan or Clinton in the 20s.
903
So, the point is that the tax rate that you have and what you actually collect as a percent of GDP don't correlate.
904
The most important thing by far is just how the economy is doing.
905
If you look at the top tick, it's around 2000 there.
906
If you just mouse over it, 1999 to 2000.
907
Yeah, we get like just under 20% of federal receipts of percent of GDP.
908
And tax rates were quite low back then.
909
The reason why is we had an economic boom.
910
So, look, the point is the most important thing in terms of tax revenue is having a good economy.
911
And this is why you don't just want to have very high tax rates because they clobber your economy.
912
So, this point that Navarro was making in that article, it actually makes sense.
913
I mean, 1.7% is a pretty tepid growth assumption.
914
We should be able to grow a lot faster.
915
And if we have a favorable tax policy, you can grow a lot faster.
916
Now, if you go to spending, can we pull up the Fred chart on spending?
917
What you see here is that, I mean, it's been kind of going up, but let's say that since the mid-1970s or so, federal net outlays as a percent of GDP.
918
So, basically, spending was around 20% of GDP.
919
And then what happened is during COVID, it went crazy, went all the way up to 30%, and now it's back down to low 20s, but it's still not back down to 20.
920
And what we need to do is grow the economy.
921
We have to grow GDP to the point where federal net outlays are back around.5% or 17%, get spending to 20%, then you have a budget deficit of 3%, which is much more tolerable.
922
And I think that's Besson's target under his 333 plan, right?
923
Is you get GDP growth back up to 3% and you get the budget deficit down to 3%.
924
All right, Jamap, you had some charts you wanted to share?
925
Well, I think what's amazing is if you take last week and now again this week, we're all converging on the same thing.
926
The path out of this is through GDP growth.
927
And I just want everybody to understand where we are.
928
And this is without judgment.
929
This is just the facts.
930
What this chart shows in gray is the total supply of power in the United States.
931
And the blue line is the utilization.
932
So what you build for is what you think is a premium above the demand, right?
933
You'd say, if there's one unit of demand, let's have 1.2 units of supply, we'll be okay.
934
But as it turns out, historically in the United States, we've had these cycles where we didn't really know what the demand curve would look like.
935
And so over the last number of years, we've stopped really building supply in power.
936
But what happened with things like AI and all of these other things is that the demand just continued to spike.
937
And so what this chart shows is we are at a standstill sitting here today in 2025.
938
On margin, we're actually short power, which is to say, sometimes.
939
So, then we talk about all of these new kinds of energy.
940
And this is just meant to ground us in the facts.
941
If you tried to turn on a project today, sitting here in May of 2025, here's what the timelines are: we all talk about SMRs, small modular reactors.
942
The reality is that if you get everything permitted and you believe the technology can be de-risked, you're still in a 2035-plus timeframe.
943
You're a decade away.
944
If you have an unplanned nat gas plant, today the fastest you could get that on is four years from now.
945
If we tried to restart a mothballed nuclear reactor, of which there are only three we can restart, that's a 2027 to 2030 timeframe.
946
So, let's give us the benefit of the doubt.
947
That's two years away.
948
If we needed a planned NAT gas plant, there's already 24 gigawatts in the queue, which can't get turned on.
949
So, where does this end up?
950
And this is where I think we need to strip away all the partisanship and understand what we're dealing with.
951
We have ready supply of renewable and storage options today.
952
It's the fastest thing that you can turn on.
953
It allows us to turn on supply to meet the demand and utilization.
954
So, I just think it's important to understand that we must not lose energy.
955
We cannot lose the energy market because that is the critical driver of all the GDP.
956
All right, Neepon Steel and the U.S.
957
Steel merger got cleared by President Trump.
958
Nippon is going to acquire a year of steel for $14.9 billion.
959
Biden blocked that, as we had discussed.
960
On Friday, Trump cleared the deal to go through, calling it a partnership that will create 70,000 jobs in the U.S.
961
And on Sunday, Trump called the deal an investment, saying it's a partial ownership, but it will be controlled by the USA.
962
Tramat, there seems to be a reframing of this deal, and that the United States is going to benefit from it, but it's not a sale.
963
Let's set investment.
964
Let's set some context.
965
The United States is always on the wrong side of these deals.
966
Okay, we've been on the wrong side for 20 years, meaning we show up when an asset is stranded or completely run into the ground.
967
For example, we did the auto bailouts at the end of the great financial crisis.
968
If it's not a company and there's toxic assets, we set up something called TARP.
969
What do we get?
970
Not much in return.
971
In this, it's the opposite.
972
And I think that this strategy has worked for many other countries really well.
973
So if you look at Brazil, companies like Embraer and Valle, which are really big Brazilian national champions, have a partnership, a pretty tight coupling with the Brazilian government.
974
The Brazilians have a golden vote.
975
If you look inside of the UK, there's a bunch of aerospace and defense companies, including Rolls-Royce, that have a very tight coupling with the UK government.
976
They have a golden vote.
977
If you look in China, companies like BikeDance and CATL have a very tight coupling with the Chinese government, and the Chinese government has a golden vote.
978
And so, what are all of those deals?
979
Those deals are about companies that are thriving and on the forward foot.
980
I've said this before, but one part of China that I think we need to pay very close attention to is Hu Jintao in 2003 laid out a plan and he said, We are going to create 10 national champions in China in all the critical industries that are going to matter for the next 50 years, including things like batteries and rare earths and AI.
981
And they did it.
982
But for those companies, it allowed them to thrive and crush it.
983
And I think that we need to do that and compete with those folks on an equal playing field.
984
In all industries or in very specific strategic ones, because that would seem like there's corrupting capitalism in free markets.
985
There's the steel man.
986
There's 10 industries that matter.
987
And you can.
988
Some of them, steel is one.
989
I think the precursors for pharmaceuticals are absolutely critical.
990
Got it.
991
I think AI is absolutely critical.
992
I think the upstream lithography and EV deposition and chip making capability, absolutely critical.
993
I think batteries are absolutely critical.
994
And I think rare earths and the specialty chemical supply chain, absolutely critical.
995
If you have those five, you are in control of your own destiny in the sense that you can keep your citizens healthy and you can make all the stuff of the future.
996
So I think if the president is creating a more expansive idea beyond U.S.
997
Deal with this idea of U.S.
998
support, maybe there'll be preferred capital in the future to U.S.
999
Deal.
1000
But if he creates a category by category thing across five or six of these critical areas of the future, I think it's super smart and we should do more of it.
1001
Sachs, what do you think?
1002
Interventionism, putting your thumb on the scale, golden votes, a good idea for America in very narrow verticals, or let the free market decide.
1003
What are your thoughts on this golden vote, having a board seat, et cetera?
1004
Well, it depends what the free market, so to speak, produced.
1005
And the reality is over the past 25 years, is we exported a lot of this manufacturing capacity to China.
1006
And I don't think it was a free market because they had all these advantages under the WTO that we talked about in a previous podcast.
1007
They were able to subsidize their national champions while still remaining compliant with the WTO rules because supposedly they were a developing country.
1008
It was totally unfair.
1009
And what they would do is, through these subsidies, they would allow these national champions to essentially dump their products in the global market and drive everyone else out of business.
1010
They became the low-cost producers.
1011
I think that, as the president just said recently, not every industry has to be treated as strategic.
1012
Clothes and toys, we don't necessarily have to reshore in the United States, but steel production is definitely strategic.
1013
Steel, aluminum, and I'd say the rare earths, we have to have that capacity.
1014
We cannot be completely dependent on China for our supply chain.
1015
So some of these industries have to be re-shored.
1016
And if you need subsidies to do it, I think that you do it for national security reasons, first and foremost.
1017
Yeah, there are other industries where the private market works just fine.
1018
And what we need to do to help those companies is simply not get in their way with unnecessary red tape and regulations.
1019
So I would say empower the free market when America is the winner.
1020
And then in other areas where they're necessary for national security, then you have to be willing to basically protect our industries.
1021
Freeberg, it seems like the great innovation here might also be the American public getting upside when we gave loans to Solyndra and Tesla and Fisker and a bunch of people for battery-powered energy under Obama.
1022
We just got paid back in some cases by Elon.
1023
Other people defaulted, but we didn't get equity.
1024
What if we had, instead of getting our $500 million back in the loan from Elon, which we paid back early and with interest, if we got half back and we got half in equity, RSUs, whatever, stock options, warrants, this would be an incredible innovation.
1025
So, what are your thoughts here?
1026
Because people look to this podcast as, hey, the free market podcast, but this does seem to be a notable exception here of maybe we should get involved and do these golden share votes, board seats, maybe more creative structures in order to win faster.
1027
What are your thoughts, Freeberg?
1028
I don't like it.
1029
I don't like the government.
1030
I don't like markets.
1031
Keep the government out of the markets.
1032
It creates a slippery slope.
1033
First of all, I think markets don't operate well if the government's involved.
1034
It gets inefficient, and that hurts consumers.
1035
It hurts productivity.
1036
It hurts the economy.
1037
Second, I think it's a slippery slope.
1038
You do one thing here.
1039
I have a question, though.
1040
Freeberg, if government non-intervention results in all the steel production moving offshore, if it results in all the rare earth processing and the rare earth magnet casting industries moving offshore, in fact, not just moving offshore, but moving to an adversarial nation such that they can just switch off our supply chain for pretty much every electric motor.
1041
Is that an outcome of the quote-unquote free market that we should accept?
1042
Well, then I think that's where the government can play a role in trade deals to manage that effect.
1043
So you can create incentives that'll drive onshore manufacturing by increasing the tariff or restricting trade with foreign countries so that there isn't a cheaper alternative, which is obviously one of the plays that this Trump administration is trying to do.
1044
I'd rather have that mechanism than the government making actual market-based decisions and business decisions.
1045
You know how inefficient government runs.
1046
You know how difficult it is to assume that that bureaucracy is actually ever going to act and pick any best interests or any good interests at all.
1047
They're just going to f it all up.
1048
So I'd rather keep the government entirely out of the market, create a trade incentive, where the trade incentive basically will drive private markets, private capital to build that industry onshore here because there isn't one and there's demand for it because you've restricted access to the foreign market.
1049
That I think would be the best general solution, Sachs.
1050
And then I think it's a slippery slope because then you could always rationalize something being strategic, something being security interests in the United States.
1051
So then every industry suddenly gets government intervention and government involvement.
1052
And then the third thing is I don't want the government making money that the Congress then says, hey, we've got more money, we've got more revenue, let's spend more money, because then they'll create a bunch of waste and nonsense that'll arise from having increased revenue.
1053
One side, and I will say one thing where I do think we do a poor job is we don't do a good job to answer your question, J.
1054
Cal, of investing the retirement funds that we've mandated through Social Security.
1055
We should be taking the $4.5 trillion that our Social Security beneficiaries have had deducted from their paychecks over many, many years.
1056
And those Social Security future retirees or current retirees are getting completely ripped off because their money is being loaned to the federal government.
1057
It's not being invested.
1058
It's been loaned to the government to spend money and run a deficit and ultimately inflate away the value of the dollar.
1059
We should have been investing those dollars in some of these strategic assets.
1060
So if ever there were to be shared.
1061
Similar, by the way, to what's done in Australia, where these supers are have created an extraordinary surplus of capital.
1062
Same in Norway, same in all the Middle East countries, incredible sovereign wealth funds that benefit the retirees and the population at large.
1063
That's where the dollars should be invested from.
1064
I do think the fundamental focus priority right now should be reforming Social Security while we still have the chance.
1065
We have until 2032 when Social Security will be functionally bankrupt and everyone's going to get overtaxed and kids are going to end up having to pay through inflation for the benefits of the retirees of the last generation.
1066
Breberg's right, we're on a seven-year shot clock to when Social Security is not funded.
1067
And by the way, this opportunity to fix mandatory spending, it was an opportunity to introduce some structural reform in Social Security.
1068
Another reason why I think that there is a degree of discrazziat in this bill, particularly with how Congress had acted, and not addressing what is becoming a critical issue, because everyone wants to get reelected in the next 12 months, 18 months.
1069
They've got elections coming up.
1070
So everyone's scrambling to not mess with that because you can't touch it.
1071
It's like, you know what?
1072
Guys, this is bankrupt in seven years.
1073
It's going to cost us five, 10 times as much when we have to deal with it when everyone runs out of money.
1074
Deal with it now.
1075
We have to fix the problem.
1076
And by the way, we should flip all that money, $4.5 trillion, into an investment account for the retirees where they can own equities and they can make investments in the markets and they can participate in the upside of American industry and the GDP growth that's coming.
1077
Instead, they're getting paid 3.8% or 4.5% average from treasuries that they own that, by the way, are now have a lower credit rating than they've ever had.
1078
You know, it's crazy.
1079
I'm completely agreeing with you.
1080
And I think it's a lack of the leadership on Trump's.
1081
If Trump is going to criticize Taylor Swift and Zelensky and Putin and everybody, you know, all day long on Truth Social, he can criticize Congress and the Democrats and the Republicans on not cutting spending.
1082
I think he should speak up.
1083
I think he was elected to do that.
1084
He was a big part of the mandate.
1085
And he should tone down the tariff chaos and tone up the and lean into intelligent immigration, you know, recruiting great talent to this country.
1086
And he should be pushing to make these bills control spending.
1087
That's just one person's belief.
1088
For the chairman dictator, Jamaica Hapatia, your czar, David Sachs, in that Chris Brioni white shirt.
1089
Very beautiful.
1090
And the Sultan of Science deep in his WAL-E era.
1091
I am the world's greatest moderator.
1092
And as Freeberg will tell you, Executive Cruiser for Life here at the All-Ind Podcast.
1093
We'll see you all next time.
1094
Bye-bye.
1095
Jason at Olin, Doc.
1096
Love you, boys.
1097
Bye-bye.
1098
Let your winners ride.
1099
Rainman David Sachs.
1100
And it said, We open source it to the fans, and they've just gone crazy with it.
1101
Love you, Bestie.
1102
I squeeze up in the wall.
1103
Besties are God.
1104
That is my dog.
1105
Oh, man.
1106
My hand has a room, meet me, I believe.
1107
We should all just get a room and just have one big huge orange because they're all these person.
1108
It's like this sexual tension that they just need to release somehow.
1109
What your beef be.
1110
Let your beat your feet.
1111
We need to get Murphy's Army.
1112
I'm going all in.