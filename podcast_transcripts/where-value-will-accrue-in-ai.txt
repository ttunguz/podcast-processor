--- METADATA START ---
Show: a16z Podcast
Episode: Where Value Will Accrue in AI:â€¦
Host: Unknown
GUESTS: Martine Casado, Sarah Wang 
Guests: Martine Casado, Sarah Wang
Source URL: https://podcasts.apple.com/us/podcast/where-value-will-accrue-in-ai-martin-casado-sarah-wang/id842818711?i=1000710145777
--- METADATA END ---

1
Zero-sum thinking has been wrong.
2
That doesn't mean that you can't get in trouble.
3
Every SaaS company under the sun has launched an AI product.
4
They're not just sitting on their hands.
5
And you'd think that they'd have a huge advantage given distribution, but we're just seeing classic innovators dilemma.
6
GPT wrapper was this like derogatory term.
7
I think you'd come to the conclusion, like, that's not even a thing.
8
When someone writes software on the cloud, you don't call it a cloud wrapper.
9
The success of these companies actually also reflects, obviously, the customer love, but I would also add on top of that tangible value that they're bringing their customers.
10
Conflicts really matter in this space.
11
And so if you're too aggressive early and you don't really think through things, it can really keep you from investing in the one that's winning it.
12
Recorded live at our annual LP Summit in Las Vegas.
13
I sat down with general partners Martine Casado and Sarah Wang for a deep dive on the current state of play in AI.
14
We covered where value is accruing across the stack, how this wave compares to past platform shifts, and what it takes to build and invest in enduring companies in an era of exponential acceleration.
15
From the myth of the GPT wrapper to the rise of AI-native apps and the unexpected lessons behind cursor's breakout growth, all with an eye toward where AI goes next.
16
Let's get into it.
17
As a reminder, the content here is for informational purposes only, should not be taken as legal business, tax, or investment advice, or be used to evaluate any investment or security, and is not directed at any investors or potential investors in any A16Z fund.
18
Please note that A16Z and its affiliates may also maintain investments in the companies discussed in this podcast.
19
For more details, including a link to our investments, please see a16z.com forward slash disclosures.
20
Martine, Sarah, we just went through the state of the firm.
21
What's the state of play right now in AI?
22
The last two and a half years have really felt like a blur.
23
Maybe just to set the table, given that the AI landscape is changing so quickly, Martine and I thought it would be valuable for our internal team actually to reflect and take stock of where value is accruing in the AI ecosystem.
24
You know, I think it really distills into a couple of key takeaways.
25
And that's one, AI companies are growing faster and are larger than even we expected.
26
There's value accruing across every layer of the stack, models, infra, apps.
27
All that being said, there's this paradox that we're seeing where more value creation is accruing in a shorter amount of time paired with more wipeout potential happening over a shorter period of time.
28
We'll definitely dive into that dynamic more.
29
And then finally, our conclusion is that you've got to be on the field, but you have to be smarter about where you're taking those bets than ever before because the stakes are higher.
30
Yeah, and I think as you're listening to this, it's probably worth pointing out that we've come to the opinion that there is no AI.
31
There's like a bunch of subspaces that are totally different that all require their own strategy.
32
So for example, the language models are very different than the diffusion models.
33
The apps are very different than the models themselves.
34
The tooling is different than that.
35
And all these subspaces are very different.
36
And so we're starting to learn that this is as big as software and the strategies need to vary as much.
37
Yeah.
38
Let's put that first point you made more into perspective.
39
What's the scale that we're talking about when we say foundation models are going faster than expected?
40
Yeah, so two years ago, I would have actually said we were probably the firm, maybe the most bullish on where the market could go.
41
And I've got to say, even we are surprised by how large and fast-growing this market is.
42
And if you look at the revenue of just two of the top-tier frontier labs, not only have they surpassed the early revenue ramps of some of the hyperscalers.
43
And I think these stats are even more breathtaking when you think about just the timing of when their products launched.
44
I think what we find even more exciting in this space is that it's not the case that just two companies are growing very quickly in AI.
45
And that shows markets are not only growing faster and much larger than expected, they're also fragmenting.
46
Let's get deeper into some examples.
47
It's obvious OpenAI and Propbic have tremendous growth opportunities ahead of them.
48
Why are we excited for leadership across the stack?
49
There was this view that OpenAI would win everything or these large models would win everything early on.
50
But if you actually look at the history to now the last two years, it's been the opposite.
51
So if you remember, what was the first use case that OpenAI did?
52
It was code.
53
It was Copilot, right?
54
But they lost that.
55
And then they were actually the first to image, really, with DALI.
56
They lost that, right?
57
Midjourney came up.
58
They were the first to real video with Sora, and they lost that.
59
And yet, they've gotten a tremendous amount of value out of text.
60
And so, like Sarah said, I think this is right.
61
The primary takeaway is these markets are larger, and they're growing faster than we expected.
62
And so it results in fragmentation.
63
So things before that we would have said, oh, this is like some sub-thing, and OpenAI will get it, or this is a minor market, or whatever, ends up turning to be large enough to have multiple companies with tremendous growth and tremendous value, right?
64
And so we think the only crime, this is going to be caveated later on, is zero-sum thinking.
65
Like anybody that likes decried, oh, defensibility isn't going to work has been wrong.
66
Anybody that's decried like it's all going to aggregate has been wrong.
67
So zero-sum thinking has been wrong.
68
That doesn't mean that you can't get in trouble.
69
And so we'll talk about that.
70
It's funny because there was all this talk a year ago about GPT wrappers.
71
Every app was a GPT wrapper.
72
You know, foundation models didn't win everything.
73
What changed?
74
And why aren't the foundation models winning everything?
75
I think this is a fun one for a lot of the investors in the room.
76
And the fact that we're seeing this gangbuster's growth in AI apps is really exciting to see.
77
So I think two parts to your question.
78
One, it makes sense that a lot of the focus and investment early on in this cycle was on the infrastructure side.
79
And now what we're seeing is apps are benefiting from that massive investment as intelligence effectively has become free.
80
And you have this aligning of the stars where the fierce competition on the state-of-the-art model market is driving both non-stop continued capability improvement paired with continuous price decreases.
81
And in fact, I think model inference costs have gone down 10x year over year.
82
So the stars, as we say, are aligning on that front.
83
And then on your question of why don't the foundation models just take over everything?
84
I think this is a question.
85
I mean, it's a very reasonable question.
86
It's one that we sort of ask ourselves for every new investment that we make.
87
And we certainly saw this with the early marketing copy AI apps.
88
But I think in talking to the founders of these app companies themselves and then also the model providers, the answer to this question has become increasingly consistent.
89
And that is where you have complex workflows and a ton of customer data where deep integrations actually are necessary to get that last mile of value for the customer.
90
This is where the specialized AI apps are sort of crushing any either foundation model layer or otherwise company in the market.
91
We have actually a couple of examples that we'll cover on this, but to see that has been very interesting given the landscape initially was going in a different direction.
92
I gotta say, like, GPT wrapper was this like derogatory term.
93
I think we've come to the conclusion, like, that's not even a thing.
94
When someone writes software on the cloud, you don't call it a cloud wrapper.
95
Like, you have all of the complexity.
96
There's a tremendous amount of opportunity to add value with traditional software, but also by building your own models.
97
And so, like, we kind of view that, like, you know, listen, this is an evolution in software.
98
These models are an evolution in infrastructure, and there's tremendous opportunity to add value above the set.
99
Someone tweeted that venture capital is just a wrapper around LP capital.
100
But, yeah, to speak to the point, how should we think about AI-native companies relative to traditional SaaS companies?
101
This is an interesting one.
102
The first thing I'd call out that sort of just jumps off the page is that the AI-native companies are far outpacing their SaaS counterparts.
103
And you can see it in terms of new companies blowing past this golden metric of time to 100 million of ARR, which is truly an incredible feat to accomplish on the left.
104
But what's amazing is that it's not just the best companies that are doing really well.
105
It's actually on average, you can see this from the aggregated Stripe data, where AI-native companies are growing faster than sort of the SaaS 2.0 generation, if you call it.
106
And we'd sort of attribute this to a number of factors.
107
One is just looking at the compelling ROI out of the box.
108
And with AI improvements and capabilities, you're seeing this 10x plus improvement in the customer experience as well.
109
Whereas SaaS 2.0, you generally saw a little bit more of an incremental improvement, you know, call it 25, 50%.
110
And then the second piece is it's early days for this, and it's related, but you're starting to see replacement of some of the services budgets versus just software.
111
And the second thing that I'd say, on top of just the fact that the growth itself was happening, is that the relative growth is particularly interesting when you take into account that every SaaS company under the sun has launched an AI product.
112
They're not just sitting on their hands.
113
And you think that they'd have a huge advantage given.
114
And the fact that they have revenue-generating products where they have to devote time and resources changes the game for them.
115
AI companies aren't building an AI product, they're just building a product.
116
A lot of them are newer, and so they don't have this 2021-imposed remote culture.
117
Most of the founders that we work with are in the office six to seven days a week.
118
And then finally, a lot of them tend to be these essentially applied AI engineers, where they're just incredible at wringing out every last drop of value from the LLM in a way that actually translates to customer value.
119
It sort of circles back to the compelling ROI piece.
120
And I think the results speak for themselves.
121
Something else we debated, which inspired this conversation, was defensibility.
122
How should we think about defensibility for this company?
123
Are they defensible?
124
Where does the defensibility come from?
125
Does it come from state?
126
Does it come from contacts?
127
Does it come from brands?
128
It's a hybrid.
129
Our team wants to take that.
130
The actual data on this stuff is really noisy because everything's doing well.
131
So it's kind of hard to have a theory.
132
But if you actually kind of dig into it and you watch this thing for three years, something seems to be pretty clear.
133
And that is a really hard thing about building any startup or software is the bootstrap problem.
134
Like, how do you get the first 100, 200 customers?
135
And like, AI actually solves that problem.
136
It just solves the bootstrap problem.
137
It's like these models are so magical.
138
You wrap one of these bottles, you know, you make it available, and people think it's amazing they show up.
139
But what's also clear is that doesn't solve your retention problem if you're a software company.
140
It solves a very hard problem, it doesn't solve another problem.
141
And arguably, there's actually a lot of perverse economies of scale that are actually in play with these AI companies because the models that commoditize very quickly, anybody can kind of use them, et cetera.
142
And so what we found out is the pattern that seems to work is a startup will come and it'll do a model and we'll get a bunch of users on that model and that'll be great, but then they have to kind of revert to traditional software to build traditional remotes, right?
143
And so, these modes can be anything, be a two-sided marketplace, it could be long-tail integration mode, it could be a workflow mode, whatever it is that we've figured out how to build in the past, they end up having to do.
144
But again, I mean, one last thing to notice is like some of these companies are growing so fast, and the space is so new.
145
Like, we're even seeing effects that we haven't seen in a long time, like brand effects, right?
146
Like, these companies are entering these massive vacuums, and then we all know them.
147
And even though you're like, the competition is just as good, right?
148
You know, like how much better is OpenAI than Amazon?
149
Like, I don't know, but everybody seems to use it because of the brand.
150
Like, how much better is Cursor than the competition?
151
It's a lot better, but like, everybody knows the name, right?
152
And so, like, when you know the name, you do this.
153
And the early internet was like this: everybody knew Google, and everybody knew Amazon, and you had these big brand modes.
154
We're starting to see that come back again in this space.
155
But as far as I can tell, as far as we can tell, there is no inherent endemic moat in the technology stack to AI other than just overcoming the bootstrap problem.
156
Let's double-click on Cursor a bit.
157
What explains its astronomical success?
158
This is just crazy, right?
159
And so, you could ask this question: like, you know, is it they've figured out cold fusion?
160
And, like, actually, some of the answers are actually pretty banal.
161
It's actually the first kind of monetized AI app was code, right?
162
It was Copilot.
163
And so, Microsoft had invested a ton of money and matured the market with Copilot, with VS Code.
164
And so, everybody knew it.
165
It's just like the models weren't quite ready then.
166
And so, you had, you know, probably say 400 to 600 million in ARR of users out there in user behavior.
167
So, when Cursor came out, two things happened: A, they basically followed the same behavior that you saw in VS Code, which is like, you know, this code editor is one.
168
And the second thing is you had the RL wave where you have these models that are using RL.
169
So, code just got way, way, way better, right?
170
And so, it's a phenomenal team, very product-focused.
171
They caught the model wave, and there's existing user behavior, and like the rest is kind of history.
172
I can't tell you how often we'll have a founder show up and they're like, we're the cursor for X.
173
It's hard to articulate the actual user love for these products, which goes a long way.
174
And we really haven't seen it in my opinion since the internet.
175
Absolutely.
176
The success of these companies actually also reflects, obviously, the customer love, but I would also add on top of that tangible value that they're bringing their customers.
177
And I think one thing that's changed over the last 12 months is this shift from just I need AI, like, you know, experimental vibes buying, I'll call it.
178
You have vibe coding, you have vibe enterprise AI purchasing, but to tangible ROI focus.
179
And so, two examples of that.
180
On the cursor side, we host these annual portfolio CTO dinners.
181
And some of the questions that we'll throw out, of course, in the last few years, AI has come up for a significant portion of the dinner.
182
And last year, it was notable that when we asked, hey, CTOs across 24 portfolio companies, how much is AI actually impacting your productivity?
183
And the answer across the board was pretty much 10 to 15%.
184
We're all using GitHub Copilot.
185
And the implication was that there's a lot of hype, not a lot of results.
186
This year, I was pretty blown away by the answers that we got.
187
They spanned from, call it 30 to 50% on the low end in terms of productivity gains, to, I kid you not, one CTO told us that he had seen a 10x productivity lift from himself and his team.
188
They were all using cursor.
189
I think 24 out of 24 portfolio companies were using cursor, and that 90% of the code in their company was AI-generated.
190
This is in a short 12 months, maybe not even 12 months.
191
And so you really are seeing this bump in hardcore ROI.
192
I think customer support is another use case that has been hyped up, if you will.
193
If you talk to a Decagon customer, they're actually slashing their customer support costs by up to 80%.
194
And not only that, they're seeing deflection rates go up from 30% to anywhere from 60% to 80%.
195
And their CSATs, their customer satisfaction scores, are doubling.
196
So this is, like I said, tangible ROI, and that's what's really driving a lot of this growth.
197
And honestly, it's the underlying productivity and impact gain that gets us really fired up.
198
Let's go deeper on the customer segmentation part.
199
What are the ramifications of the fact that a lot of the growth is being driven by the prosumer market?
200
So, like I mentioned before, AI really helps overcome the bootstrap problem.
201
It doesn't have the retention problem.
202
So it's kind of a separate thing that we look at.
203
And it just turns out these companies look like these prosumer companies that we've been looking at for quite a long time, and they all have different profiles.
204
So I just think we should remember that every time we have a super cycle, it tends to start in these prosumer ways, right?
205
The internet did this, right?
206
Earlier, when Sun outlawed the browser, right?
207
This is Sun Microsystems, right?
208
But they didn't really know how to consume it.
209
So the enterprise doesn't know how to consume these new technologies, but there's clearly a lot of value.
210
And so, you know, the individuals pick them up and they use it.
211
And we're seeing a lot of the new behavior.
212
And what's been very interesting is that has already led into an enterprise pipeline like we've never seen.
213
So the fact that these are prosumer businesses, like very specifically to your point, the fact that these are prosumer businesses is not in some way because that's what they always sell to.
214
It's just a natural maturation of the cycle.
215
And if anything, it looks far more promising than it didn't get at a time.
216
To build on Martine's point a little bit more, I think the high amount of prosumer revenue does mean that we're paying attention.
217
I mean, we always pay attention to retention, but we're paying attention to it more than ever before.
218
And a lot of these high-growth apps are not your typical system-of-record 95% gross dollar retention companies that we sort of saw in the 2010s.
219
But importantly, that doesn't mean you should throw the baby out with the bathwater.
220
It's not like, hey, these have terrible retention, and so these are terrible companies, right?
221
And then I think the other piece is for the companies with questionable retention, that's something that we're being cautious about because the valuations that are being demanded in this market do require some sort of customer stickiness and base to build upon, or at least the ability to show that the top of funnel is actually converting into enterprise revenue, as Martine mentioned.
222
And so, this is an area that I think requires a lot of nuance and is one, frankly, that the team is spending a lot of time on.
223
So, we talked about the big winners, but there are also some big wipeouts, as we mentioned.
224
What have we learned about the commonalities between ones that win and ones that don't?
225
So, I think what's interesting about this funding cycle in particular, I know history repeats itself sometimes, but in this case, especially on the foundation model layer side, I think what's remarkable is just the massive size of the rounds that folks are raising before any traction.
226
And we're participating in some of these rounds.
227
We'll talk more about what our thesis is when we do.
228
But as we all know, the more money you raise early on, the more pressure you have to really show performance.
229
DG likes to call this transition going from a tell-the-story company to a show-not-tell company.
230
So, you really need to show-not-tell when you've raised hundreds of millions of dollars.
231
So, there's a couple of themes that we would flag.
232
The key ones are passing on good but not exceptional teams has generally paid off.
233
And then, the second one I'd highlight is that researcheritis, as Martine and I call it, is a real thing.
234
It's particularly important given a lot of incumbents and Chinese companies are pouring money into these spaces.
235
So it's really not for the faint of heart.
236
And then finally, I think the broader point that we make here is that this is not a market where a rising tide lifts all votes.
237
Picking actually matters more than ever.
238
Also just important to realize, unlike even crypto in the early days, conflicts really matter in this space.
239
And so if you're too aggressive early and you don't really think through things, it can really keep you from investing in the one that's winning.
240
Martine, why don't you talk about how what's happening in China affects all the markets?
241
Yeah, so let me just be very quick about that.
242
It's kind of a mixed blessing, right?
243
So on one hand, they build these great open source models.
244
They're not hindered by copyright.
245
They get very cheap access to data.
246
But on the other side, like historically, China's just not been able to build software, at least for like the pro sooner enterprise market, which is my world.
247
They've just never really been able to do that.
248
And so I think that their ability to compete at a software level is pretty limited.
249
At a model level, they're actually quite good, but we benefit a lot from that.
250
And of course, in the consumer space, with TikTok, they've historically been very good.
251
And so I think that's TBD.
252
But for us, for me, I think it's a mixed blessing, but more of a blessing than not.
253
I mean, I think it's actually great to have the competition.
254
And it's great to have these models out there.
255
Let's transition to our thesis.
256
We talked about what to avoid in terms of pitfalls.
257
Let's talk about what we're looking for starting on the foundation model side.
258
Yeah, so we split the foundation models into kind of two.
259
And I'll just talk about the set of models because everybody does.
260
So the state-of-the-art model market, this is like the Anthropics and the OpenAIs, is incredibly competitive and it's very heavily subsidized, right?
261
I mean, like with Meta and like Google, et cetera.
262
And so kind of our view is you have to be very, very careful before you go into it.
263
And there's a lot of companies you've never heard about that are in this space that we avoid.
264
So our view is you really want to back the primary names that have done it before that are able to raise.
265
I mean, the guy's Oppenheimer, right?
266
He's been close to every major advancement in the last 15 years in AI.
267
Our view when it comes to state-of-the-art models is really just like the premium teams that can get the capital.
268
Yeah, exactly.
269
And I won't go into our thesis on the other categories one by one, but I think the common theme here, and you'll hear it over and over again during this, is that the goal, the thesis, is to bet on market leaders with demonstrated momentum and are led by founders that are visionary and how they're applying AI to their verticals.
270
Let's close with one or two spicy takes.
271
What's something that other firms think is real that we don't, or vice versa?
272
I think, just at a high level, I'd say it seems like a lot of firms are failing on either side of this.
273
Like, some of them are like, it's not real.
274
We're not going to invest.
275
And it's amazing, like, some firms that were very, very relevant, we just never see anymore.
276
I mean, like, the founders don't talk about them.
277
They're not there.
278
They're not in the deal.
279
For the 10 years I've been doing this, the most remarkable transition.
280
And then there's others that got so excited so early and did all the deals.
281
And like I mentioned, they kind of got conflicted out.
282
Like they're dealing with a lot of companies that aren't working.
283
And so, I mean, we think you have to be very thoughtful and realize that this is its own space, that you need to have the same level of sophistication for any software.
284
In closing, what are the key messages we want to leave this audience?
285
You've already heard these messages over and over again, but they really are the key ones that we wanted to impart from our work and the way that we think about investing.
286
And that is, the market is growing faster and it's larger than anyone anticipated.
287
You've got to be really thoughtful about where you're placing the bets.
288
The stakes are higher than ever.
289
And this is a market where heat cannot be confused with momentum.
290
And then finally, as Martine said, you're on the field or you're irrelevant.
291
We're incredibly bullish.
292
Thanks for listening to the A16Z podcast.
293
If you enjoyed the episode, let us know by leaving a review at rate thispodcast.com slash A16Z.
294
We've got more great conversations coming your way.
295
See you next time.